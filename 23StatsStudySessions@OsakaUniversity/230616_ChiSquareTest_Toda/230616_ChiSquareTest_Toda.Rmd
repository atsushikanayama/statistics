---
title: "χ2検定の基礎と実践 by 戸田梨鈴"
author: "まとめ by 金山篤志"
date: "2023-06-16"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
  ioslides_presentation:
    toc: true
  word_document:
    toc: true
  beamer_presentation:
    toc: true
    latex_engine: xelatex
  pdf_document:
    toc: true
    latex_engine: xelatex
header-includes:
  - \usepackage{xeCJK}
  - \setCJKmainfont{Hiragino Mincho Pro}
---

```{r, error=TRUE, echo=FALSE}
# これはRのオプション設定コマンドです。CRANのミラーサイトとして"https://cloud.r-project.org/"を指定しています。
# CRANとはComprehensive R Archive Networkの略で、Rのパッケージが保存されているリポジトリです。
options(repos = c(CRAN = "https://cloud.r-project.org/"))

# "ggplot2"というパッケージをインストールします。Rのパッケージは、特定の機能や手法を利用するための一連の関数とデータセットを含んでいます。
# "ggplot2"はグラフィカルなデータ表示に広く使用されるパッケージです。
# "quiet = TRUE"は、インストールの途中経過やメッセージを表示しないようにするオプションです。
install.packages(c("ggplot2"), quiet = TRUE)

# ここで"ggplot2"パッケージを読み込みます。これにより、このパッケージに含まれる関数やデータセットがRセッションで使用可能になります。
# library関数は、パッケージの関数やデータをRの作業環境に読み込むためのものです。
library(ggplot2)
```

# 1. 概要

χ²検定は、カテゴリ型変数間の関連性や、観測データが特定の分布に従っているかどうかを評価するための統計的手法です。具体的には、カテゴリ型変数間の独立性を評価するだけでなく、理論値や期待値と観測値との適合性を評価します。この特性からχ²検定は「ノンパラメトリック」（無母数）検定とも呼ばれ、以下のような理由によります:

- データの分布に関する仮定が不要: χ2検定は、データが特定の分布（例えば正規分布）に従っているという仮定を立てません。これは、分布の特定のパラメーター（例えば平均値や標準偏差）に依存せず、データがどのように分布しているかに関わらず使用できるためです。
- 変数の尺度や順序についての仮定が不要: χ2検定では、χ2という名前が示すように、χ2値という特定の統計量を使用します。この統計量は、データのランクや尺度についての仮定を必要とせず、変数間の関連性や観測値と理論値の適合性を評価することができます。
- 度数を利用した統計量の計算: χ2検定は、観測された度数（各カテゴリの観測回数）と期待度数（変数が独立している場合や特定の理論値に基づいた予想度数）の間の差異を考慮します。この差異はχ2値という統計量に集約され、独立性や適合性の検定に使用されます。

したがって、χ2検定は、データの分布に関する仮定を必要とせず、カテゴリ型変数の独立性を評価し、観測値と理論値の適合性を評価するためのノンパラメトリックな検定手法と言えます。ただし、注意すべきは、χ2検定がデータの分布に関する仮定を立てない一方で、χ2値（検定統計量）がχ2分布に従うという仮定を立てるという点です。データ自体の分布と検定統計量の分布の仮定は異なることを理解しておくことが重要です。

本稿の目次は以下の通りです:

1. 概要
2. χ2分布
   - 定義
   - 特性
   - 自由度
3. χ2検定
   - χ2検定の種類
   - χ2検定の手順
   - χ2検定の統計的仮説
   - 注意点とヒント
   - χ2値の計算方法
   - まとめ
4. 1変量のχ2検定（適合度の検定）
   - 理論
   - 実践
5. 2変量のχ2検定（独立性の検定）
   - 理論
   - 実践
   - χ2検定とフィッシャーの直接確率検定の比較
6. マクネマー検定
   - 理論
   - 実践
7. χ2検定の同質性
   - 概要
   - 「2 x C」のχ2検定の同質性
   - 「R x 2」のχ2検定の同質性
   - 「R x C」のχ2検定の同質性
   - 「2 x C」、「R x 2」、および「R x C」の違い
   - まとめ
8. 多重比較
   - 多重比較の種類
   - 独立性の検定と多重比較補正の使用例
   - 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例
   - マクネマー検定と多重比較補正の使用例
   
# 2. χ2分布

χ2分布は、確率論および統計学で頻繁に用いられる確率分布です。ここではχ2分布の定義、特性、およびその利用法について解説します。

## 定義

χ²分布は、複数の独立した標準正規分布の二乗和が従う確率分布です。ここで、標準正規分布は平均が0で分散が1の正規分布を指します。

## 特性

χ2分布は、以下のような特性を持っています:

- χ2分布は必ず0以上の値をとります。これは、χ2分布が正規分布の二乗和として定義されるためです。マイナスの値をとることはありません。
- χ2分布の形状は自由度というパラメータにより決定されます。自由度が増えると、分布の形状は正規分布に近づきます。

χ2分布は統計的な検定、特に独立性の検定や適合度検定、分散分析などに用いられます。また、信頼区間の算出にも使用されます。

## 自由度

自由度は、統計的な分析における制約のない変動が可能な独立変数の数を指します。データの量や推定量の数によって影響を受けます。

自由度は、特定の確率分布（例えば、χ²分布、t分布、F分布など）の形状を決定し、統計的な検定の結果の解釈に使用されます。χ²分布の形状は自由度によって決定されます。

### 自由度の計算例

χ²検定では、自由度は観測データの行と列の数から計算します。具体的には、「（行数-1）×（列数-1）」の数式を用いて計算されます。

例として、2x2の観測データから自由度を計算します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2の観測データを作成します。
observed <- matrix(c(10, 20, 30, 40), nrow = 2)

# 行数と列数を取得します。
num_rows <- nrow(observed)
num_cols <- ncol(observed)

# 自由度を計算します。
df <- (num_rows - 1) * (num_cols - 1)

# 結果を表示します。
cat("自由度は:", df, "\n")
```

### 自由度の増加と分布の形状

自由度が増えると、χ²分布の形状は徐々に正規分布に近づいていきます。以下で、自由度が1, 3, 5, 10のχ²分布の形状を比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# ggplot2という描画に便利なパッケージを読み込みます。
library(ggplot2)

# 自由度というものを1,3,5,10と設定します。これはあとで分布の形を見るときに使います。
df_values <- c(1, 3, 5, 10)  

# 0から30までの間を、1000等分します。これがx軸の範囲になります。
x <- seq(0, 30, length.out = 1000) 

# df_valuesの各値に対して、以下の関数を適用します。
df_list <- lapply(df_values, function(df) { 
  data.frame(
    x = x,
    y = dchisq(x, df = df), # xの各値に対して、χ²分布の値を計算します。その分布の自由度は上で指定したdfです。
    df = as.factor(df) # 自由度dfを因子に変換してデータフレームに入れます。
  )
})

# 各自由度のデータフレームを一つにまとめます。
df_total <- do.call(rbind, df_list)

# 以下でグラフを描きます。
ggplot(df_total, aes(x = x, y = y, colour = df)) + # データフレームとx軸、y軸、色を指定します。
  geom_line() + # 線を描きます。
  labs(x = "Value", y = "Density", colour = "Degrees of Freedom") + # x軸、y軸、色の説明を書きます。
  theme_minimal() # シンプルなデザインにします。
```

χ²検定の結果は自由度によって影響を受けます。その影響を視覚的に理解するために、まず3x3の観測データを元にχ²検定を行い、その後で2x2の観測データを元にχ²検定を行います。これにより、自由度が変化した場合にχ²検定の結果がどのように変わるかを観察します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# dplyrパッケージの読み込み
library(dplyr)

# 3x3の観測データを作成します
observed2 <- matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90), nrow = 3)
cat("3x3観測データ:\n")
print(observed2)

# 3x3のデータに対してχ²検定を行います。デフォルトでは自由度は（行数-1）×（列数-1）で計算されます。
chisq_result2 <- chisq.test(observed2)

# χ²値、p値、自由度を表示します。
cat("3x3データに対するχ²値は: ", chisq_result2$statistic, "\n")
cat("3x3データに対するp値は: ", chisq_result2$p.value, "\n")
cat("3x3データに対する自由度は: ", chisq_result2$parameter, "\n")
```

次に、2x2のデータセットを用いて同様のχ²検定を行います。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2の観測データを作成します
observed <- matrix(c(10, 20, 30, 40), nrow = 2)
cat("2x2観測データ:\n")
print(observed)

# 2x2のデータに対してχ²検定を行います。デフォルトでは自由度は（行数-1）×（列数-1）で計算されます。
chisq_result <- chisq.test(observed)

# χ²値、p値、自由度を表示します。
cat("2x2データに対するχ²値は: ", chisq_result$statistic, "\n")
cat("2x2データに対するp値は: ", chisq_result$p.value, "\n")
cat("2x2データに対する自由度は: ", chisq_result$parameter, "\n")
```

以上の2つの結果から、自由度が変化した場合のχ²検定の結果（χ²値、p値、自由度）の違いを比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
library(tidyr)

# 比較用のデータフレームを準備
data <- data.frame(
  Test = c("3x3 Dataset", "2x2 Dataset"),
  ChiSquareValue = c(chisq_result2$statistic, chisq_result$statistic),
  PValue = c(chisq_result2$p.value, chisq_result$p.value),
  DegreesOfFreedom = c(chisq_result2$parameter, chisq_result$parameter)
)

# プロット用にデータを整形
data_plot <- data %>%
  pivot_longer(cols = -Test, names_to = "Metric", values_to = "Value") %>%
  mutate(Metric = case_when(
    Metric == "ChiSquareValue" ~ "Chi-square Value",
    Metric == "PValue" ~ "p-value",
    Metric == "DegreesOfFreedom" ~ "Degrees of Freedom"
  ))

# バープロットを作成し、χ²値、p値、自由度を比較
p <- ggplot(data_plot, aes(x = Test, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  scale_fill_brewer(palette = "Set2", name = "") +
  labs(x = "Dataset", y = "Value", fill = "") +
  facet_wrap(~ Metric, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom", 
        plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold")) +
  ggtitle("Comparison of 3x3 and 2x2 Datasets")

# バープロットを表示
p
```

次に、自由度が1から10までのときのχ²分布を描画し、自由度が増加するにつれて分布の形状がどのように変化するかを確認します。

```{r, error=FALSE, echo=FALSE}
# 自由度が1から10までのχ²分布をプロットします
df_list <- list()
for (df in 1:10) {
  df_list[[df]] <- data.frame(x = seq(0, 30, length.out = 1000), 
                              y = dchisq(seq(0, 30, length.out = 1000), df), 
                              df = factor(df))
}
df_all <- do.call(rbind, df_list)

# χ²分布を描画します
ggplot(df_all, aes(x = x, y = y, color = df)) +
  geom_line() +
  labs(x = "Value", y = "Density", color = "Degrees of Freedom") +
  theme_minimal() +
  ggtitle("Degrees of Freedom 1-10: Chi-square Distributions")
```

以上の結果から、自由度が増えるとχ²分布は右にシフトし、形状も変化します。自由度はχ²検定の結果に影響を及ぼすため、その概念を理解することは統計的分析を行う上で重要です。

# 3. χ²検定

χ²検定は、2つ以上のカテゴリカルデータ間の独立性や、一組の観測データが特定の理論的な分布に従っているかどうかを検定するための統計手法です。これはカテゴリカルなデータに対する統計的検定の一つで、観測された頻度分布が期待される頻度分布と有意に異なるかどうかを判断することが目的です。

## χ²検定の種類

χ²検定は主に以下の3つの目的で使用されます：

1. **適合度検定**：観測されたデータの分布が予想される特定の理論的な分布に適合するかどうかを評価します。
2. **独立性検定**：2つのカテゴリカル変数が互いに独立しているか、関連しているかを調べます。
3. **同質性の検定**：異なる群間でカテゴリカルデータの分布が同じであるかどうかを検定します。

## χ²検定の手順

1. **問題の理解と仮説の設定**:
    - 分析の目的を明確にし、適切なχ²検定（適合度検定、独立性検定、または同質性検定）を選択します。
    - 帰無仮説（H0）と対立仮説（H1）を設定します。

2. **前提条件の検証**:
    - サンプルデータはランダムに選ばれているか？
    - データはカテゴリカルまたは順序尺度か？
    - 各カテゴリの観測値は独立しているか？
    - 各カテゴリの期待度数は5以上か？（もし期待度数が5未満のセルがある場合は、Yatesの補正やフィッシャーの正確検定を検討する）

3. **χ²統計量の計算**:
    - χ²値は、観測された頻度と期待される頻度との間の差を考慮して計算されます。

4. **p値の計算**:
    - χ²分布表または統計ソフトウェアを使用して、計算されたχ²値と自由度（通常は「サンプルサイズ - 1」）を基にp値を求めます。
    - χ²検定の結果を報告する際には、χ²値、自由度（分析に使用された情報量のようなもの）、そしてp値（偶然から生じた結果である確率）を報告することが一般的です。

5. **結果の解釈**:
    - χ²検定の結果は、χ²値とp値で報告されます。p値が有意水準（通常は0.05）以下であれば、帰無仮説を棄却し、観測された頻度分布と期待される頻度分布との間に有意な差があると結論づけます。
    - p値が所定の有意水準より大きい場合、帰無仮説を採用します。

## χ²検定の統計的仮説

### 適合度検定
- **帰無仮説（H0）**：観測された頻度分布は期待される頻度分布に適合する。
- **対立仮説（H1）**：観測された頻度分布は期待される頻度分布に適合しない。

### 独立性検定
- **帰無仮説（H0）**：2つのカテゴリカル変数は独立である。
- **対立仮説（H1）**：2つのカテゴリカル変数は独立ではない。

### 同質性の検定
- **帰無仮説（H0）**：異なる群間でのカテゴリカルデータの分布は同じである。
- **対立仮説（H1）**：少なくとも1つの群でカテゴリカルデータの分布が異なる。

## 注意点とヒント

- χ²検定はカテゴリカルデータにのみ適用されます。連続データには適用できません。
- 期待度数が非常に小さい場合（通常は5未満）、χ²検定の結果は信頼性が低くなる可能性があります。この場合、データを再分類するか、別の検定方法を検討してください。
- χ²検定は、サンプルデータが母集団から無作為に選ばれていることを前提としています。
- χ²検定は、差の有無を判断するのに役立ちますが、その差がどの程度重要であるか（効果量）については情報を提供しません。効果量の推定も検討してください。
- χ²検定は、帰無仮説が正しいかどうかを判断するものであり、帰無仮説が正しくない理由を特定するものではありません。帰無仮説を棄却した場合、さらなる分析が必要です。

## χ²値の計算方法

χ²値は以下の式で計算されます：

\[ \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \]

ここで、\(O_i\)はi番目のカテゴリの観測された頻度であり、\(E_i\)はi番目のカテゴリの期待される頻度です。

このχ²値は、観測された頻度と期待される頻度との間の差異を統計的に表現するための指標です。観測値と期待値の差を二乗し、その後期待値で割ることで、各カテゴリにおける差異の相対的な大きさを求めます。これらの計算を各カテゴリで行い、その結果を合計することでχ²値が得られます。

χ²値の大きさは、観測データと期待値との間の乖離を表しています。この値が大きいほど、観測データは期待値から大きくずれていると解釈され、そのデータの背後に何らかの影響がある可能性を示唆します。

## まとめ

χ²検定は、カテゴリカルデータに対して、観測された頻度分布が期待される頻度分布と有意に異なるかどうかを判断するための強力な統計的手法です。しかし、この検定を適切に使用するためには、前提条件を理解し、適切な手順を踏む必要があります。また、χ²検定の結果は、データの背後にある実際のプロセスやメカニズムを理解するための出発点であることを念頭に置くことが重要です。

# 4. 1変量のχ2検定（適合度の検定）

## 理論

1変量のχ²検定（適合度の検定）は、観測データが特定の理論上の分布に従っているか否かを評価するための手法です。

公正な6面のサイコロを60回投げた例を考えてみましょう。理論的には、各面が出る回数は10回（60回 / 6面）と期待されます。しかし、実際の回数は必ずしも10回とは限りません。その差異が大きいほどχ²統計量は大きくなります。

p値が特定の閾値（通常は0.05）以下であれば、観測データが期待分布から統計的に有意に異なると解釈されます。

以下に、Rを用いたχ²検定の例を示します。

```{r, error=TRUE, include=TRUE}
# 乱数生成の初期値を設定
set.seed(123)

# 1から6までの数字（サイコロの目）をランダムに60回選ぶ
# 選択は置換あり（選ばれた数値を再度選ぶことが可能）
# 選択された数値を因子として扱う
# 各因子レベル（サイコロの目）が選ばれた回数（頻度）を集計
roll_results <- table(factor(sample(1:6, size = 60, replace = TRUE), levels = 1:6))

# サイコロを60回投げた結果を表示
print(roll_results)

# 各面が出る期待頻度を定義
# 各面が出る期待値は10回
expected_frequencies <- rep(10, 6)

# χ²検定を実行
# 検定は実際の結果（roll_results）と期待頻度（expected_frequencies）を比較
test_results <- chisq.test(roll_results, p = expected_frequencies / 60)

# χ²検定の結果を表示
print(test_results)
```

上記のコードでは、6面のサイコロを60回投げた結果をシミュレートし、その後、期待頻度（各面が10回出る）と観測頻度を用いてχ²検定を実行します。p値を確認することで、観測データが期待する分布（この場合、各面が等確率で出るとする分布）から統計的に有意に異なるかどうかを判断します。

## 実践

Rを用いてχ2適合度検定を実行する具体的な解析手順を示します。

### 例示の背景

この例では、幼稚園の子供たちが「幼稚園は好きですか？」という質問に「はい」または「いいえ」で答える場合を想定します。

### 仮説の設定

- 理論的仮説：特定の年齢層の子供たちが「幼稚園は好きですか？」という質問に「はい」または「いいえ」で答える確率は50%ずつである。

- 統計的仮説
  - 帰無仮説 (H0): 観測された分布が期待される分布（この場合は、はいといいえの確率が等しい）に従っている
  - 対立仮説 (Ha): 観測された分布が期待される分布に従っていない

### データの準備

```{r, error=TRUE, include=TRUE}
# CSVファイル 'chap4sample1.csv' を読み込み、x1 という変数に格納します。
x1 <- read.csv("chap4sample1.csv", header=T)
head(x1) # データの最初の数行を表示します。
```

```{r, error=TRUE, include=TRUE}
# factor関数を用いて、x1データフレームのAnswer列をカテゴリ変数（因子）に変換します。labelsパラメータを用いて、0と1の値をそれぞれ'No'と'Yes'に対応付けます。
x1$Answer <- factor(x1$Answer, labels=c('No','Yes')) 

# print関数を使って、変換後のAnswer列のデータを表示します。
print(x1$Answer) 
```

### 前提条件の検証

χ2検定の前提条件は、各カテゴリの期待頻度が5以上であることです。

```{r, error=TRUE, include=TRUE}
# table関数を用いて、Answer列のデータに基づきクロス集計表を作成します。この表には、'No'と'Yes'の回答数が表示されます。
x1table <- table(x1$Answer)

# print関数を使って、クロス集計表を表示します。
print(x1table) 
```

### Rでの実行

```{r, error=TRUE, include=TRUE}
# chisq.test関数を用いてχ2適合度検定を実行します。これにより観測データが期待する分布にどの程度適合しているかを評価します。
test_results <- chisq.test(x1table)
test_results
```

p値が0.05より小さい場合、観測されたデータが期待される分布と有意に異なると解釈されます。

### 視覚化

```{r, error=TRUE, include=TRUE}
# pie関数を用いて、クロス集計表のデータを利用して円グラフを作成します。円グラフは 'No'と'Yes'が全体に占める割合を視覚的に表示します。
pie(x1table, main="Pie Chart of Answers", col=c("lightblue", "pink"))
```

```{r, error=TRUE, include=TRUE}
# barplot関数を用いて、クロス集計表のデータを利用して棒グラフを作成します。棒グラフは各カテゴリ（'No'と'Yes'）の観測数を直観的に比較するのに適しています。
barplot(x1table, main="Number of 'No' and 'Yes'", xlab="Answer", ylab="Count", col=c("lightblue", "pink"))
```

### 結果の解釈

p値が0.05未満であれば、帰無仮説を棄却し、「はい」または「いいえ」の回答の分布は、期待される分布（「はい」と「いいえ」の確率が均等）と有意に異なると結論付けることができます。

この解析結果から、χ2統計量が5、自由度が1、p値が0.02535という結果が得られました。通常、p値が0.05以下であれば、統計的に有意と判断され、帰無仮説を棄却します。今回のp値は0.02535であるため、0.05より小さく、統計的に有意です。したがって、「はい」または「いいえ」の回答の分布は、期待される分布（「はい」と「いいえ」の確率が均等）と有意に異なると結論付けることができます。

### 結果の報告

論文での報告は以下のようになります：

「特定の年齢層の子どもたちに対して“幼稚園は好きですか？”という質問を行い、回答が均等に分布しているかどうかをχ2適合度検定で評価した（χ²(1) = 5.00, p = .03）。この結果は、回答の分布が均等であるという仮説を支持しなかった。これは、子どもたちの幼稚園に対する感情が一様でないことを可能性が示唆される。」

# 5. 2変量のχ2検定（独立性の検定）

2変量のχ²検定は、二つのカテゴリカル変数が互いに独立、つまり一方が他方に影響を与えないかどうかを評価する統計的手法です。

## 理論

χ²検定の帰無仮説は、「二つの変数は独立である」です。つまり、一つの変数の値がもう一つの変数の値に影響を与えないという仮説を検証します。

χ²統計量は次の式で求められます:

\\[\\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\]

ここで、

- \(O_{ij}\)はi番目とj番目のカテゴリの組み合わせの観測頻度を表し、
- \(E_{ij}\)はi番目とj番目のカテゴリの組み合わせの期待頻度を示します。

帰無仮説（二つの変数が独立である）が正しい場合、χ²統計量は小さな値になることが期待されます。逆に、χ²統計量が一定の閾値を超えた場合、帰無仮説は棄却され、二つの変数間に何らかの関連性が存在することを示します。

以下に、Rを用いてχ²検定を実行する例を示します：

```{r, error=TRUE, include=TRUE}
# ランダムな結果が再現可能になるようにシード値を設定
set.seed(123) 

# それぞれが3つのカテゴリを持つ2つのカテゴリカル変数のデータをシミュレーション
var1 <- sample(c("A", "B", "C"), size = 100, replace = TRUE)
var2 <- sample(c("X", "Y", "Z"), size = 100, replace = TRUE)

# 2つの変数のクロス集計表を作成
data <- table(var1, var2)

# χ²検定の実行
test_result <- chisq.test(data)

# χ²値の表示
print(test_result$statistic)

# p値の表示
print(test_result$p.value)
```

このコードでは、2つのカテゴリカル変数から成るデータセットをシミュレーションし、その後でχ²検定を実行してこれら2つの変数の間の独立性を評価します。出力されるp値を参照し、変数間に統計的に有意な関連性があるかどうかを判断します。

## 実践

Rを用いてχ2独立性検定を実行する具体的な解析手順を示します。

### 例示の背景

この例では、小学校の児童が授業が面白いかどうかについての意見（「同意」または「不同意」）と、その児童の性別（「男性」または「女性」）との間に関連性があるかどうかを調査します。

### 仮説の設定

- 理論的仮説：児童の性別は、授業に対する意見に影響を及ぼす。
- 統計的仮説
  - 帰無仮説 (H0): 性別と授業に対する意見の間には関連性がない（独立である）。
  - 対立仮説 (Ha): 性別と授業に対する意見の間には関連性がある。

### データの準備

```{r, error=TRUE, include=TRUE}
# CSVファイル 'chap4sample2.csv' を読み込む。
x2 <- read.csv("chap4sample2.csv", header=T) 
# データの最初の部分を表示する。
head(x2)
```
データの構造の確認:

```{r, error=TRUE, include=TRUE}
# データの構造を確認する。
str(x2)
```

### 前提条件の検証

χ2検定の前提条件は、各カテゴリの期待頻度が5以上であることです。

```{r, error=TRUE, include=TRUE}
# クロス集計表を作成
x2matrix <- with(x2, table(gender, answer))

# 期待度数のチェック
expected <- sum(x2matrix) * prod(dim(x2matrix)) / prod(sum(x2matrix))

if(all(expected >= 5)){
  print("期待度数は全て5以上なので、χ2検定を適用可能です。")
} else {
  print("期待度数が5未満のセルが存在するため、χ2検定を適用することはできません。")
}
```

### Rでの実行

```{r, error=TRUE, include=TRUE}
# χ2検定を実行する。
result <- chisq.test(x2matrix) 

# 結果を表示する。
print(result)
```

### 視覚化

```{r, error=TRUE, include=TRUE}
# データの視覚化
barplot(t(x2matrix), beside = TRUE, col = c("lightblue", "salmon"), 
        legend = rownames(x2matrix), ylim = c(0, max(x2matrix)*1.2), 
        ylab = "Counts", xlab = "Opinions", main = "Chi-Square Test of Independence")
```

### 結果の解釈

p値は0.01131となっており、これは一般的に用いられる有意水準0.05を下回るものです。したがって、統計的に有意と判断し、帰無仮説（性別と授業評価の間には関連性がない）を棄却し、対立仮説（性別と授業評価の間には関連性がある）を受け入れることができます。これにより、性別と授業評価との間には有意な関連性があり、男女の性別が授業評価に影響を及ぼす可能性が示唆されています。

### 結果の報告

論文での報告は以下のようになります：

「χ2独立性検定を使用して、小学生の性別（男性、女性）と授業評価（同意、不同意）の間の関連性を評価した。検定結果は、χ2(1) = 6.416, p = .011、となり、性別と授業評価の間に有意な関連性が存在することを示している。したがって、性別は授業評価に影響を及ぼす可能性があることが示唆された。」

## χ2検定とフィッシャーの直接確率検定の比較

フィッシャーの直接確率検定は、特に小さなサンプルサイズや期待度数が少ない場合に、χ2検定よりも高精度な結果を提供することが知られています。
    
```{r, error=TRUE, include=TRUE}
# 同じデータを読み込む
x2 <- read.csv("chap4sample2.csv", header=T) 
x2matrix <- with(x2, table(gender, answer))

# フィッシャーの直接確率検定を計算する。
fisher_result <- fisher.test(x2matrix) 

# 結果を表示する。
print(fisher_result)
```

# 6. マクネマー検定（対応のある二項的なデータの分析）

マクネマー検定は、対応のある二項的なデータ（成功/失敗、はい/いいえ等）を分析するためのノンパラメトリックな統計手法であり、カテゴリカルな変数間の関連性を評価します。これはχ²検定の一種であり、対応のあるペアデータに特に適用されます。

## 理論

マクネマー検定の帰無仮説は、「二つのカテゴリーの出現頻度は等しい」つまり、一方の変数の状態がもう一方の変数の状態に影響を及ぼさないというものです。

マクネマー検定は2x2のクロス集計表に基づいて計算を行います。具体的には、以下のような表を作成します:

```{r, error=FALSE, include=TRUE}
# matrix関数を用いて2行2列の行列を作成します。
data <- matrix(c("a", "b", "c", "d"), nrow = 2, byrow = TRUE,
               dimnames = list("Condition B" = c("Success", "Failure"),
                               "Condition A" = c("Success", "Failure")))

# 作成した行列を表示します。
print(data)
```

ここで、a、b、c、dはそれぞれの条件下で成功または失敗した被験体の数を示しています。そして、マクネマー検定の統計量は以下の式で計算されます:

\\[χ² = (|b - c| - 1)² / (b + c)\\]

このχ²の値が大きければ大きいほど、帰無仮説（条件Aと条件Bが同等の影響を及ぼす）が棄却されやすくなります。

以下に、Rを用いた具体的な例を示します:

```{r, error=TRUE, include=TRUE}
# 2行2列のクロス集計表を作成します。
data <- matrix(c(20, 30, 25, 25), nrow = 2)

# 行と列の名前をそれぞれ"条件B: 成功", "条件B: 失敗"、"条件A: 成功", "条件A: 失敗"と設定します。
rownames(data) <- c("条件B: 成功", "条件B: 失敗")
colnames(data) <- c("条件A: 成功", "条件A: 失敗")

# 作成したクロス集計表を出力します。
print(data)
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。この検定は、2x2のクロス集計表に対し、関連性または一貫性の評価に使用されます。
test_results <- mcnemar.test(data)

# マクネマー検定の結果を出力します。
print(test_results)
```

この例では、条件Aと条件B下での成功と失敗の頻度に差があるかどうかを評価しています。マクネマー検定のp値により、二つの条件間に統計的に有意な差異が存在するかどうかを判断することが可能です。

## 実践

### 例示の背景

次の例示は、幼稚園の子供たちが2つの異なるストーリー（「許す」または「許さない」）を聞いた後に、「一緒に遊ぶ」か「別々に遊ぶ」を選ぶというものです。このシナリオは、特定のストーリーが子供たちの選択に影響を与えるかどうかを評価するために考えられたものです。

### 仮説の設定

このシナリオの場合、帰無仮説（H0）と対立仮説（H1）は次のように設定されます:

- H0: ストーリーは子供たちの選択（一緒に遊ぶか、別々に遊ぶか）に影響を与えない。
- H1: ストーリーは子供たちの選択（一緒に遊ぶか、別々に遊ぶか）に影響を与える。

### データの準備

```{r}
# read.csv関数を用いて"chap4sample3.csv"という名前のCSVファイルを読み込み、その結果を"data"という変数に代入します。
data <- read.csv("chap4sample3.csv", header=TRUE)

# head関数を用いて"data"データフレームの最初の数行を表示します。これによりデータの一部を確認できます。
head(data)
```

```{r, error=TRUE, include=TRUE}
# str関数を用いて"data"データフレームの構造を確認します。これによりデータの各列のタイプ、列数、行数などを確認できます。
str(data)
```

### 前提条件の検証

マクネマー検定を使用する前に、必要な前提条件を確認する必要があります:

- データは対応のある二項的なデータ（成功/失敗、はい/いいえなど）であること。
- 各サブグループ（ここでは、各ストーリー）内の観測値は互いに独立であること。

### Rでの実行

```{r, error=TRUE, include=TRUE}
table_data <- table(Forgiveness = data$Forgive, Rejection = data$Reject)
table_data
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。correct=TRUEオプションを指定して、イェーツの補正を適用します。
# イェーツの補正とは二項分布が正規分布に近似するために行われる補正のことで、2×2の分割表のカイ二乗検定に用いられます。特にサンプルサイズが小さい場合に有用です。
test_results <- mcnemar.test(table_data, correct=TRUE)

# print関数を用いて、マクネマー検定の結果を表示します。
print(test_results)
```

### 視覚化

検定の結果を使用して棄却領域を示すχ²分布を描くことができます。

χ²統計量と自由度、そしてp値の情報を注釈として表示させてください:

```{r, error=TRUE, include=TRUE}
# 必要なライブラリの読み込み
library(ggplot2)

# マクネマー検定の結果を取得します。これらの結果は既に得られています。
chi_squared <- test_results$statistic  # χ²統計量
df <- test_results$parameter  # 自由度
p <- test_results$p.value  # p値

# χ²分布を描くためのデータフレームを作成します。
# xは0から15までの100等分した数値のベクトル、yはxと自由度dfに基づくχ²分布です。
data_distribution <- data.frame(x = seq(0, 15, length.out = 100))
data_distribution$y <- dchisq(data_distribution$x, df = df)

# チートラインのx座標を制限範囲内に収めます。
chi_squared_line <- ifelse(chi_squared > max(data_distribution$x)*0.8, 
                           max(data_distribution$x)*0.8, chi_squared)

# χ²分布を描画します。赤い破線はマクネマー検定で得られたχ²統計量を示します。
ggplot(data_distribution, aes(x = x, y = y)) +  # 描画の基盤を作成
  geom_line() +  # データフレームから線グラフを描画
  geom_vline(xintercept = chi_squared_line, linetype = "dashed", color = "red") +  # χ²統計量の位置に破線を描画
  annotate(  # χ²統計量とp値の情報を注釈として追加
    "text",
    x = chi_squared_line + 1,  # 注釈のx座標
    y = dchisq(chi_squared_line, df = df),  # 注釈のy座標
    label = paste("χ² =", round(chi_squared, 2), "\np =", round(p, 4)),  # 注釈のテキスト
    hjust = "left"  # 注釈の水平方向の位置（"left"は左寄せ）
  ) +
  xlab("χ²") +  # x軸ラベル
  ylab("Density") +  # y軸ラベル
  theme_minimal()  # テーマを設定
```

### 結果の解釈

今回の解析の結果、χ²統計量は16、自由度は1、そしてp値は6.334e-05でした。通常、p値が0.05未満の場合、統計的に有意と判断され、帰無仮説が棄却されます。今回のp値は6.334e-05であり、0.05を大幅に下回っているため、統計的に有意と判断できます。これは、「一緒に遊ぶ」と「別々に遊ぶ」の選択には偶然以上の関連性があることを意味します。

### 結果の報告

論文での報告は以下のようになります：

「子どもたちはストーリーの結果に基づき、「一緒に遊ぶ」か「別々に遊ぶ」かを選び、その選択が偶然に従って分布しているかどうかを確認するために、イェーツの補正を用いたマクネマー検定を実行した（McNemar's χ²(1) = 16, p < .001）。この結果から、選択が偶然によるものという帰無仮説は棄却された。つまり、ストーリーの結果が子どもたちの「一緒に遊ぶ」か「別々に遊ぶ」の選択に統計的に有意な影響を与えたと推測できる。」

# 7. χ2検定の同質性

χ2検定の同質性は、カテゴリデータが複数のグループ間で均等に分布しているかどうかを調査するための統計的な方法です。この手法は、「2 x C」、「R x 2」、および「R x C」など、さまざまな形式で活用されます。

## 概要

χ2検定の同質性は、異なるグループ間でカテゴリーの分布が似ているかどうかを調べるために使用されます。これは、例えば、異なる年齢層の子供たちが同じような学習スタイルを持っているかどうかを調査する際に役立ちます。

## 「2 x C」のχ2検定の同質性

2 x C」形式は、2つのカテゴリがC個のグループに分かれている場合に使用されます。例として、5歳と10歳の子供たちが3つの異なる学習スタイル（視覚的、聴覚的、運動性）にどのように分かれるかを調査します。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep("5歳", 150), rep("10歳", 150))
learning_style <- c(rep(c("視覚的", "聴覚的", "運動性"), length.out = 150),
                    rep(c("視覚的", "聴覚的", "運動性"), length.out = 150))

# データフレームを作成
data_2xC <- data.frame(age_group, learning_style)

# クロス集計表を作成
cross_table <- table(data_2xC)
cross_table
```

```{r, error=TRUE, include=TRUE}
# χ2検定を実行
result_2xC <- chisq.test(cross_table)

# 結果を表示
print(result_2xC)
```

サンプルサイズが小さい場合は、Fisherの正確性検定を使用することで、より信頼性のある結果を得ることができます。

```{r, error=TRUE, include=TRUE}
# Fisherの正確性検定を実行
result_fisher <- fisher.test(cross_table)

# 結果を出力
print(result_fisher)
```

## 「R x 2」のχ2検定の同質性

「R x 2」形式は、R個のグループが2つのカテゴリに分かれている場合に使用されます。例えば、一親家庭、両親家庭、祖父母と同居の3つの家庭環境の子供たちが、学業成績が平均以上か平均未満かでどう分かれるかを調査する場合です。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
family_environment <- rep(c("一親家庭", "両親家庭", "祖父母と同居"), each = 50)
academic_performance <- rep(c("平均以上", "平均未満"), each = 75)

# データフレームを作成
data_Rx2 <- data.frame(family_environment, academic_performance)

# クロス集計表を作成
cross_table <- table(data_Rx2)
print(cross_table)
```

```{r, error=TRUE, include=TRUE}
# χ2検定を実行
result_Rx2 <- chisq.test(cross_table)

# 結果を表示
print(result_Rx2)
```

## 「R x C」のχ2検定の同質性

「R x C」形式は、R個のグループがC個のカテゴリに分かれている場合に使用されます。これは、より複雑なデータセットを分析する際に役立ちます。例として、異なる年齢層（5歳、10歳、15歳）の子供たちが3つの異なる学習スタイル（視覚的、聴覚的、運動性）にどのように分かれるかを調査します。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep(c("5歳", "10歳", "15歳"), each = 100))
learning_style <- c(rep(c("視覚的", "聴覚的", "運動性"), length.out = 300))

# データフレームを作成
data_RxC <- data.frame(age_group, learning_style)

# クロス集計表を作成
cross_table <- table(data_RxC)
cross_table
```

```{r, error=TRUE, include=TRUE}
# χ2検定を実行
result_RxC <- chisq.test(cross_table)

# 結果を表示
print(result_RxC)
```

## 「2 x C」、「R x 2」、および「R x C」の違い

「2 x C」は2つのカテゴリが複数のグループに分かれている場合、「R x 2」は複数のグループが2つのカテゴリに分かれている場合、そして「R x C」はR個のグループがC個のカテゴリに分かれている場合に使用されます。これらは、χ2統計量を使用して分布の違いを探るものですが、使用する状況が異なります。

## まとめ

χ2検定の同質性は、カテゴリデータの分布がグループ間で一様であるかどうかを評価するために使用されます。これは、発達心理学などの分野で特に重要です。たとえば、子供たちの学習スタイルが年齢層によって異なるかどうかを調査する際などに役立ちます。サンプルサイズが小さい場合は、Fisherの正確性検定など、他の手法を検討する必要があるかもしれません。これにより、データからより深い洞察を得ることができ、意味のある結論を導く手助けとなります。

# 8. 多重比較

統計解析では、複数の比較を一度に行うことを多重比較と呼びます。しかし、一度に多くの比較を行うと、偶然による偽陽性（存在しない効果を検出する誤り）のリスクが増大します。これを緩和するために、以下の補正方法が提案されています。

## 多重比較の種類

1. ボンフェローニ補正 (Bonferroni correction): 各比較の有意性レベル（p値）を全体の比較の数で割ることで偽陽性のリスクを減らしますが、厳格すぎるために偽陰性のリスクも増大します。

2. ホルム補正 (Holm correction): ボンフェローニ補正を改良し、全てのp値を小さい順に並べ、それぞれにボンフェローニ補正を適用します。これにより偽陽性のリスクを抑えつつ、偽陰性のリスクも低減します。

3. ベンジャミニ＆ホッホベルク法 (Benjamini & Hochberg method): 偽陽性の「割合」を制御する方法で、全てのp値を小さい順に並べ、それぞれのp値に（その順位/全比較数）*目標FDRを掛けた値を新たなp値とします。

4. チューキーのHSD法 (Tukey's HSD method): ANOVA（分散分析）後の多重比較に有効で、全てのペア間の比較を行います。

## 独立性の検定と多重比較補正の使用例

ここでは、3つの異なる教育介入（A、B、C）が特定の行動（行動1、行動2）の発生にどのように関連しているかをχ2検定で評価し、その結果に対して多重比較補正を適用する例を紹介します。さらに、各教育介入における行動1と行動2の出現率に違いがあるかどうかを検証するために、ペアワイズのχ2検定を適用します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込み
library(pwr)

# 再現可能なランダムな結果を得るためにシードを設定
set.seed(123)

# Intervention列に"A", "B", "C"、Behavior列に"Behavior1", "Behavior2"をランダムに割り当て（全体で300行）
data <- data.frame(
  Intervention = sample(c("A", "B", "C"), 300, replace = TRUE),
  Behavior = sample(c("Behavior1", "Behavior2"), 300, replace = TRUE)
)
head(data)
```

```{r, error=TRUE, include=TRUE}
# データフレームから介入と行動についてのクロス集計表を作る
table(data$Intervention, data$Behavior)
```

```{r, error=TRUE, include=TRUE}
# それをχ2検定に渡す
chisq_res <- chisq.test(table(data$Intervention, data$Behavior))

# p値を取得
p_value <- chisq_res$p.value

# ボンフェローニ補正、ホルム補正、ベンジャミニ＆ホッチベルク補正（BH補正）を適用してp値を補正
bonferroni <- p.adjust(p_value, method = "bonferroni")
holm <- p.adjust(p_value, method = "holm")
BH <- p.adjust(p_value, method = "BH")

# 補正後のp値を表示
data.frame(Bonferroni = bonferroni, Holm = holm, BH = BH)
```

```{r, error=TRUE, include=TRUE}
# 各教育介入における行動1と行動2の出現率に違いがあるかどうかを検証するために、ペアワイズのχ2検定を適用
pairs <- combn(unique(data$Intervention), 2)
pairwise_chisq <- apply(pairs, 2, function(x) {
  subdata <- data[data$Intervention %in% x, ]
  chisq_res <- chisq.test(table(subdata$Intervention, subdata$Behavior))
  chisq_res$p.value
})

# 各ペア間のχ2検定のp値を補正
bonferroni_pairwise <- p.adjust(pairwise_chisq, method = "bonferroni")
holm_pairwise <- p.adjust(pairwise_chisq, method = "holm")
BH_pairwise <- p.adjust(pairwise_chisq, method = "BH")

# 補正後のペアワイズp値を表示
data.frame(Pairs = t(pairs), Bonferroni = bonferroni_pairwise, Holm = holm_pairwise, BH = BH_pairwise)
```

この結果から、各教育介入が行動1と行動2の出現にどのように影響するか、そして介入間で行動の出現率に違いがあるかどうかを多重比較補正を用いて評価できます。

## 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例

一元配置分散分析（ANOVA）は、一つ以上の要因が群間での平均値の差異を引き起こすかどうかを評価するための統計的手法です。さらに、チューキーのHSD法を利用することで、具体的な群間の差を明らかにすることができます。ここでは、これらの方法を用いて、特定の介入がスコアにどのような影響を及ぼすかを調査する例を示します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(agricolae)

# 再現可能なランダムな結果を得るために乱数シードを設定
set.seed(123)

# データフレームを作成。Intervention列に"A", "B", "C"を、Score列には異なる平均値と標準偏差をもつ正規分布から抽出したスコアを割り当てる
data <- data.frame(
  Intervention = rep(c("A", "B", "C"), each = 50),
  Score = c(rnorm(50, mean = 80, sd = 10),
            rnorm(50, mean = 85, sd = 10),
            rnorm(50, mean = 90, sd = 10))
)
head(data)
```

```{r, error=TRUE, include=TRUE}
# Intervention列の影響をスコアに対して評価するために一元配置ANOVAを適用する
model <- aov(Score ~ Intervention, data = data)

# ANOVAの結果を表示
summary(model)
```

```{r, error=TRUE, include=TRUE}
# チューキーのHSD法を用いて具体的な群間比較を行う
HSD_result <- HSD.test(model, 'Intervention', group = TRUE)

# 結果を表示
print(HSD_result)
```

この例では、ANOVAを使用して教育介入（A、B、C）が学生のスコアに対してどのような影響を及ぼしているかを評価します。その後、チューキーのHSD法を用いて各介入間のスコアの差を明らかにします。ANOVAの結果にかかわらず、チューキーのHSD法は介入効果の具体的な違いを理解するために用いられます。ただし、ANOVAの結果が非有意の場合、その結果を過度に解釈することは避けるべきです。

## マクネマー検定と多重比較補正の使用例

教育介入方法A、B、Cが子供の行動にどれほど影響を及ぼすかを評価します。それぞれの教育介入についてマクネマー検定を行い、得られたp値に対してボンフェローニ補正、ホルム補正、そしてベンジャミニ＆ホッホベルグ法を適用します。これらの補正は、多重比較によって誤って有意な結果と判断されるリスクを軽減するためのものです。

なお、チューキーのHSD法はANOVAの結果に対する多重比較補正として使用される手法で、マクネマー検定に対しては直接適用することはできません。


```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込み
library(stats)

# 結果の再現性を確保するためのシード設定
set.seed(123)

# 各教育介入方法についてデータ生成
before_A <- sample(c(0, 1), 100, replace = TRUE)
after_A <- sample(c(0, 1), 100, replace = TRUE)
before_B <- sample(c(0, 1), 100, replace = TRUE)
after_B <- sample(c(0, 1), 100, replace = TRUE)
before_C <- sample(c(0, 1), 100, replace = TRUE)
after_C <- sample(c(0, 1), 100, replace = TRUE)

# 各方法についてマクネマー検定の実施
mcnemar_res_A <- mcnemar.test(before_A, after_A)
mcnemar_res_B <- mcnemar.test(before_B, after_B)
mcnemar_res_C <- mcnemar.test(before_C, after_C)

# p値の取得
p_values <- c(mcnemar_res_A$p.value, mcnemar_res_B$p.value, mcnemar_res_C$p.value)

# 各補正法によるp値の調整
bonferroni <- p.adjust(p_values, method = "bonferroni")
holm <- p.adjust(p_values, method = "holm")
BH <- p.adjust(p_values, method = "BH")

# 元のp値と補正後のp値を表示するためのデータフレームを作成
result_df <- data.frame(
  Method = c("A", "B", "C"),
  p_value = p_values,
  p_value_bonferroni = bonferroni,
  p_value_holm = holm,
  p_value_BH = BH
)

# 結果を表示
print(result_df)
```

これらの結果を通じて、各教育介入方法が子供の行動に与える影響の有意性を複数の補正法に基づいて評価することができます。これにより、個々の教育介入方法の効果をより厳密に解釈することが可能になります。

# 参考ページ:

- [統計学の時間 - パラメトリックとノンパラメトリック](https://bellcurve.jp/statistics/course/1562.html)

- [Study Channel - パラメトリックとノンパラメトリック](https://www.study-channel.com/2015/06/parametric-nonparametric-test.html)

- [日経調査研究所 - χ2検定](https://service.nikkei-r.co.jp/glossary/chi-square-test/)

- [Best Biostatistics - 自由度の理解](https://best-biostatistics.com/contingency/degree-freedom.html)

- [統計学の時間 - χ2適合度検定](https://bellcurve.jp/statistics/course/9494.html)
