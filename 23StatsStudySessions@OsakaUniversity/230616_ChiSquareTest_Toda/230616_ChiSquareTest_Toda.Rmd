---
title: "χ²検定の基礎と実践 by 戸田梨鈴"
author: "まとめ by 金山篤志"
date: "2023-06-16"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
  ioslides_presentation:
    toc: true
  word_document:
    toc: true
  beamer_presentation:
    toc: true
    latex_engine: xelatex
  pdf_document:
    toc: true
    latex_engine: xelatex
header-includes:
  - \usepackage{xeCJK}
  - \setCJKmainfont{Hiragino Mincho Pro}
---

```{r, error=TRUE, echo=FALSE}
# これはRのオプション設定コマンドです。CRANのミラーサイトとして"https://cloud.r-project.org/"を指定しています。
# CRANとはComprehensive R Archive Networkの略で、Rのパッケージが保存されているリポジトリです。
options(repos = c(CRAN = "https://cloud.r-project.org/"))

# "ggplot2"というパッケージをインストールします。Rのパッケージは、特定の機能や手法を利用するための一連の関数とデータセットを含んでいます。
# "ggplot2"はグラフィカルなデータ表示に広く使用されるパッケージです。
# "quiet = TRUE"は、インストールの途中経過やメッセージを表示しないようにするオプションです。
install.packages(c("ggplot2"), quiet = TRUE)

# ここで"ggplot2"パッケージを読み込みます。これにより、このパッケージに含まれる関数やデータセットがRセッションで使用可能になります。
# library関数は、パッケージの関数やデータをRの作業環境に読み込むためのものです。
library(ggplot2)
```

目次

1. 概要
2. χ²分布
   - 定義
   - 特性
   - 自由度
3. χ²検定
   - χ²検定の種類
   - χ²検定の手順
4. 1変量のχ²検定（適合度の検定）
   - 理論
   - 実践
5. 2変量のχ²検定（独立性の検定）
   - 理論
   - 実践
   - χ²検定とフィッシャーの直接確率検定の比較
6. マクネマー検定
   - 理論
   - 実践
7. χ²検定の同質性（同質性の検定）
   - 「2 x C」のχ²検定の同質性
   - 「R x 2」のχ²検定の同質性
   - 「R x C」のχ²検定の同質性
   - 「2 x C」、「R x 2」、および「R x C」の違い
8. 多重比較
   - 多重比較の種類
   - 独立性の検定と多重比較補正の使用例
   - 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例
   - マクネマー検定と多重比較補正の使用例

# 1. 概要

χ²検定は、カテゴリー型のデータ（例：男性か女性、成功か失敗など）の関連性を調べるための統計的手法です。また、実際のデータが理論的な分布とどれだけ合っているかを確かめる際にも使われます。

この検定は、いわゆる「ノンパラメトリック」（無母数）検定として知られており、その特長は以下の通りです：

- **特定の分布を前提としない**： χ²検定では、データが正規分布などの特定の分布に従っている必要がありません。データがどのように分布しているかにかかわらず、この検定を利用することができます。

- **尺度に依存しない**： データが何らかのランクや順序を持っている必要はなく、χ²検定はχ²という統計量を使ってデータの関連性を評価します。これにより、データの尺度にとらわれることなく分析が行えます。

- **度数に着目**： χ²検定は、カテゴリごとの観測回数（度数）と理論上期待される度数との間の違いを考慮します。これらの違いはχ²の値としてまとめられ、データがどれだけ理論的な分布に従っているかを判断するのに用います。

χ²検定は、データの特定の形状にとらわれることなく、「データが特定の理論的な分布に従っているかどうか」を調査する（これを適合度検定と呼びます）または、カテゴリ間の関連性を検証する（これを独立性検定と呼びます）ための非常に便利な方法です。χ²検定を利用する際に重要なことは、データが特定の確率分布に厳密に従う必要はない、という点です。しかし、データと理論の違いを数値化する「χ²統計量」は、特定のパターン（つまりχ²分布）に従うという前提があります。この前提を把握しておくことで、検定結果の解釈とその有効性が適切に理解できます。
   
# 2. χ²分布

χ²分布は統計学や確率論の分野で広く採用されている確率分布であり、統計的検定や信頼区間の推定など、多くの応用に重要な役割を果たします。このセクションでは、χ²分布の基本的な概念、特性、そして自由度との関係について解説します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なパッケージをロードします
library(ggplot2)

# カイ二乗分布のデータを生成します
x <- seq(0, 20, length.out = 1000)
density <- dchisq(x, df = 4)

# データフレームに変換します
df <- data.frame(
  x = x,
  density = density
)

# グラフをプロットします
ggplot(df, aes(x, density)) +
  geom_line(color = "blue") +
  theme_minimal() +
  labs(x = "Value", y = "Density", 
       title = "Chi-Squared Distribution with df = 4")
```

## 定義

χ²分布は、複数の独立した標準正規分布（平均0、分散1の正規分布）の二乗和が従う確率分布と理解できます。詳しくは、k個の独立した標準正規分布の値をそれぞれ二乗し、その結果を足し合わせたものが、自由度kのχ²分布に従うということです。

ここで、\(Z_1\), \(Z_2\), ..., \(Z_k\)は互いに独立した標準正規分布（平均0、分散1の正規分布）に従うとします。これらを二乗して足し合わせると、その和Xは自由度kのχ²分布に従います。

\[ X = Z_1^2 + Z_2^2 + ... + Z_k^2 \]

次のグラフでは、ヒストグラムが2つの独立した標準正規分布の二乗和のデータ分布を、滑らかな曲線が自由度2の理論的なχ²分布をそれぞれ表現しています。このグラフから、二乗和がχ²分布に従う様子を視覚的に理解することが可能です。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# Rコード
library(ggplot2)

# 標準正規分布からサンプルを取得
n_samples <- 10000
z1 <- rnorm(n_samples, 0, 1)
z2 <- rnorm(n_samples, 0, 1)

# 二乗して足し合わせる
chi_square <- z1^2 + z2^2

# プロットにヒストグラムと理論的なχ²分布を表示
p <- ggplot() +
  geom_histogram(data = data.frame(chi_square), aes(x = chi_square, y = after_stat(density)), bins = 50, alpha = 0.5) +
  stat_function(fun = dchisq, args = list(df = 2), aes(color = "Theoretical Chi-Square Distribution"), linewidth = 1) +
  labs(title = "Sum of Squares of Two Independent Standard Normal Distributions",
       x = "Value",
       y = "Density",
       color = "Legend") +
  theme_minimal()

# プロットを表示
print(p)
```

## 特性

χ²分布は以下のような特性を持っています。

- **0以上の値**: χ²分布は0以上の値しか取りません。これは、正規分布の二乗和として定義されるため、負の値が出現しないからです。
- **形状と自由度**: χ²分布の形状は自由度に依存します。自由度が増えるにつれて、χ²分布は徐々に正規分布に近づき、ピークは右にシフトします。
- **平均と分散**: χ²分布の平均は自由度と等しく、分散は自由度の2倍です。

χ²分布は以下のような用途があります。

- **χ²検定**:χ²検定は、カテゴリカルデータに基づいて、2つのカテゴリカル変数間の関連性や観測データが特定の理論的分布に従っているかどうかを評価するために使用されます。χ²検定では、観測された頻度と期待される頻度の間の差異をχ²統計量で評価し、この統計量をχ²分布と比較して検定を行います。

- **分散の信頼区間の計算**:χ²分布は、分散の信頼区間の計算に頻繁に使用されます。特に、正規分布の母集団分散の信頼区間を推定する際にχ²分布が活用されます。サンプルデータから得られたχ²統計量を用いて、分散の信頼区間を求めます。

- **統計モデルの評価**:統計モデルの適合度を評価する際にもχ²分布は使われます。例えば、ロジスティック回帰モデルの適合度を評価する際の尤度比検定では、その統計量がχ²分布に従うことが知られています。これにより、統計モデルがデータにどれほど良く適合しているか、またそのモデルが信頼できるのかを判断することが可能となります。

- **モンテカルロシミュレーション**:モンテカルロシミュレーションなどの確率的なシミュレーションを行う際に、特定の自由度を持つχ²分布に基づいて乱数を生成し、それをシミュレーションの一部として使用します。

- **発達心理学における使用**:
発達心理学では、成長曲線のモデリングにχ²分布が用いられることがあります。例えば、身長の成長曲線をモデリングする際、子供の成長の観察データと理論的な成長曲線の適合性を評価するためにχ²統計量とその分布が使用されます。これにより、理論的な成長曲線が観察データにどれほど良く適合しているかを評価します。

## 自由度

自由度は、制約のない独立した情報の総量を示す概念で、具体的には他のパラメータや制約に影響されずに選択できる変数の数を指します。自由度は、統計的仮説検定の精度を計算するためや、特定の確率分布（χ²分布、t分布、F分布など）の形状を定義するために使用されます。

以下に、個々のデータ値と統計モデルの観点から自由度について考察します。

- **個々のデータ値における自由度**: 各データ点は自由度を1つ持っています。しかし、すべてのデータ点が完全に自由であるわけではありません。例えば、3つの数値が与えられ、それらの平均が0であるとすると、最初の2つの数値は自由に選べますが、3つ目の数値は他の2つによって制約されます。つまり、この場合の自由度は2となります。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 最初の2つの数値を指定します
x1 <- 4
x2 <- -2

# 平均が0になるように3つ目の数値を計算します
x3 <- - (x1 + x2)

# 数値と平均値を出力します
cat("Numbers: ", x1, x2, x3, "\n")
cat("Mean: ", mean(c(x1, x2, x3)), "\n")
```

- **統計モデルにおける自由度**: 一方、統計モデルの自由度は、そのモデルのパラメータの数によって決まります。例えば、線形回帰モデルの場合、直線のフィットは y = ax + b の形で表現されます。ここでaとbはパラメータで、データから推定されます。したがって、このモデルの自由度は、観測値の数（n）からパラメータ数（2つ、aとb）を引いた n-2 となります。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 乱数生成の初期値を設定
set.seed(123)

# データを生成
n <- 100  # データの数
x <- runif(n, 0, 10)
y <- 2*x + 3 + rnorm(n)

# 線形回帰モデルを作成
model <- lm(y ~ x)

# 自由度を計算し、出力します
df <- n - length(coef(model))
cat("Degrees of freedom: ", df, "\n")
```

このコードでは乱数を用いてデータを生成し、それを用いて線形回帰モデルを作成しました。このモデルの自由度はデータの数（この場合、100）からパラメータの数（この場合、2）を引いた値です。

自由度は、特定の確率分布（χ²分布、t分布、F分布など）の形状を決定する重要な要素でもあります。自由度が増えると、これらの分布は正規分布に近づきます。これは、自由度が大きくなるほど利用可能な情報量が増え、結果の信頼性が向上するためです。この性質は中心極限定理と密接に関連しています。

### 自由度の計算例

χ²検定においては、自由度の計算方法は特定の公式に従います。具体的には、カテゴリカルなデータに対するχ²検定では、自由度は観測データの行と列の数から計算します。この場合、「（行数-1）×（列数-1）」の公式を用いて自由度が計算されます。

例えば、2x2の観測データ（例：行と列がそれぞれ2つのカテゴリを持つクロス集計表）がある場合、自由度は「(2-1) x (2-1) = 1」となります。つまり、1つの自由な変動が可能なパラメータが存在します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2の観測データを作成します。
observed <- matrix(c(10, 20, 30, 40), nrow = 2)

# 行数と列数を取得します。
num_rows <- nrow(observed)
num_cols <- ncol(observed)

# 自由度を計算します。
df <- (num_rows - 1) * (num_cols - 1)

# 結果を表示します。
cat("自由度は:", df, "\n")
```

### 自由度と分布の形状

χ²分布の形状は、その自由度により決まります。自由度とは、統計的な解析で自由に変動できる値の数を示します。

自由度が1のχ²分布は、原点から離れたところでピークを持ち、右に偏った形状を示します。しかし、自由度が増加すると、分布の形状は徐々に正規分布に近づき、ピークも原点から遠くに移動します。つまり、自由度が増えると、分布は右にシフトし、分布の広がり（すなわち、分布のばらつき）が増加します。

次のグラフは自由度が1から10までのχ²分布を描画し、自由度が増加するにつれて分布の形状がどのように変わるかを視覚的に示したものです。

```{r, error=FALSE, echo=FALSE}
# 自由度が1から10までのχ²分布のプロット
df_list <- list()
for (df in 1:10) {
  df_list[[df]] <- data.frame(x = seq(0, 30, length.out = 1000), 
                              y = dchisq(seq(0, 30, length.out = 1000), df), 
                              df = factor(df))
}
df_all <- do.call(rbind, df_list)

# χ²分布の描画
ggplot(df_all, aes(x = x, y = y, color = df)) +
  geom_line() +
  labs(x = "Value", y = "Density", color = "Degrees of Freedom") +
  coord_cartesian(ylim = c(0, 0.6)) + # y軸の範囲を0から0.75に制限します。
  theme_minimal() + # シンプルなデザインにします。
  ggtitle("Degrees of Freedom 1-10: Chi-square Distributions")
```

自由度が増えるとχ²分布は右にシフトし、徐々に正規分布に近づいていくことがわかります。

### 自由度と検定の結果

χ²検定の結果は、自由度に強く影響されます。自由度が変われば、χ²検定の結果も必然的に変化します。今回、3x3と2x2の異なる観測データセットを用いて、自由度の違いがχ²検定結果にどのように影響を及ぼすかを評価します。

まず、3x3の観測データセットを用いてχ²検定を行い、次に2x2の観測データセットで同じ検定を実施し、それぞれの結果を比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# dplyrパッケージの読み込み
library(dplyr)

# 3x3観測データの作成
observed2 <- matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90), nrow = 3)
cat("3x3観測データ:\n")
print(observed2)

# 3x3データを用いたχ²検定の実行
chisq_result2 <- chisq.test(observed2)

# χ²値、p値、自由度の表示
cat("3x3データに対するχ²値: ", chisq_result2$statistic, "\n")
cat("3x3データに対するp値: ", chisq_result2$p.value, "\n")
cat("3x3データに対する自由度: ", chisq_result2$parameter, "\n")
```

続いて、2x2のデータセットを用いて同様のχ²検定を行います。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2観測データの作成
observed <- matrix(c(10, 20, 30, 40), nrow = 2)
cat("2x2観測データ:\n")
print(observed)

# 2x2データを用いたχ²検定の実行
chisq_result <- chisq.test(observed)

# χ²値、p値、自由度の表示
cat("2x2データに対するχ²値: ", chisq_result$statistic, "\n")
cat("2x2データに対するp値: ", chisq_result$p.value, "\n")
cat("2x2データに対する自由度: ", chisq_result$parameter, "\n")
```

これらの結果を元に、自由度の違いがχ²検定結果（χ²値とp値）にどのように影響するかを比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# パッケージの読み込み
library(tidyr)

# 比較用のデータフレームの準備
data <- data.frame(
  Test = c("3x3", "2x2"),
  DegreesOfFreedom = c(chisq_result2$parameter, chisq_result$parameter),
  ChiSquareValue = c(chisq_result2$statistic, chisq_result$statistic),
  PValue = c(chisq_result2$p.value, chisq_result$p.value)
)

# プロット用のデータ整形
data_plot <- data %>%
  pivot_longer(cols = -Test, names_to = "Metric", values_to = "Value") %>%
  mutate(Metric = factor(Metric, levels = c("DegreesOfFreedom", "ChiSquareValue", "PValue")),
         Metric = case_when(
           Metric == "DegreesOfFreedom" ~ "Degrees of Freedom",
           Metric == "ChiSquareValue" ~ "Chi-square Value",
           Metric == "PValue" ~ "p-value"
         ))

# Metricの順序を指定
data_plot$Metric <- factor(data_plot$Metric, levels = c("Degrees of Freedom", "Chi-square Value", "p-value"))

# χ²値、p値、自由度の比較用バープロットの作成
p <- ggplot(data_plot, aes(x = Test, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  scale_fill_brewer(palette = "Set2", name = "") +
  labs(x = "Dataset", y = "Value", fill = "") +
  facet_wrap(~ Metric, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom", 
        plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold")) +
  ggtitle("Comparison of 3x3 and 2x2 Datasets")

# バープロットの表示
p
```

自由度はχ²検定の結果（χ²値とp値）に以下のように影響を与えます：

- **χ²値**：自由度が増えると、χ²値の範囲（すなわち、可能な最小値と最大値）も増えます。これは、より多くのセル（つまり自由度が高い）を持つテーブルでは、観測された値と期待される値との間により大きな差が生じる可能性が高まるためです。

- **p値**：p値は、観測された（またはより極端な）データが、帰無仮説が真であるという前提のもとで生じる確率を示します。自由度が増えると、χ²分布の形状が変わり（具体的には、分布が右にシフトし、広がりが大きくなります）、これによりp値も変化します。特定のχ²値が与えられたとき、自由度が高いほどそのχ²値を得る確率は高くなり、したがってp値は大きくなります。

# 3. χ²検定

χ²検定は、2つ以上のカテゴリカルデータ間の独立性や、一組の観測データが特定の理論的な分布に従っているかどうかを検定するための統計手法です。これはカテゴリカルなデータに対する統計的検定の一つで、観測された頻度分布が期待される頻度分布と有意に異なるかどうかを判断することが目的です。

## χ²検定の種類

χ²検定は主に以下の3つの目的で使用されます：

1. **適合度検定**：観測されたデータの分布が予想される特定の理論的な分布に適合するかどうかを評価します。
2. **独立性検定**：2つのカテゴリカル変数が互いに独立しているか、関連しているかを調べます。
3. **同質性の検定**：異なる群間でカテゴリカルデータの分布が同じであるかどうかを検定します。

## χ²検定の手順

1. **問題の理解と仮説の設定**:
    - 分析の目的を明確にし、適切なχ²検定（適合度検定、独立性検定、または同質性検定）を選択します。
    - 帰無仮説（H0）と対立仮説（H1）を設定します。
      - 適合度検定
        - **帰無仮説（H0）**：観測された頻度分布は期待される頻度分布に適合する。
        - **対立仮説（H1）**：観測された頻度分布は期待される頻度分布に適合しない。
      - 独立性検定
        - **帰無仮説（H0）**：2つのカテゴリカル変数は独立である。
        - **対立仮説（H1）**：2つのカテゴリカル変数は独立ではない。
      - 同質性の検定
        - **帰無仮説（H0）**：異なる群間でのカテゴリカルデータの分布は同じである。
        - **対立仮説（H1）**：少なくとも1つの群でカテゴリカルデータの分布が異なる。
2. **前提条件の検証**:
    - サンプルデータはランダムに選ばれているか？
    - データはカテゴリカルまたは順序尺度か？
    - 各カテゴリの観測値は独立しているか？
    - 各カテゴリの期待度数は5以上か？（もし期待度数が5未満のセルがある場合は、Yatesの補正やフィッシャーの正確検定を検討する）

3. **χ²統計量の計算**:
    - χ²値は、観測された頻度と期待される頻度との間の差を考慮して計算されます。

4. **p値の計算**:
    - χ²分布表または統計ソフトウェアを使用し、算出されたχ²値と自由度（通常は「カテゴリ数 - 1」）に基づきp値を計算します。
    - χ²検定の結果を報告する際には、χ²値、自由度（分析の柔軟性を示す要素）、そしてp値（結果が偶然から生じた可能性）を含めるのが一般的です。
    
5. **効果量の計算の計算**:
    - χ²検定の結果だけでなく、その検定結果がどれほど実質的な影響を持つのかを示す効果量を評価することも重要です。
    - 効果量の計算方法はχ²検定の種類によって異なります:
       - 1変量のχ²検定（適合度の検定）: Cohenのw
       - 2変量のχ²検定（独立性の検定）: CramerのV
       - フィッシャーの直接確率検定: オッズ比またはリスク比
       - マクネマー検定: マクネマーのオッズ比
       - 同質性の検定: 標準化された平均の差（Cohenのd）や相関（r）

6. **結果の解釈**:
    - χ²検定の結果は、χ²値、自由度、p値、そして効果量（例えばCramer's V）を用いて報告されます。p値が有意水準（通常は0.05）以下であれば、帰無仮説を棄却し、観測された頻度分布と期待される頻度分布との間に有意な差があると結論づけます。
    - p値が所定の有意水準より大きい場合、帰無仮説が採用されます。
    - 効果量が大きいと、観測された変数間の関連性が強いことを示します。逆に、効果量が小さいと、関連性が弱いか、もしくは無関係であることを示します。これは、p値が有意であっても、その関連性が実際には弱い、つまり「統計的に有意だが実質的には無意味」である可能性を示しています。

以下に、χ²検定の使用に際して考慮すべきいくつかのポイントを示します：

- χ²検定はカテゴリカルデータに対してのみ適用可能です。連続データにχ²検定を適用することは不適切です。
- 期待度数が極端に小さい（通常5未満）場合、χ²検定の結果の信頼性は低下します。このような状況では、データの再分類を行うか、別の統計的手法を検討する必要があります。
- χ²検定は、サンプルデータが母集団から無作為に選択されることを前提としています。これを満たしていない場合、検定結果は偏っている可能性があります。
- χ²検定は、群間の差異が存在するかどうかを判断するのに有用ですが、その差異がどれほど意義深いか（効果量）については判断しないため、効果量の評価も重視する必要があります。
- χ²検定は帰無仮説の正しさを評価しますが、帰無仮説が棄却された理由を特定するものではありません。帰無仮説が棄却された場合、その理由を探るために追加の分析が必要となります。


# 4. 1変量のχ²検定（適合度の検定）

## 理論

1変量のχ²検定（適合度の検定）は、観測されたデータの分布が特定の理論的な分布（一般には、帰無仮説で述べられた期待される結果に基づく分布）に合致しているか否かを評価する手法です。同時に、効果量を用いることで、統計的な有意性だけでなく、結果の大きさや重要性も評価します。


χ²値は以下の公式に従って計算されます：

\[ \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \]

ここで、

- \(O_i\)はi番目のカテゴリの観測された頻度、
- \(E_i\)はi番目のカテゴリの期待される頻度、

を示しています。

このχ²値は観測頻度と期待頻度間の差異の大きさを統計的に評価します。各カテゴリで観測頻度と期待頻度の差を二乗し、それを期待頻度で割ります。これにより各カテゴリにおける差異の相対的な大きさが求まり、それらを全て足し合わせることでχ²値を算出します。

χ²値の大きさは、観測データが期待値からどれだけ逸脱しているかを示します。この値が大きければ大きいほど、観測データは期待値から大きく逸脱していると解釈されます。これは観測データに何らかの効果が存在する可能性を示唆します。

効果量としては、Cohenのwが一般的に用いられます。Cohenのwの計算式は次のようになります：

\[ w = \sqrt{\frac{\chi^2}{N}} \]

ここで、

- \(\chi^2\)はχ²値、
- \(N\)は全サンプル数、

を示しています。

Cohenのwはカイ二乗統計量を全サンプル数で正規化し、その結果の平方根を計算します。これにより、標本サイズの影響を排除しています。

Cohenのwは標準化された効果量として位置づけられ、統計的な有意性だけでなく、その結果が実質的にどれほど重要であるか、つまり効果の大きさを評価するために使用されます。この指標は観測データが期待分布からどれだけ逸脱しているかを示し、その逸脱度の大きさを理解するために利用されます。

公平な6面のサイコロを60回投げるシナリオを考えてみましょう。理論的には、各面が出る回数は10回（60回 / 6面）と期待できます。しかし、実際の結果は必ずしも10回とは限りません。その差異が大きいほどχ²統計量は大きくなります。

p値が特定の閾値（通常は0.05）以下であれば、観測データが期待分布から統計的に有意に異なると判断されます。

以下に、Rを用いたχ²検定の例と効果量の計算を示します。

```{r, error=TRUE, include=TRUE}
# 乱数生成の初期値を設定
set.seed(123)

# 1から6までの数字（サイコロの目）をランダムに60回選ぶ
# 選択は置換あり（選ばれた数値を再度選ぶことが可能）
# 選択された数値を因子として扱う
# 各因子レベル（サイコロの目）が選ばれた回数（頻度）を集計
roll_results <- table(factor(sample(1:6, size = 60, replace = TRUE), levels = 1:6))

# サイコロを60回投げた結果を表示
print(roll_results)

# 各面が出る期待頻度を定義
# 各面が出る期待値は10回
expected_frequencies <- rep(10, 6)

# χ²検定を実行
# 検定は実際の結果（roll_results）と期待頻度（expected_frequencies）を比較
test_results <- chisq.test(roll_results, p = expected_frequencies / 60)

# χ²検定の結果を表示
print(test_results)

# 効果量 (Cohen's w) を計算
effect_size <- sqrt(test_results$statistic / sum(roll_results))
print(effect_size)
```

上記のコードでは、公平な6面のサイコロを60回投げる結果をシミュレートしています。その後、期待頻度（各面が10回出ると期待される）と観測頻度を用いてχ²検定を実行します。p値を確認することで、観測データが期待する分布（この場合、各面が等確率で出るとする分布）から統計的に有意に異なるかどうかを判断します。最後に、効果量（Cohenのw）を計算し、検定結果の大きさを評価します。

## 実践

Rを用いてχ²適合度検定を実行する具体的な解析手順を示します。

### 例示の背景

この例では、幼稚園の子供たちが「幼稚園は好きですか？」という質問に「はい」または「いいえ」で答える場合を想定します。

### 仮説の設定

- 理論的仮説：特定の年齢層の子供たちが「幼稚園は好きですか？」という質問に「はい」または「いいえ」で答える確率は50%ずつである。

- 統計的仮説：
  - 帰無仮説 (H0): 観測された分布は期待される分布（この場合は、はいといいえの確率が等しい）に従っている。
  - 対立仮説 (Ha): 観測された分布は期待される分布に従っていない。

### データの準備

```{r, error=TRUE, include=TRUE}
# CSVファイル 'chap4sample1.csv' を読み込みます。結果はデータフレームx1に格納されます。
x1 <- read.csv("chap4sample1.csv", header=T)

# データフレームx1の先頭6行を表示します。これにより、データの概観を把握します。
head(x1)
```

```{r, error=TRUE, include=TRUE}
# Answer列のデータを因子型に変換します。これは統計分析でよく使用されるデータ型で、カテゴリーデータを扱うのに適しています。
# labels引数を用いて、0を'No'、1を'Yes'に対応させます。
x1$Answer <- factor(x1$Answer, labels=c('No','Yes')) 

# 変換後のAnswer列のデータを表示します。これにより、変換が正しく行われたことを確認します。
print(x1$Answer)
```

### 前提条件の検証

χ²検定の前提条件は、各カテゴリの期待頻度が5以上であることです。

```{r, error=TRUE, include=TRUE}
# Answer列のデータを用いて、'No'と'Yes'の回答数を集計します。結果はクロス集計表x1tableに格納されます。
x1table <- table(x1$Answer)

# クロス集計表x1tableを表示します。これにより、各カテゴリの頻度を確認します。
print(x1table) 
```

### Rでの実行

```{r, error=TRUE, include=TRUE}
# chisq.test関数を用いてχ²適合度検定を実行します。観測データが期待する分布にどの程度適合しているかを評価します。結果はtest_resultsに格納されます。
test_results <- chisq.test(x1table)

# テスト結果を表示します。これにより、p値やχ²統計量などの情報を得ます。
print(test_results)
```

```{r, error=TRUE, include=TRUE}
# 効果量 (Cohen's w) を計算します。これは検定結果の効果の大きさを評価するための指標です。
effect_size <- sqrt(test_results$statistic / sum(x1table))

# 効果量 (Cohen's w) を表示します。これにより、結果の解釈に役立つ情報を得ます。
print(effect_size)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 10, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "blue") +
  labs(x = "Chi-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# Chi-squaredの値
chi_squared <- 5

# Chi-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = chi_squared, linetype = "dashed", colour = "red") + 
  annotate("text", x = chi_squared, y = 3, 
           label = paste("Chi-squared =", chi_squared, "(α = 0.02535)"), 
           vjust = 0, hjust = 0.1, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "green") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 0, hjust = 0.9, colour = "black")

# プロットを表示
print(p)
```

p値が0.05より小さい場合、観測されたデータが期待される分布と有意に異なると解釈されます。

### 視覚化

```{r, error=TRUE, include=TRUE}
# pie関数を用いて、クロス集計表のデータを利用して円グラフを作成します。円グラフは 'No'と'Yes'が全体に占める割合を視覚的に表示します。
pie(x1table, main="Pie Chart of Answers", col=c("lightblue", "pink"))
```

```{r, error=TRUE, include=TRUE}
# barplot関数を用いて、クロス集計表のデータを利用して棒グラフを作成します。棒グラフは各カテゴリ（'No'と'Yes'）の観測数を直観的に比較するのに適しています。
barplot(x1table, main="Number of 'No' and 'Yes'", xlab="Answer", ylab="Count", col=c("lightblue", "pink"))
```

### 結果の解釈

この解析結果から、χ²統計量が5、自由度が1、p値が0.02535という結果が得られました。通常、p値が0.05以下であれば、統計的に有意と判断され、帰無仮説を棄却します。今回のp値は0.02535であるため、0.05より小さく、統計的に有意です。したがって、「はい」または「いいえ」の回答の分布は、期待される分布（「はい」と「いいえ」の確率が均等）と有意に異なると結論付けることができます。

さらに、効果量（Cohen's w）が0.5と計算されました。効果量は、結果の「大きさ」を定量化するための統計的な手段であり、p値だけでは捉えられない情報を提供します。Cohen's wの値は0から無限大までの範囲を持ち、値が大きいほど効果の大きさが大きいことを示します。このケースでは、Cohen's wが0.5という結果は、回答の分布が期待される均等な分布から中程度にずれていることを示しています。しかし、ここでのCohen's wの解釈は一般的なガイドラインに過ぎず、実際は具体的な研究領域の先行研究で報告された効果量と比較する必要があります。

### 結果の報告

「特定の年齢層の子どもたちに対して"幼稚園は好きですか？"という質問を行い、その回答が均等に分布しているかどうかをχ²適合度検定で評価した。この分析は、回答の分布が均等であるという仮説を支持しなかった, χ²(1) = 5.00, p = .03。さらに、効果量（Cohen's w）は0.5であり、回答の分布は期待される均等な分布から中程度にずれていた（ただし、この効果量の解釈は一般的なガイドラインに過ぎず、実際の解釈には関連する先行研究との比較が必要です）。これらの結果は、子どもたちの幼稚園に対する感情が一様でない可能性を示唆している。」

# 5. 2変量のχ²検定（独立性の検定）

2変量のχ²検定は、二つのカテゴリカル変数が互いに独立、つまり一方が他方に影響を与えないかどうかを評価する統計的手法です。

## 理論

χ²検定の帰無仮説は、「二つの変数は独立である」です。つまり、一つの変数の値がもう一つの変数の値に影響を与えないという仮説を検証します。

χ²統計量は次の式で求められます:

\[\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}\]

ここで、

- \(O_{ij}\)はi番目とj番目のカテゴリの組み合わせの観測頻度、
- \(E_{ij}\)はi番目とj番目のカテゴリの組み合わせの期待頻度、

を示しています。

帰無仮説（2つの変数が独立である）が正しい場合、χ²統計量は小さな値になることが期待されます。逆に、χ²統計量が特定の閾値を超えた場合、帰無仮説は棄却され、2つの変数間に何らかの関連性が存在するとされます。

χ²検定は、2つの変数の独立性を評価するためのものですが、これらの変数間の関連性の強さを定量的に評価するためには別の指標が必要です。その指標としてよく用いられるのがフィルの係数とCramerのVです。

フィルの係数は2x2クロス表、つまり2つの二項変数間の相関を測定します。その計算式は以下の通りです。

\[\Phi = \sqrt{\frac{\chi^2}{n}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)はサンプルサイズ（観測数）

をそれぞれ表します。

一方、CramerのVは、2つのカテゴリカル変数間の関連性の度合いを0から1までの値で表したもので、2x2表だけでなく、より大きな次元（2×2以上）のクロス表に対して使用することができます。値が0であれば変数間には全く関連性がないことを示し、1であれば変数間が完全に関連していることを示します。

CramerのVの計算式は次の通りです：

\[V = \sqrt{\frac{\chi^2}{n(k-1)}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)はサンプルサイズ（観測数）、
- \(k\)は二つの変数のカテゴリの数のうち少ない方、

をそれぞれ表します。

CramerのVは、これら3つの要素を組み合わせたものであり、χ²統計量が大きければ大きいほど、またサンプルサイズが小さければ小さいほど、Vの値が大きくなります。一方、カテゴリの数が増えると、Vの値は減少します。これはカテゴリの数が増えると、各カテゴリ間の関連性が一般的に弱くなることを反映しています。

これら全ての要素が組み合わさることで、CramerのVは2つのカテゴリカル変数間の関連性の強さを0から1の範囲で表現しています。

以下に、Rを用いてχ²検定を実行し、関連性の強さをCramerのVで評価する例を示します：

```{r, error=TRUE, include=TRUE}
# 再現性を確保するためのシード値を設定
set.seed(123) 

# それぞれが3つのカテゴリを持つ2つのカテゴリカル変数のデータを生成
var1 <- sample(c("A", "B", "C"), size = 100, replace = TRUE)
var2 <- sample(c("X", "Y", "Z"), size = 100, replace = TRUE)

# 2つの変数のクロス集計表を作成
data <- table(var1, var2)

# χ²検定を実行
test_result <- chisq.test(data)

# χ²値を表示
test_result$statistic

# p値を表示
test_result$p.value

# CramerのVを計算
V <- sqrt(test_result$statistic / (sum(data) * (min(dim(data)) - 1)))

# CramerのVを表示
V
```

このコードは、2つのカテゴリカル変数からなるデータセットを生成し、その後でχ²検定を実行して2つの変数間の独立性を評価します。出力されるp値を見て、変数間に統計的に有意な関連性があるかどうかを判断します。そして、CramerのVを計算することで関連性の強さを評価します。変数がそれぞれ複数のカテゴリを持つため、この例ではフィルの係数ではなくCramerのVが用いられています。

## 実践

Rを用いてχ²独立性検定を実行する具体的な解析手順を示します。

### 例示の背景

この例では、小学校の児童が授業が面白いかどうかについての意見（「同意」または「不同意」）と、その児童の性別（「男性」または「女性」）との間に関連性があるかどうかを調査します。

### 仮説の設定

- 理論的仮説：児童の性別は、授業に対する意見に影響を及ぼす。
- 統計的仮説
  - 帰無仮説 (H0): 性別と授業に対する意見の間には関連性がない（独立である）。
  - 対立仮説 (Ha): 性別と授業に対する意見の間には関連性がある。

### データの準備

まずは、CSVファイル 'chap4sample2.csv' を読み込み、データの構造を確認します。

```{r, error=TRUE, include=TRUE}
# CSVファイルの読み込み
x2 <- read.csv("chap4sample2.csv", header=T) 

# データの一部を表示
head(x2)
```

```{r, error=TRUE, include=TRUE}
# データ構造の確認
str(x2)
```

### 前提条件の検証

χ²検定を実行する前に、各カテゴリの期待頻度が5以上であることを確認します。このためにクロス集計表を作成します。

```{r, error=TRUE, include=TRUE}
# クロス集計表の作成
x2matrix <- with(x2, table(gender, answer))

# 表示
x2matrix
```

### Rでの実行

以下のコードでχ²独立性検定を実行し、結果を表示します。

```{r, error=TRUE, include=TRUE}
# χ²独立性検定の実行
result <- chisq.test(x2matrix) 

# 結果の表示
print(result)

# Cramer's Vの計算
V <- sqrt(result$statistic / (sum(x2matrix) * (min(dim(x2matrix)) - 1)))

# Cramer's Vの表示
print(V)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 10, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "blue") +
  labs(x = "X-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# X-squaredの値
x_squared <- 6.416

# X-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = x_squared, linetype = "dashed", colour = "red") + 
  annotate("text", x = x_squared, y = 3, 
           label = paste("X-squared =", x_squared, "(α = 0.01131)"), 
           vjust = 1, hjust = 0.3, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "green") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 1, hjust = 0.7, colour = "black")

# プロットを表示
print(p)
```

### 視覚化

```{r, error=TRUE, include=TRUE}
barplot(x2matrix, beside = TRUE, col = c("lightblue", "salmon"), 
        legend.text = rownames(x2matrix), ylim = c(0, max(x2matrix)*1.2), 
        ylab = "Counts", xlab = "Opinions", main = "Chi-Square Test of Independence")
```

### 結果の解釈

p値は0.01131であり、これは一般的に用いられる有意水準0.05を下回るものです。したがって、統計的に有意と判断し、帰無仮説（性別と授業評価の間に関連性がない）を棄却し、対立仮説（性別と授業評価の間に関連性がある）を受け入れることができます。これは性別と授業評価との間に有意な関連性があり、男女の性別が授業評価に影響を及ぼす可能性を示しています。

加えて、クラメールのVは0.4005であり、これは性別と授業評価の間に中程度の関連性があることを示唆しています。ただし、この効果量の解釈は一般的なガイドラインに過ぎず、実際の解釈には関連する先行研究との比較が必要であることを忘れてはなりません。特定の文脈や研究領域における関連性の大きさが何を意味するのかを理解するためには、以前の研究結果と比較することが重要です。

### 結果の報告

「χ²独立性検定を使用して、小学生の性別（男性、女性）と授業評価（同意、不同意）の間の関連性を評価した。検定結果は、χ²(1) = 6.416, p = .011、となり、性別と授業評価の間に有意な関連性が存在することを示している。クラメールのVの値は0.4005であり、性別と授業評価の間に中程度の関連性があることを示している（ただし、この効果量の解釈は一般的なガイドラインに過ぎず、具体的な解釈は先行研究との比較を必要とします）。したがって、性別は授業評価に影響を及ぼす可能性があることが示唆された。」

## χ²検定とフィッシャーの正確確率検定の比較

フィッシャーの正確確率検定は特にサンプルサイズが小さかったり、期待頻度が一部のカテゴリで低い場合に、χ²検定よりも精度の高い結果を提供します。

### データの準備

ここでは、同じデータセットを用いてχ²検定とフィッシャーの正確確率検定の結果を比較します。それぞれの検定結果がどれほど異なるのか、そしてその結果がどのように解釈できるのかを理解することが目的です。

### Rでの実行

フィッシャーの直接確率検定はRの fisher.test() 関数を使用して計算します。

```{r, error=TRUE, include=TRUE}
# フィッシャーの正確確率検定の実行
fisher_result <- fisher.test(x2matrix) 

# 結果の表示
print(fisher_result)
```

### 結果の解釈

フィッシャーの正確確率検定の結果、p値は0.01039となり、これは一般的に用いられる有意水準0.05を下回ります。したがって、性別と授業評価の間には統計的に有意な関連性が存在すると結論付けられます。また、オッズ比（odds ratio）は6.614723と推定され、その95%信頼区間は1.457116から35.737819までとなりました。オッズ比は効果量を表す一種の指標であり、これは性別の影響が授業評価に対して6.614723倍になることを示しています。これは性別が授業評価に大きな影響を及ぼす可能性があることを示唆しています。

しかし、オッズ比やその信頼区間の解釈には注意が必要です。信頼区間が広い（1.457116から35.737819）場合、効果量の不確実性が高いことを示します。つまり、性別が授業評価に及ぼす影響は比較的大きいかもしれないが、その程度ははっきりしないということです。

### χ²検定との比較

フィッシャーの正確確率検定とχ²検定の結果は、両方とも性別と授業評価の間に有意な関連性が存在することを示しています。ただし、フィッシャーの正確確率検定はさらにオッズ比とその信頼区間を提供し、効果量の評価に役立ちます。

フィッシャーの正確確率検定によるp値はχ²検定によるものよりもわずかに低く、いずれも一般的な有意水準0.05を下回っています。したがって、どちらの検定も性別と授業評価の間に有意な関連性があると結論付けています。

ただし、サンプルサイズが小さい場合や期待頻度が低い場合は、フィッシャーの正確確率検定がχ²検定よりも適切な選択となる可能性があることを覚えておいてください。

# 6. マクネマー検定（対応のある二項的なデータの分析）

マクネマー検定は、対応のある二項的なデータ（成功/失敗、はい/いいえ等）を分析するためのノンパラメトリックな統計手法であり、カテゴリカルな変数間の関連性を評価します。これはχ²検定の一種であり、対応のあるペアデータに特に適用されます。

## 理論

マクネマー検定の帰無仮説は、「二つのカテゴリーの出現頻度は等しい」つまり、一方の変数の状態がもう一方の変数の状態に影響を及ぼさないというものです。

マクネマー検定は2x2のクロス集計表に基づいて計算を行います。具体的には、以下のような表を作成します:

```{r, error=FALSE, include=TRUE}
# matrix関数を用いて2行2列の行列を作成します。
data <- matrix(c("a", "b", "c", "d"), nrow = 2, byrow = TRUE,
               dimnames = list("Condition B" = c("Success", "Failure"),
                               "Condition A" = c("Success", "Failure")))

# 作成した行列を表示します。
print(data)
```

ここで、a、b、c、dはそれぞれの条件下で成功または失敗した被験体の数を示しています。そして、マクネマー検定の統計量は以下の式で計算されます:

\\[χ² = (|b - c| - 1)² / (b + c)\\]

このχ²の値が大きければ大きいほど、帰無仮説（条件Aと条件Bが同等の影響を及ぼす）が棄却されやすくなります。

以下に、Rを用いた具体的な例を示します:

```{r, error=TRUE, include=TRUE}
# 2行2列のクロス集計表を作成します。
data <- matrix(c(20, 30, 25, 25), nrow = 2)

# 行と列の名前をそれぞれ"条件B: 成功", "条件B: 失敗"、"条件A: 成功", "条件A: 失敗"と設定します。
rownames(data) <- c("条件B: 成功", "条件B: 失敗")
colnames(data) <- c("条件A: 成功", "条件A: 失敗")

# 作成したクロス集計表を出力します。
print(data)
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。この検定は、2x2のクロス集計表に対し、関連性または一貫性の評価に使用されます。
test_results <- mcnemar.test(data)

# マクネマー検定の結果を出力します。
print(test_results)
```

この例では、条件Aと条件B下での成功と失敗の頻度に差があるかどうかを評価しています。マクネマー検定のp値により、二つの条件間に統計的に有意な差異が存在するかどうかを判断することが可能です。

## 実践

### 例示の背景

以下の例示では、幼稚園の子供たちが2つの異なるストーリー（「許す」または「許さない」）を聞いた後、「一緒に遊ぶ」か「別々に遊ぶ」かを選択するシチュエーションについて考察します。

### 仮説の設定

このシナリオの場合、帰無仮説（H0）と対立仮説（H1）は次のように設定されます:

- H0: ストーリーは子供たちの選択（一緒に遊ぶか、別々に遊ぶか）に影響を与えない。
- H1: ストーリーは子供たちの選択（一緒に遊ぶか、別々に遊ぶか）に影響を与える。

### データの準備

```{r}
# "chap4sample3.csv"という名前のCSVファイルをread.csv関数を用いて読み込み、その結果を"data"という変数に代入します。
data <- read.csv("chap4sample3.csv", header=TRUE)

# "data"データフレームの最初の数行をhead関数を用いて表示します。これによりデータの一部を確認できます。
head(data)
```

```{r, error=TRUE, include=TRUE}
# "data"データフレームの構造をstr関数を用いて確認します。これによりデータの各列のタイプ、列数、行数などを確認できます。
str(data)
```

### 前提条件の検証

マクネマー検定を使用する前に、必要な前提条件を確認する必要があります:

- データは対応のある二項的なデータ（成功/失敗、はい/いいえなど）であること。
- 各サブグループ（ここでは、各ストーリー）内の観測値は互いに独立であること。

### Rでの実行

```{r, error=TRUE, include=TRUE}
table_data <- table(Forgiveness = data$Forgive, Rejection = data$Reject)
table_data
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。correct=TRUEオプションを指定して、イェーツの補正を適用します。
# イェーツの補正とは二項分布が正規分布に近似するために行われる補正のことで、2×2の分割表のχ²検定に用いられます。特にサンプルサイズが小さい場合に有用です。
test_results <- mcnemar.test(table_data, correct=TRUE)

# マクネマー検定の結果をprint関数を用いて表示します。
print(test_results)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 25, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "blue") +
  labs(x = "McNemar's Chi-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# McNemar's Chi-squaredの値
mcnemars_chi_squared <- 16

# McNemar's Chi-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = mcnemars_chi_squared, linetype = "dashed", colour = "red") + 
  annotate("text", x = mcnemars_chi_squared, y = 3, 
           label = paste("McNemar's Chi-squared =", mcnemars_chi_squared, "(α = 6.334e-05)"),
           vjust = 4, hjust = 0.4, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "green") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 4, hjust = 0.4, colour = "black")

# プロットを表示
print(p)
```

### 視覚化

次のRコードは、「許す」ストーリーと「許さない」ストーリーのそれぞれについて、「一緒に遊ぶ」選択と「別々に遊ぶ」選択の回数を示す棒グラフを描くものです。

```{r, error=TRUE, include=TRUE}
# 必要なライブラリの読み込み
library(ggplot2)

# データの集計
data_agg <- table(data)

# 集計結果をデータフレームに変換
data_df <- as.data.frame(data_agg)
names(data_df) <- c("Story", "Choice", "Count")

# 棒グラフの描画
ggplot(data = data_df, aes(x = Story, y = Count, fill = Choice)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("blue", "orange")) +
  labs(x = "Story", y = "Number of Children", fill = "Choice") +
  theme_minimal() +
  theme(text = element_text(size = 15))
```

### 結果の解釈

今回の解析の結果、χ²統計量は16、自由度は1、そしてp値は6.334e-05でした。通常、p値が0.05未満の場合、統計的に有意と判断され、帰無仮説が棄却されます。今回のp値は6.334e-05であり、0.05を大幅に下回っているため、統計的に有意と判断できます。これは、「一緒に遊ぶ」と「別々に遊ぶ」の選択には偶然以上の関連性があることを意味します。

### 結果の報告

「子どもたちはストーリーの結果に基づき、「一緒に遊ぶ」か「別々に遊ぶ」かを選び、その選択が偶然に従って分布しているかどうかを確認するために、イェーツの補正を用いたマクネマー検定を実行した（McNemar's χ²(1) = 16, p < .001）。この結果から、選択が偶然によるものという帰無仮説は棄却された。つまり、ストーリーの結果が子どもたちの「一緒に遊ぶ」か「別々に遊ぶ」の選択に統計的に有意な影響を与えたと推測できる。」

# 7. χ²検定の同質性（同質性の検定）

χ²検定の同質性は、カテゴリカルデータが複数のグループ間で均等に分布しているかどうかを評価する統計手法です。この手法は、「2 x C」、「R x 2」、および「R x C」の形式で使用され、各観測グループ間のカテゴリカルデータの分布が統計的に同質（同じ）かどうかを判定します。

## 「2 x C」のχ²検定の同質性

「2 x C」形式のχ²検定は、2つのカテゴリがC個のグループに分けられる場合に使用されます。たとえば、5歳と10歳の子供たちが3つの異なる学習スタイル（視覚的、聴覚的、運動性）にどのように分かれるかを調査する場合などです。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep("5歳", 150), rep("10歳", 150))
learning_style <- c(rep(c("視覚的", "聴覚的", "運動性"), length.out = 150),
                    rep(c("視覚的", "聴覚的", "運動性"), length.out = 150))

# データフレームを作成
data_2xC <- data.frame(age_group, learning_style)

# クロス集計表を作成
cross_table <- table(data_2xC)
cross_table
```

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_2xC <- chisq.test(cross_table)

# 結果を表示
print(result_2xC)
```

サンプルサイズが小さい場合は、Fisherの正確性検定を使用することで、より信頼性のある結果を得ることができます。

```{r, error=TRUE, include=TRUE}
# Fisherの正確性検定を実行
result_fisher <- fisher.test(cross_table)

# 結果を出力
print(result_fisher)
```

## 「R x 2」のχ²検定の同質性

「R x 2」形式のχ²検定は、R個のグループが2つのカテゴリに分けられる場合に使用されます。例えば、一親家庭、両親家庭、祖父母と同居の3つの家庭環境の子供たちが、学業成績が平均以上か平均未満かでどのように分かれるかを調査する場合などです。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
family_environment <- rep(c("一親家庭", "両親家庭", "祖父母と同居"), each = 50)
academic_performance <- rep(c("平均以上", "平均未満"), each = 75)

# データフレームを作成
data_Rx2 <- data.frame(family_environment, academic_performance)

# クロス集計表を作成
cross_table <- table(data_Rx2)
print(cross_table)
```

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_Rx2 <- chisq.test(cross_table)

# 結果を表示
print(result_Rx2)
```

## 「R x C」のχ²検定の同質性

R x C」形式のχ²検定は、R個のグループがC個のカテゴリに分けられる場合に使用されます。これは、より複雑なデータセットを分析する際に利用されます。たとえば、異なる年齢層（5歳、10歳、15歳）の子供たちが3つの異なる学習スタイル（視覚的、聴覚的、運動性）にどのように分かれるかを調査する場合などです。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep(c("5歳", "10歳", "15歳"), each = 100))
learning_style <- c(rep(c("視覚的", "聴覚的", "運動性"), length.out = 300))

# データフレームを作成
data_RxC <- data.frame(age_group, learning_style)

# クロス集計表を作成
cross_table <- table(data_RxC)
cross_table
```

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_RxC <- chisq.test(cross_table)

# 結果を表示
print(result_RxC)
```

## 「2 x C」、「R x 2」、および「R x C」の違い

これらの形式は、χ²統計量を用いて各カテゴリの分布が異なるグループ間で同じであるかどうかを評価します。「2 x C」は2つのカテゴリが複数のグループに分けられる場合、「R x 2」は複数のグループが2つのカテゴリに分けられる場合、「R x C」はR個のグループがC個のカテゴリに分けられる場合にそれぞれ使用されます。

これらの手法は、特に発達心理学のような分野で重要です。子供たちの学習スタイルが年齢層によって異なるかどうかを調査する際などに用いられます。サンプルサイズが小さい場合は、Fisherの正確性検定など他の手法を検討することで、より確実な結果を得ることが可能です。

# 8. 多重比較

統計解析では、複数の比較を一度に行うことを多重比較と呼びます。しかし、一度に多くの比較を行うと、偶然による偽陽性（存在しない効果を検出する誤り）のリスクが増大します。これを緩和するために、以下の補正方法が提案されています。

## 多重比較の種類

1. ボンフェローニ補正 (Bonferroni correction): 各比較の有意性レベル（p値）を全体の比較の数で割ることで偽陽性のリスクを減らしますが、厳格すぎるために偽陰性のリスクも増大します。

2. ホルム補正 (Holm correction): ボンフェローニ補正を改良し、全てのp値を小さい順に並べ、それぞれにボンフェローニ補正を適用します。これにより偽陽性のリスクを抑えつつ、偽陰性のリスクも低減します。

3. ベンジャミニ＆ホッホベルク法 (Benjamini & Hochberg method): 偽陽性の「割合」を制御する方法で、全てのp値を小さい順に並べ、それぞれのp値に（その順位/全比較数）*目標FDRを掛けた値を新たなp値とします。

4. チューキーのHSD法 (Tukey's HSD method): ANOVA（分散分析）後の多重比較に有効で、全てのペア間の比較を行います。

## 独立性の検定と多重比較補正の使用例

ここでは、3つの異なる教育介入（A、B、C）が特定の行動（行動1、行動2）の発生にどのように関連しているかをχ²検定で評価し、その結果に対して多重比較補正を適用する例を紹介します。さらに、各教育介入における行動1と行動2の出現率に違いがあるかどうかを検証するために、ペアワイズのχ²検定を適用します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込み
library(pwr)

# 再現可能なランダムな結果を得るためにシードを設定
set.seed(123)

# Intervention列に"A", "B", "C"、Behavior列に"Behavior1", "Behavior2"をランダムに割り当て（全体で300行）
data <- data.frame(
  Intervention = sample(c("A", "B", "C"), 300, replace = TRUE),
  Behavior = sample(c("Behavior1", "Behavior2"), 300, replace = TRUE)
)
head(data)
```

```{r, error=TRUE, include=TRUE}
# データフレームから介入と行動についてのクロス集計表を作る
table(data$Intervention, data$Behavior)
```

```{r, error=TRUE, include=TRUE}
# それをχ²検定に渡す
chisq_res <- chisq.test(table(data$Intervention, data$Behavior))

# p値を取得
p_value <- chisq_res$p.value

# ボンフェローニ補正、ホルム補正、ベンジャミニ＆ホッチベルク補正（BH補正）を適用してp値を補正
bonferroni <- p.adjust(p_value, method = "bonferroni")
holm <- p.adjust(p_value, method = "holm")
BH <- p.adjust(p_value, method = "BH")

# 補正後のp値を表示
data.frame(Bonferroni = bonferroni, Holm = holm, BH = BH)
```

```{r, error=TRUE, include=TRUE}
# 各教育介入における行動1と行動2の出現率に違いがあるかどうかを検証するために、ペアワイズのχ²検定を適用
pairs <- combn(unique(data$Intervention), 2)
pairwise_chisq <- apply(pairs, 2, function(x) {
  subdata <- data[data$Intervention %in% x, ]
  chisq_res <- chisq.test(table(subdata$Intervention, subdata$Behavior))
  chisq_res$p.value
})

# 各ペア間のχ²検定のp値を補正
bonferroni_pairwise <- p.adjust(pairwise_chisq, method = "bonferroni")
holm_pairwise <- p.adjust(pairwise_chisq, method = "holm")
BH_pairwise <- p.adjust(pairwise_chisq, method = "BH")

# 補正後のペアワイズp値を表示
data.frame(Pairs = t(pairs), Bonferroni = bonferroni_pairwise, Holm = holm_pairwise, BH = BH_pairwise)
```

この結果から、各教育介入が行動1と行動2の出現にどのように影響するか、そして介入間で行動の出現率に違いがあるかどうかを多重比較補正を用いて評価できます。

## 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例

一元配置分散分析（ANOVA）は、一つ以上の要因が群間での平均値の差異を引き起こすかどうかを評価するための統計的手法です。さらに、チューキーのHSD法を利用することで、具体的な群間の差を明らかにすることができます。ここでは、これらの方法を用いて、特定の介入がスコアにどのような影響を及ぼすかを調査する例を示します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(agricolae)

# 再現可能なランダムな結果を得るために乱数シードを設定
set.seed(123)

# データフレームを作成。Intervention列に"A", "B", "C"を、Score列には異なる平均値と標準偏差をもつ正規分布から抽出したスコアを割り当てる
data <- data.frame(
  Intervention = rep(c("A", "B", "C"), each = 50),
  Score = c(rnorm(50, mean = 80, sd = 10),
            rnorm(50, mean = 85, sd = 10),
            rnorm(50, mean = 90, sd = 10))
)
head(data)
```

```{r, error=TRUE, include=TRUE}
# Intervention列の影響をスコアに対して評価するために一元配置ANOVAを適用する
model <- aov(Score ~ Intervention, data = data)

# ANOVAの結果を表示
summary(model)
```

```{r, error=TRUE, include=TRUE}
# チューキーのHSD法を用いて具体的な群間比較を行う
HSD_result <- HSD.test(model, 'Intervention', group = TRUE)

# 結果を表示
print(HSD_result)
```

この例では、ANOVAを使用して教育介入（A、B、C）が学生のスコアに対してどのような影響を及ぼしているかを評価します。その後、チューキーのHSD法を用いて各介入間のスコアの差を明らかにします。ANOVAの結果にかかわらず、チューキーのHSD法は介入効果の具体的な違いを理解するために用いられます。ただし、ANOVAの結果が非有意の場合、その結果を過度に解釈することは避けるべきです。

## マクネマー検定と多重比較補正の使用例

教育介入方法A、B、Cが子供の行動にどれほど影響を及ぼすかを評価します。それぞれの教育介入についてマクネマー検定を行い、得られたp値に対してボンフェローニ補正、ホルム補正、そしてベンジャミニ＆ホッホベルグ法を適用します。これらの補正は、多重比較によって誤って有意な結果と判断されるリスクを軽減するためのものです。

なお、チューキーのHSD法はANOVAの結果に対する多重比較補正として使用される手法で、マクネマー検定に対しては直接適用することはできません。


```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込み
library(stats)

# 結果の再現性を確保するためのシード設定
set.seed(123)

# 各教育介入方法についてデータ生成
before_A <- sample(c(0, 1), 100, replace = TRUE)
after_A <- sample(c(0, 1), 100, replace = TRUE)
before_B <- sample(c(0, 1), 100, replace = TRUE)
after_B <- sample(c(0, 1), 100, replace = TRUE)
before_C <- sample(c(0, 1), 100, replace = TRUE)
after_C <- sample(c(0, 1), 100, replace = TRUE)

# 各方法についてマクネマー検定の実施
mcnemar_res_A <- mcnemar.test(before_A, after_A)
mcnemar_res_B <- mcnemar.test(before_B, after_B)
mcnemar_res_C <- mcnemar.test(before_C, after_C)

# p値の取得
p_values <- c(mcnemar_res_A$p.value, mcnemar_res_B$p.value, mcnemar_res_C$p.value)

# 各補正法によるp値の調整
bonferroni <- p.adjust(p_values, method = "bonferroni")
holm <- p.adjust(p_values, method = "holm")
BH <- p.adjust(p_values, method = "BH")

# 元のp値と補正後のp値を表示するためのデータフレームを作成
result_df <- data.frame(
  Method = c("A", "B", "C"),
  p_value = p_values,
  p_value_bonferroni = bonferroni,
  p_value_holm = holm,
  p_value_BH = BH
)

# 結果を表示
print(result_df)
```

これらの結果を通じて、各教育介入方法が子供の行動に与える影響の有意性を複数の補正法に基づいて評価することができます。これにより、個々の教育介入方法の効果をより厳密に解釈することが可能になります。

# 参考ページ:

- [統計学の時間 - パラメトリックとノンパラメトリック](https://bellcurve.jp/statistics/course/1562.html)

- [Study Channel - パラメトリックとノンパラメトリック](https://www.study-channel.com/2015/06/parametric-nonparametric-test.html)

- [日経調査研究所 - χ²検定](https://service.nikkei-r.co.jp/glossary/chi-square-test/)

- [Best Biostatistics - 自由度の理解](https://best-biostatistics.com/contingency/degree-freedom.html)

- [統計学の時間 - χ²適合度検定](https://bellcurve.jp/statistics/course/9494.html)
