---
title: "χ²検定の基礎と実践 by 戸田梨鈴"
author: "まとめ by 金山篤志"
date: "2023-06-16"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
  ioslides_presentation:
    toc: true
  word_document:
    toc: true
  beamer_presentation:
    toc: true
    latex_engine: xelatex
  pdf_document:
    toc: true
    latex_engine: xelatex
header-includes:
  - \usepackage{xeCJK}
  - \setCJKmainfont{Hiragino Mincho Pro}
---

```{r, error=TRUE, echo=FALSE}
# これはRのオプション設定コマンドです。CRANのミラーサイトとして"https://cloud.r-project.org/"を指定しています。
# CRANとはComprehensive R Archive Networkの略で、Rのパッケージが保存されているリポジトリです。
options(repos = c(CRAN = "https://cloud.r-project.org/"))

# "ggplot2"というパッケージをインストールします。Rのパッケージは、特定の機能や手法を利用するための一連の関数とデータセットを含んでいます。
# "ggplot2"はグラフィカルなデータ表示に広く使用されるパッケージです。
# "quiet = TRUE"は、インストールの途中経過やメッセージを表示しないようにするオプションです。
install.packages(c("ggplot2"), quiet = TRUE)

# ここで"ggplot2"パッケージを読み込みます。これにより、このパッケージに含まれる関数やデータセットがRセッションで使用可能になります。
# library関数は、パッケージの関数やデータをRの作業環境に読み込むためのものです。
library(ggplot2)
```

目次

1. 概要
2. χ²分布
   - 定義
   - 特性
   - 自由度
3. χ²検定
   - χ²検定の種類
   - χ²検定の手順
4. 1変量のχ²検定（適合度の検定）
   - 理論
   - 実践
5. 2変量のχ²検定（独立性の検定）
   - 理論
   - 実践
   - フィッシャーの正確性検定（標本サイズが小さい場合）
6. マクネマー検定
   - 理論
   - 実践
7. 同質性の検定
   - 理論
   - 実践:「2 x C」のχ²同質性検定
   - 実践:「R x 2」のχ²同質性検定
   - 実践:「R x C」のχ²同質性検定
8. 多重比較
   - 有意水準の調整方法
   - 独立性の検定と多重比較補正の使用例
   - 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例
   - マクネマー検定と多重比較補正の使用例

# 1. 概要

χ²検定は、カテゴリー型のデータ（例：男性か女性、成功か失敗など）の関連性を調べるための統計的手法です。また、実際のデータが理論的な分布とどれだけ合っているかを確かめる際にも使われます。

この検定は、いわゆる「ノンパラメトリック」（無母数）検定として知られており、その特長は以下の通りです：

- **特定の分布を前提としない**： χ²検定では、データが正規分布などの特定の分布に従っている必要がありません。データがどのように分布しているかにかかわらず、この検定を利用することができます。

- **尺度に依存しない**： データが何らかのランクや順序を持っている必要はなく、χ²検定はχ²という統計量を使ってデータの関連性を評価します。これにより、データの尺度にとらわれることなく分析が行えます。

- **度数に着目**： χ²検定は、カテゴリごとの観測回数（度数）と理論上期待される度数との間の違いを考慮します。これらの違いはχ²の値としてまとめられ、データがどれだけ理論的な分布に従っているかを判断するのに用います。

χ²検定は、データの特定の形状にとらわれることなく、「データが特定の理論的な分布に従っているかどうか」を調査する（これを適合度検定と呼びます）または、カテゴリ間の関連性を検証する（これを独立性検定と呼びます）ための非常に便利な方法です。χ²検定を利用する際に重要なことは、データが特定の確率分布に厳密に従う必要はない、という点です。しかし、データと理論の違いを数値化する「χ²統計量」は、特定のパターン（つまりχ²分布）に従うという前提があります。この前提を把握しておくことで、検定結果の解釈とその有効性が適切に理解できます。
   
# 2. χ²分布

χ²分布は統計学や確率論の分野で広く採用されている確率分布であり、統計的検定や信頼区間の推定など、多くの応用に重要な役割を果たします。このセクションでは、χ²分布の基本的な概念、特性、そして自由度との関係について解説します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なパッケージをロードします
library(ggplot2)

# カイ二乗分布のデータを生成します
x <- seq(0, 20, length.out = 1000)
density <- dchisq(x, df = 4)

# データフレームに変換します
df <- data.frame(
  x = x,
  density = density
)

# グラフをプロットします
ggplot(df, aes(x, density)) +
  geom_line(color = "blue") +
  theme_minimal() +
  labs(x = "Value", y = "Density", 
       title = "Chi-Squared Distribution with df = 4")
```

## 定義

χ²分布は、複数の独立した標準正規分布（平均0、分散1の正規分布）の二乗和が従う確率分布と理解できます。詳しくは、k個の独立した標準正規分布の値をそれぞれ二乗し、その結果を足し合わせたものが、自由度kのχ²分布に従うということです。

ここで、\(Z_1\), \(Z_2\), ..., \(Z_k\)は互いに独立した標準正規分布（平均0、分散1の正規分布）に従うとします。これらを二乗して足し合わせると、その和Xは自由度kのχ²分布に従います。

\[ X = Z_1^2 + Z_2^2 + ... + Z_k^2 \]

次のグラフでは、ヒストグラムが2つの独立した標準正規分布の二乗和のデータ分布を、滑らかな曲線が自由度2の理論的なχ²分布をそれぞれ表現しています。このグラフから、二乗和がχ²分布に従う様子を視覚的に理解することが可能です。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# Rコード
library(ggplot2)

# 標準正規分布から標本を取得
n_samples <- 10000
z1 <- rnorm(n_samples, 0, 1)
z2 <- rnorm(n_samples, 0, 1)

# 二乗して足し合わせる
chi_square <- z1^2 + z2^2

# プロットにヒストグラムと理論的なχ²分布を表示
p <- ggplot() +
  geom_histogram(data = data.frame(chi_square), aes(x = chi_square, y = after_stat(density)), bins = 50, alpha = 0.5) +
  stat_function(fun = dchisq, args = list(df = 2), aes(color = "Theoretical Chi-Square Distribution"), linewidth = 1) +
  labs(title = "Sum of Squares of Two Independent Standard Normal Distributions",
       x = "Value",
       y = "Density",
       color = "Legend") +
  theme_minimal()

# プロットを表示
print(p)
```

## 特性

χ²分布は以下のような特性を持っています。

- **0以上の値**: χ²分布は0以上の値しか取りません。これは、正規分布の二乗和として定義されるため、負の値が出現しないからです。
- **形状と自由度**: χ²分布の形状は自由度に依存します。自由度が増えるにつれて、χ²分布は徐々に正規分布に近づき、ピークは右にシフトします。
- **平均と分散**: χ²分布の平均は自由度と等しく、分散は自由度の2倍です。

χ²分布は以下のような用途があります。

- **χ²検定**:χ²検定は、カテゴリカルデータに基づいて、2つのカテゴリカル変数間の関連性や観測データが特定の理論的分布に従っているかどうかを評価するために使用されます。χ²検定では、観測された頻度と期待される頻度の間の差異をχ²統計量で評価し、この統計量をχ²分布と比較して検定を行います。

- **分散の信頼区間の計算**:χ²分布は、分散の信頼区間の計算に頻繁に使用されます。特に、正規分布の母集団分散の信頼区間を推定する際にχ²分布が活用されます。標本データから得られたχ²統計量を用いて、分散の信頼区間を求めます。

- **統計モデルの評価**:統計モデルの適合度を評価する際にもχ²分布は使われます。例えば、ロジスティック回帰モデルの適合度を評価する際の尤度比検定では、その統計量がχ²分布に従うことが知られています。これにより、統計モデルがデータにどれほど良く適合しているか、またそのモデルが信頼できるのかを判断することが可能となります。

- **モンテカルロシミュレーション**:モンテカルロシミュレーションなどの確率的なシミュレーションを行う際に、特定の自由度を持つχ²分布に基づいて乱数を生成し、それをシミュレーションの一部として使用します。

- **発達心理学における使用**:
発達心理学では、成長曲線のモデリングにχ²分布が用いられることがあります。例えば、身長の成長曲線をモデリングする際、子供の成長の観察データと理論的な成長曲線の適合性を評価するためにχ²統計量とその分布が使用されます。これにより、理論的な成長曲線が観察データにどれほど良く適合しているかを評価します。

## 自由度

自由度は、制約のない独立した情報の総量を示す概念で、具体的には他のパラメータや制約に影響されずに選択できる変数の数を指します。自由度は、統計的仮説検定の精度を計算するためや、特定の確率分布（χ²分布、t分布、F分布など）の形状を定義するために使用されます。

以下に、個々のデータ値と統計モデルの観点から自由度について考察します。

- **個々のデータ値における自由度**: 各データ点は自由度を1つ持っています。しかし、すべてのデータ点が完全に自由であるわけではありません。例えば、3つの数値が与えられ、それらの平均が0であるとすると、最初の2つの数値は自由に選べますが、3つ目の数値は他の2つによって制約されます。つまり、この場合の自由度は2となります。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 最初の2つの数値を指定します
x1 <- 4
x2 <- -2

# 平均が0になるように3つ目の数値を計算します
x3 <- - (x1 + x2)

# 数値と平均値を出力します
cat("Numbers: ", x1, x2, x3, "\n")
cat("Mean: ", mean(c(x1, x2, x3)), "\n")
```

- **統計モデルにおける自由度**: 一方、統計モデルの自由度は、そのモデルのパラメータの数によって決まります。例えば、線形回帰モデルの場合、直線のフィットは y = ax + b の形で表現されます。ここでaとbはパラメータで、データから推定されます。したがって、このモデルの自由度は、観測値の数（n）からパラメータ数（2つ、aとb）を引いた n-2 となります。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 乱数生成の初期値を設定
set.seed(123)

# データを生成
n <- 100  # データの数
x <- runif(n, 0, 10)
y <- 2*x + 3 + rnorm(n)

# 線形回帰モデルを作成
model <- lm(y ~ x)

# 自由度を計算し、出力します
df <- n - length(coef(model))
cat("Degrees of freedom: ", df, "\n")
```

このコードでは乱数を用いてデータを生成し、それを用いて線形回帰モデルを作成しました。このモデルの自由度はデータの数（この場合、100）からパラメータの数（この場合、2）を引いた値です。

自由度は、特定の確率分布（χ²分布、t分布、F分布など）の形状を決定する重要な要素でもあります。自由度が増えると、これらの分布は正規分布に近づきます。これは、自由度が大きくなるほど利用可能な情報量が増え、結果の信頼性が向上するためです。この性質は中心極限定理と密接に関連しています。

### 自由度の計算例

χ²検定においては、自由度の計算方法は特定の公式に従います。具体的には、カテゴリカルなデータに対するχ²検定では、自由度は観測データの行と列の数から計算します。この場合、「（行数-1）×（列数-1）」の公式を用いて自由度が計算されます。

例えば、2x2の観測データ（例：行と列がそれぞれ2つのカテゴリを持つクロス集計表）がある場合、自由度は「(2-1) x (2-1) = 1」となります。つまり、1つの自由な変動が可能なパラメータが存在します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2の観測データを作成します。
observed <- matrix(c(10, 20, 30, 40), nrow = 2)

# 行数と列数を取得します。
num_rows <- nrow(observed)
num_cols <- ncol(observed)

# 自由度を計算します。
df <- (num_rows - 1) * (num_cols - 1)

# 結果を表示します。
cat("自由度は:", df, "\n")
```

### 自由度と分布の形状

χ²分布の形状は、その自由度により決まります。自由度とは、統計的な解析で自由に変動できる値の数を示します。

自由度が1のχ²分布は、原点から離れたところでピークを持ち、右に偏った形状を示します。しかし、自由度が増加すると、分布の形状は徐々に正規分布に近づき、ピークも原点から遠くに移動します。つまり、自由度が増えると、分布は右にシフトし、分布の広がり（すなわち、分布のばらつき）が増加します。

次のグラフは自由度が1から10までのχ²分布を描画し、自由度が増加するにつれて分布の形状がどのように変わるかを視覚的に示したものです。

```{r, error=FALSE, echo=FALSE}
# 自由度が1から10までのχ²分布のプロット
df_list <- list()
for (df in 1:10) {
  df_list[[df]] <- data.frame(x = seq(0, 30, length.out = 1000), 
                              y = dchisq(seq(0, 30, length.out = 1000), df), 
                              df = factor(df))
}
df_all <- do.call(rbind, df_list)

# χ²分布の描画
ggplot(df_all, aes(x = x, y = y, color = df)) +
  geom_line() +
  labs(x = "Value", y = "Density", color = "Degrees of Freedom") +
  coord_cartesian(ylim = c(0, 0.6)) + # y軸の範囲を0から0.75に制限します。
  theme_minimal() + # シンプルなデザインにします。
  ggtitle("Degrees of Freedom 1-10: Chi-square Distributions")
```

自由度が増えるとχ²分布は右にシフトし、徐々に正規分布に近づいていくことがわかります。

### 自由度と検定の結果

χ²検定の結果は、自由度に強く影響されます。自由度が変われば、χ²検定の結果も必然的に変化します。今回、3x3と2x2の異なる観測データセットを用いて、自由度の違いがχ²検定結果にどのように影響を及ぼすかを評価します。

まず、3x3の観測データセットを用いてχ²検定を行い、次に2x2の観測データセットで同じ検定を実施し、それぞれの結果を比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# dplyrパッケージの読み込み
library(dplyr)

# 3x3観測データの作成
observed2 <- matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90), nrow = 3)
cat("3x3観測データ:\n")
print(observed2)

# 3x3データを用いたχ²検定の実行
chisq_result2 <- chisq.test(observed2)

# χ²値、p値、自由度の表示
cat("3x3データに対するχ²値: ", chisq_result2$statistic, "\n")
cat("3x3データに対するp値: ", chisq_result2$p.value, "\n")
cat("3x3データに対する自由度: ", chisq_result2$parameter, "\n")
```

続いて、2x2のデータセットを用いて同様のχ²検定を行います。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2観測データの作成
observed <- matrix(c(10, 20, 30, 40), nrow = 2)
cat("2x2観測データ:\n")
print(observed)

# 2x2データを用いたχ²検定の実行
chisq_result <- chisq.test(observed)

# χ²値、p値、自由度の表示
cat("2x2データに対するχ²値: ", chisq_result$statistic, "\n")
cat("2x2データに対するp値: ", chisq_result$p.value, "\n")
cat("2x2データに対する自由度: ", chisq_result$parameter, "\n")
```

これらの結果を元に、自由度の違いがχ²検定結果（χ²値とp値）にどのように影響するかを比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# パッケージの読み込み
library(tidyr)

# 比較用のデータフレームの準備
data <- data.frame(
  Test = c("3x3", "2x2"),
  DegreesOfFreedom = c(chisq_result2$parameter, chisq_result$parameter),
  ChiSquareValue = c(chisq_result2$statistic, chisq_result$statistic),
  PValue = c(chisq_result2$p.value, chisq_result$p.value)
)

# プロット用のデータ整形
data_plot <- data %>%
  pivot_longer(cols = -Test, names_to = "Metric", values_to = "Value") %>%
  mutate(Metric = factor(Metric, levels = c("DegreesOfFreedom", "ChiSquareValue", "PValue")),
         Metric = case_when(
           Metric == "DegreesOfFreedom" ~ "Degrees of Freedom",
           Metric == "ChiSquareValue" ~ "Chi-square Value",
           Metric == "PValue" ~ "p-value"
         ))

# Metricの順序を指定
data_plot$Metric <- factor(data_plot$Metric, levels = c("Degrees of Freedom", "Chi-square Value", "p-value"))

# χ²値、p値、自由度の比較用バープロットの作成
p <- ggplot(data_plot, aes(x = Test, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  scale_fill_brewer(palette = "Set2", name = "") +
  labs(x = "Dataset", y = "Value", fill = "") +
  facet_wrap(~ Metric, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom", 
        plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold")) +
  ggtitle("Comparison of 3x3 and 2x2 Datasets")

# バープロットの表示
p
```

自由度はχ²検定の結果（χ²値とp値）に以下のように影響を与えます：

- **χ²値**：自由度が増えると、χ²値の範囲（すなわち、可能な最小値と最大値）も増えます。これは、より多くのセル（つまり自由度が高い）を持つテーブルでは、観測された値と期待される値との間により大きな差が生じる可能性が高まるためです。

- **p値**：p値は、観測された（またはより極端な）データが、帰無仮説が真であるという前提のもとで生じる確率を示します。自由度が増えると、χ²分布の形状が変わり（具体的には、分布が右にシフトし、広がりが大きくなります）、これによりp値も変化します。特定のχ²値が与えられたとき、自由度が高いほどそのχ²値を得る確率は高くなり、したがってp値は大きくなります。

# 3. χ²検定

χ²検定は、2つ以上のカテゴリカルデータ間の独立性や、一組の観測データが特定の理論的な分布に従っているかどうかを検定するための統計手法です。これはカテゴリカルなデータに対する統計的検定の一つで、観測された頻度分布が期待される頻度分布と有意に異なるかどうかを判断することが目的です。

## χ²検定の種類

χ²検定は主に以下の3つの目的で使用されます：

1. **適合度検定**：観測されたデータの分布が予想される特定の理論的な分布に適合するかどうかを評価します。
2. **独立性検定**：2つのカテゴリカル変数が互いに独立しているか、関連しているかを調べます。
3. **同質性の検定**：異なる群間でカテゴリカルデータの分布が同じであるかどうかを検定します。

## χ²検定の手順

1. **研究課題の設定**
     - 仮説や課題を明確化します。具体的な問いを立て、これが特定の発達段階、行動、あるいは子供の発達に影響を与える要素に関連することを確認します。
     - 研究課題がどの文脈で重要であるかを説明します。問題の背景、既存の研究のギャップ、研究結果が社会や教育にどのような影響を与えるかを含めます。
     - 研究の目標と、それを達成するための手段を詳述します。
     - 研究の結果とその重要性を示します。その結果が発達心理学の理解を深め、子供の生活の改善にどのように寄与するかを強調します。
     
2. **母集団の定義と標本の選択**：
     - 研究対象全体を母集団として明確に定義します。母集団の特性と範囲は、研究目的や問題の設定に基づいて定められます。
     - 母集団から適切な標本を選びます。理想的にはランダムサンプリングを用い、標本が母集団を適切に表現していることを確認します。ランダムサンプリングが不可能な場合は、そのことを統計分析結果の解釈に反映します。
     - データ収集方法、タイミング、場所などもこの段階で決定します。データ収集の設計は結果の信頼性と分析の質に大きく影響します。
     
3. **データの前処理**
     - データ収集後、前処理を行います。欠損値の処理、外れ値の検出と対応、不適切なデータの排除などを含みます。
     - 欠損値は削除または適切な方法で補完します（平均値補完、回帰補完など）。
     - 外れ値はデータの分布を確認し、適切な対応を行います。外れ値が重要な情報を含む場合は、その影響を考慮した解析を行います。

4. **問題の理解と仮説の設定**:
    - 問題の理解を深め、何を解明したいのかを明確にします。理論的仮説を設定します。これは、研究の目的と直接関連しています。
    - テストしたい理論的仮説に基づいてχ²検定のタイプ（適合度検定、独立性検定、同質性検定）を選びます。
    - 選択したχ²検定のタイプに基づき、帰無仮説と対立仮説を設定します。これらは具体的で測定可能な形で理論的仮説を表現するものです。
      - 適合度検定
        - **帰無仮説（H0）**：観測された頻度分布は期待される頻度分布に適合する。
        - **対立仮説（H1）**：観測された頻度分布は期待される頻度分布に適合しない。
      - 独立性検定
        - **帰無仮説（H0）**：2つのカテゴリカル変数は独立である。
        - **対立仮説（H1）**：2つのカテゴリカル変数は独立ではない。
      - 同質性の検定
        - **帰無仮説（H0）**：異なる群間でのカテゴリカルデータの分布は同じである。
        - **対立仮説（H1）**：少なくとも1つの群でカテゴリカルデータの分布が異なる。
        
5. **前提条件の検証**:
    - 標本データはランダムに選ばれているか？
    - データはカテゴリカルまたは順序尺度か？
    - 各カテゴリの観測値は独立しているか？
    - 各カテゴリの期待度数は5以上か？（もし期待度数が5未満のセルがある場合は、Yatesの補正やフィッシャーの正確検定を検討する）

6. **χ²統計量の算出方法**:
    - χ²値は観測された頻度と期待される頻度との差を反映したもので、これにより計算されます。
    - 検定により期待度数の計算方法は異なります:
       - **適合度検定**では、期待度数は理論的な分布に基づきます。例えば、特定の年齢群の子供たちの言語習得スキルが全国平均の正規分布に適合するかどうかを検定する場合、期待度数は全国平均の言語習得スキルの分布に基づきます。
       - **独立性検定**では、期待度数の算出は全体の頻度分布に基づいて行われます。子供の性別が学業成績に影響を与えるかどうかを調べる場合、期待度数は全体の男女比と全体の学業成績の比から算出します。
       - **マクネマー検定**では、期待度数はマージナルな分布（各行または列の合計）を元に算出されます。特定の介入（例えば、新しい教育方法）の前後で行動（例えば、学習行動の有無）が変化したかどうかを調べる場合に用います。
       - **同質性検定**では、期待度数は各グループ内の頻度分布に基づいて計算されます。異なる教育方法（例えば、伝統的な教育法と新しい教育法）が学生の成績分布に影響を与えるかどうかを調べる際に用いられ、各教育法が同じ成績分布を持つという帰無仮説のもとで期待度数を算出します。

7. **p値の計算**:
    - χ²分布表または統計ソフトウェアを使用し、算出されたχ²値と自由度（通常は「カテゴリ数 - 1」）に基づきp値を計算します。
    - χ²検定の結果を報告する際には、χ²値、自由度（分析の柔軟性を示す要素）、そしてp値（結果が偶然から生じた可能性）を含めるのが一般的です。
    
8. **効果量の計算の計算**:
    - χ²検定の結果だけでなく、その検定結果がどれほど実質的な影響を持つのかを示す効果量を評価することも重要です。ここでは、一部の検定における主要な効果量を挙げますが、実際の研究状況や分析目的によっては他の種類の効果量を使用することもあります。
    - 効果量の計算方法はχ²検定の種類によって異なります:
       - 1変量のχ²検定（適合度の検定）: 主要な効果量としてCohenのwがありますが、状況によっては他の指標を使用することもあります。
       - 2変量のχ²検定（独立性の検定）: 一般的な効果量としてCramerのVがあります。また、2つの二項変数間の相関を測定するためにφ係数（phi coefficient）を使用することもあります。
       - フィッシャーの直接確率検定: 一般的にオッズ比やリスク比が用いられますが、相対リスク（Relative Risk）など他の指標も参考にされることがあります。
       - マクネマー検定: マクネマーのオッズ比が主要な効果量ですが、一対の値についての変化の程度を測定するモノメンチのΔ（McNemar's Delta）も用いられます。
       - 同質性の検定:「2 x C」、「R x 2」、「R x C」のデータ形式では、効果量としてCramér's VやPhi係数が用いられます。これらの指標は、カテゴリ間の関連性の強さを示します。
    
9. **結果の解釈**:
    - χ²値、自由度、p値、そして効果量（Cramer's Vなど）の各統計量を解釈し、研究結果の結論を導き出します。
    - p値が有意水準（通常は0.05）を下回る場合、帰無仮説は棄却され、観察された頻度分布と期待される頻度分布との間に統計的に有意な差があると結論付けられます。一方、p値が設定した有意水準を上回る場合は、帰無仮説を維持します。
    - 効果量が大きければ、観察された変数間に強い関連性があることが示唆されます。逆に、効果量が小さければ、関連性が弱い、または無関係であることを示します。これは、p値が有意であっても、その関連性が実質的には微弱であることを示しています。すなわち、「統計的に有意だが実質的には無意味」である可能性を示しています。

10. **結果の報告**:
    - 研究結果は特定の書式に従い報告する必要があります。心理学の分野では、APAスタイルが広く採用されており、このスタイルでは統計的な結果とその解釈を詳細に記載することが強調されています。また、統計的有意性だけでなく、効果量の報告も重要視されています。
    - APAスタイルでは、特定のフォーマットが統計量の報告に求められます。例えば、χ²検定の結果は "χ²(自由度) = χ²値, p = p値, φc = Cramer's V値" の形式で記述します。
    - 効果量（例えばCramer's V）の信頼区間も報告することが求められます。信頼区間は "95% CI [下限, 上限]" の形式で表されます。信頼区間は母集団パラメータの可能な範囲を示す統計量で、この区間が特定の値（例えば0）を含むか否かで、その値が統計的に有意かどうかを判断します。信頼区間の幅が狭いほど、推定値の精度が高いと判断されます。

以下に、χ²検定の使用に際して考慮すべきいくつかのポイントを示します：

- χ²検定はカテゴリカルデータに対してのみ適用可能です。連続データにχ²検定を適用することは不適切です。
- 期待度数が極端に小さい（通常5未満）場合、χ²検定の結果の信頼性は低下します。このような状況では、データの再分類を行うか、別の統計的手法を検討する必要があります。
- χ²検定は、標本データが母集団から無作為に選択されることを前提としています。これを満たしていない場合、検定結果は偏っている可能性があります。
- χ²検定は、群間の差異が存在するかどうかを判断するのに有用ですが、その差異がどれほど意義深いか（効果量）については判断しないため、効果量の評価も重視する必要があります。
- χ²検定は帰無仮説の正しさを評価しますが、帰無仮説が棄却された理由を特定するものではありません。帰無仮説が棄却された場合、その理由を探るために追加の分析が必要となります。


# 4. 1変量のχ²検定（適合度の検定）

## 理論

1変量のχ²検定（適合度の検定）は、観測されたデータの分布が特定の理論的な分布（一般には、帰無仮説で述べられた期待される結果に基づく分布）に合致しているか否かを評価する手法です。同時に、効果量を用いることで、統計的な有意性だけでなく、結果の大きさや重要性も評価します。


χ²値は以下の公式に従って計算されます：

\[ \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \]

ここで、

- \(O_i\)はi番目のカテゴリの観測された頻度、
- \(E_i\)はi番目のカテゴリの期待される頻度、

を示しています。

このχ²値は観測頻度と期待頻度間の差異の大きさを統計的に評価します。各カテゴリで観測頻度と期待頻度の差を二乗し、それを期待頻度で割ります。これにより各カテゴリにおける差異の相対的な大きさが求まり、それらを全て足し合わせることでχ²値を算出します。

χ²値の大きさは、観測データが期待値からどれだけ逸脱しているかを示します。この値が大きければ大きいほど、観測データは期待値から大きく逸脱していると解釈されます。これは観測データに何らかの効果が存在する可能性を示唆します。

効果量としては、Cohenのwが一般的に用いられます。Cohenのwの計算式は次のようになります：

\[ w = \sqrt{\frac{\chi^2}{N}} \]

ここで、

- \(\chi^2\)はχ²値、
- \(N\)は全標本数、

を示しています。

Cohenのwはカイ二乗統計量を全標本数で正規化し、その結果の平方根を計算します。これにより、標本サイズの影響を排除しています。

Cohenのwは標準化された効果量として位置づけられ、統計的な有意性だけでなく、その結果が実質的にどれほど重要であるか、つまり効果の大きさを評価するために使用されます。この指標は観測データが期待分布からどれだけ逸脱しているかを示し、その逸脱度の大きさを理解するために利用されます。

公平な6面のサイコロを60回投げるシナリオを考えてみましょう。理論的には、各面が出る回数は10回（60回 / 6面）と期待できます。しかし、実際の結果は必ずしも10回とは限りません。その差異が大きいほどχ²統計量は大きくなります。

p値が特定の閾値（通常は0.05）以下であれば、観測データが期待分布から統計的に有意に異なると判断されます。

以下に、Rを用いたχ²検定の例と効果量の計算を示します。

```{r, error=TRUE, include=TRUE}
# 乱数生成の初期値を設定
set.seed(123)

# 1から6までの数字（サイコロの目）をランダムに60回選ぶ
# 選択は置換あり（選ばれた数値を再度選ぶことが可能）
# 選択された数値を因子として扱う
# 各因子レベル（サイコロの目）が選ばれた回数（頻度）を集計
roll_results <- table(factor(sample(1:6, size = 60, replace = TRUE), levels = 1:6))

# サイコロを60回投げた結果を表示
print(roll_results)

# 各面が出る期待頻度を定義
# 各面が出る期待値は10回
expected_frequencies <- rep(10, 6)

# χ²検定を実行
# 検定は実際の結果（roll_results）と期待頻度（expected_frequencies）を比較
test_results <- chisq.test(roll_results, p = expected_frequencies / 60)

# χ²検定の結果を表示
print(test_results)

# 効果量 (Cohen's w) を計算
effect_size <- sqrt(test_results$statistic / sum(roll_results))
print(effect_size)
```

上記のコードでは、公平な6面のサイコロを60回投げる結果をシミュレートしています。その後、期待頻度（各面が10回出ると期待される）と観測頻度を用いてχ²検定を実行します。p値を確認することで、観測データが期待する分布（この場合、各面が等確率で出るとする分布）から統計的に有意に異なるかどうかを判断します。最後に、効果量（Cohenのw）を計算し、検定結果の大きさを評価します。

## 実践

χ²適合度検定の解析手順をRを用いて示します。

### 背景とデータの説明

日本全国の幼稚園児に対する幼稚園の好感度を調査します。「幼稚園が好きですか？」という質問に対する「はい」または「いいえ」の回答を分析の対象とします。大阪府内の幼稚園児に対して便宜的サンプリングを行い、データを収集した場合を考えます。

- 母集団: 日本全国に在籍する全幼稚園児
- 標本: 大阪府内の特定の幼稚園に在籍する子供たち

### 仮説の設定

- 理論的仮説：全ての子供たちは、質問「幼稚園は好きですか？」に対して、「はい」または「いいえ」のいずれかで答える確率はそれぞれ50%である。

- 統計的仮説：
  - 帰無仮説 (H0): 観測された子供たちの回答の分布は、期待される分布（「はい」と「いいえ」の確率がそれぞれ50%）と一致する。
  - 対立仮説 (Ha): 観測された子供たちの回答の分布は、期待される分布（「はい」と「いいえ」の確率がそれぞれ50%）と一致しない。

### データの準備

- データの種類: 名義尺度であり、「はい」または「いいえ」の2つのカテゴリーを有する
- データの前処理: 欠損値や異常値の確認を行います。欠損値は適切な代替値で補完するか、あるいは完全に除去します。一方、異常値については、データの性質を考慮して最善の処理方法を選択します。

```{r, error=TRUE, include=TRUE}
# CSVファイル '20230616_chap4sample1_RToda.csv' を読み込みます。結果はデータフレームx1に格納されます。
x1 <- read.csv("20230616_chap4sample1_RToda.csv", header=T)

# データフレームx1の先頭6行を表示します。これにより、データの概観を把握します。
head(x1)
```

```{r, error=TRUE, include=TRUE}
# Answer列のデータを因子型に変換します。これは統計分析でよく使用されるデータ型で、カテゴリーデータを扱うのに適しています。
# labels引数を用いて、0を'No'、1を'Yes'に対応させます。
x1$Answer <- factor(x1$Answer, labels=c('No','Yes')) 

# 変換後のAnswer列のデータを表示します。これにより、変換が正しく行われたことを確認します。
print(x1$Answer)
```

### 前提条件の検証

χ²適合度検定を行う前には、以下の前提条件が満たされていることを確認する必要があります。

- 観測データはカテゴリカル（名義尺度）である。
- 各観測値は互いに独立している。
- 全てのカテゴリで期待度数が5以上である。

まず、データをクロス集計表にまとめて視覚的に確認します。

```{r, error=TRUE, include=TRUE}
# Answer列のデータを用いて、'No'と'Yes'の回答数を集計します。結果はクロス集計表x1tableに格納されます。
x1table <- table(x1$Answer)

# クロス集計表x1tableを表示します。これにより、各カテゴリの頻度を確認します。
print(x1table) 
```

次に、全てのセルの期待度数が5以上であることを確認します。

```{r, error=TRUE, include=TRUE}
# 期待度数の確認
expected_values <- chisq.test(x1table)$expected
all(expected_values >= 5)
```

期待度数が5以上のカテゴリが存在しない場合、χ²適合度検定の結果は信頼できない可能性があります。その場合は、別の適切な検定方法を検討してください。

### Rでの実行

```{r, error=TRUE, include=TRUE}
# chisq.test関数を用いてχ²適合度検定を実行します。観測データが期待する分布にどの程度適合しているかを評価します。結果はtest_resultsに格納されます。
test_results <- chisq.test(x1table)

# テスト結果を表示します。これにより、p値やχ²統計量などの情報を得ます。
print(test_results)
```

Cohen's wを計算します。Cohenのwは0から1までの値を取り、1に近いほど変数間の関連性が高いことを示します。

```{r, error=TRUE, include=TRUE}
# 効果量 (Cohen's w) を計算します。これは検定結果の効果の大きさを評価するための指標です。
effect_size <- sqrt(test_results$statistic / sum(x1table))

# 効果量 (Cohen's w) を表示します。これにより、結果の解釈に役立つ情報を得ます。
print(effect_size)
```

Cohen's wの信頼区間を直接計算する方法は確立されていません。したがって統計的な分析結果を報告する際には、χ²値、自由度、p値、およびCohen's wを報告するのが一般的です。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 10, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "black") +
  labs(x = "Chi-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# Chi-squaredの値
chi_squared <- 5

# Chi-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = chi_squared, linetype = "dashed", colour = "black") + 
  annotate("text", x = chi_squared, y = 3, 
           label = paste("Chi-squared =", chi_squared, "(α = 0.02535)"), 
           vjust = 0, hjust = 0.1, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 0, hjust = 0.9, colour = "red")

# プロットを表示
print(p)
```

p値が0.05より小さい場合、観測されたデータが期待される分布と有意に異なると解釈されます。

### 視覚化

```{r, error=TRUE, include=TRUE}
# pie関数を用いて、クロス集計表のデータを利用して円グラフを作成します。円グラフは 'No'と'Yes'が全体に占める割合を視覚的に表示します。
pie(x1table, main="Pie Chart of Answers", col=c("lightblue", "pink"))
```

```{r, error=TRUE, include=TRUE}
# barplot関数を用いて、クロス集計表のデータを利用して棒グラフを作成します。棒グラフは各カテゴリ（'No'と'Yes'）の観測数を直観的に比較するのに適しています。
barplot(x1table, main="Number of 'No' and 'Yes'", xlab="Answer", ylab="Count", col=c("lightblue", "pink"))
```

### 結果の解釈

χ²値が5、自由度が1、そしてp値が0.02535という結果が得られました。通常、p値が0.05を下回ると、統計的に有意であると判断され、帰無仮説を棄却します。今回のp値は0.02535であるため、0.05を下回ります。これにより、「はい」または「いいえ」の回答の分布が期待される均等な分布（「はい」と「いいえ」がそれぞれ50%）と統計的に有意に異なると結論付けることができます。

さらに、効果量（Cohen's w）が0.5であることが計算されました。効果量は結果の「大きさ」を定量化するための統計的手段で、p値だけでは捉えられない情報を提供します。Cohen's wの値が大きいほど効果の大きさが大きいと解釈されます。本研究では、Cohen's wが0.5という結果は、回答の分布が期待される均等な分布から中程度にずれていることを示しています。しかし、このCohen's wの解釈は一般的なガイドラインに基づいており、実際の解釈には具体的な研究領域の先行研究との比較が必要です。

### 結果の報告（APAスタイル）

「特定の年齢層の子どもたちに対して"幼稚園は好きですか？"という質問を行い、その回答が均等に分布しているかどうかをχ²適合度検定で評価した。この分析は、回答の分布が均等であるという仮説を支持しなかった, χ²(1) = 5.00, p = .03。さらに、効果量（Cohen's w）は0.5であり、回答の分布は期待される均等な分布から中程度にずれていた（ただし、ここでの効果量の解釈は一般的なガイドラインに過ぎず、実際の解釈には関連する先行研究との比較が必要です）。これらの結果は、子どもたちの幼稚園に対する感情が一様でない可能性を示唆している。」

# 5. 2変量のχ²検定（独立性の検定）

2変量のχ²検定は、二つのカテゴリカル変数が互いに独立、つまり一方が他方に影響を与えないかどうかを評価する統計的手法です。

## 理論

χ²検定の帰無仮説は、「二つの変数は独立である」です。つまり、一つの変数の値がもう一つの変数の値に影響を与えないという仮説を検証します。

χ²統計量は次の式で求められます:

\[\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}\]

ここで、

- \(O_{ij}\)はi番目とj番目のカテゴリの組み合わせの観測頻度、
- \(E_{ij}\)はi番目とj番目のカテゴリの組み合わせの期待頻度、

を示しています。

帰無仮説（2つの変数が独立である）が正しい場合、χ²統計量は小さな値になることが期待されます。逆に、χ²統計量が特定の閾値を超えた場合、帰無仮説は棄却され、2つの変数間に何らかの関連性が存在するとされます。

χ²検定は、2つの変数の独立性を評価するためのものですが、これらの変数間の関連性の強さを定量的に評価するためには別の指標が必要です。その指標としてよく用いられるのがフィルの係数とCramerのVです。

フィルの係数は2x2クロス表、つまり2つの二項変数間の相関を測定します。その計算式は以下の通りです。

\[\Phi = \sqrt{\frac{\chi^2}{n}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)は標本サイズ（観測数）

をそれぞれ表します。

一方、CramerのVは、2つのカテゴリカル変数間の関連性の度合いを0から1までの値で表したもので、2x2表だけでなく、より大きな次元（2×2以上）のクロス表に対して使用することができます。値が0であれば変数間には全く関連性がないことを示し、1であれば変数間が完全に関連していることを示します。

CramerのVの計算式は次の通りです：

\[V = \sqrt{\frac{\chi^2}{n(k-1)}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)は標本サイズ（観測数）、
- \(k\)は二つの変数のカテゴリの数のうち少ない方、

をそれぞれを示しています。

CramerのVは、これら3つの要素を組み合わせたものであり、χ²統計量が大きければ大きいほど、また標本サイズが小さければ小さいほど、Vの値が大きくなります。一方、カテゴリの数が増えると、Vの値は減少します。これはカテゴリの数が増えると、各カテゴリ間の関連性が一般的に弱くなることを反映しています。

これら全ての要素が組み合わさることで、CramerのVは2つのカテゴリカル変数間の関連性の強さを0から1の範囲で表現しています。

以下に、Rを用いてχ²検定を実行し、関連性の強さをCramerのVで評価する例を示します：

```{r, error=TRUE, include=TRUE}
# 再現性を確保するためのシード値を設定
set.seed(123) 

# それぞれが3つのカテゴリを持つ2つのカテゴリカル変数のデータを生成
var1 <- sample(c("A", "B", "C"), size = 100, replace = TRUE)
var2 <- sample(c("X", "Y", "Z"), size = 100, replace = TRUE)

# 2つの変数のクロス集計表を作成
data <- table(var1, var2)

# χ²検定を実行
test_result <- chisq.test(data)

# χ²値を表示
test_result$statistic

# p値を表示
test_result$p.value

# CramerのVを計算
V <- sqrt(test_result$statistic / (sum(data) * (min(dim(data)) - 1)))

# CramerのVを表示
V
```

このコードは、2つのカテゴリカル変数からなるデータセットを生成し、その後でχ²検定を実行して2つの変数間の独立性を評価します。出力されるp値を見て、変数間に統計的に有意な関連性があるかどうかを判断します。そして、CramerのVを計算することで関連性の強さを評価します。変数がそれぞれ複数のカテゴリを持つため、この例ではフィルの係数ではなくCramerのVが用いられています。

## 実践

χ²独立性検定の解析手順をRを用いて示します。

### 背景とデータの説明

小学生が授業を面白いと感じるかどうか（「はい」または「いいえ」）と、その感じ方が児童の性別（「男性」または「女性」）に依存するかどうかを調査します。大阪府内の特定の小学校の児童から便宜的にサンプリングを行い、データを収集します。

- 母集団: 日本全国の小学校に通っているすべての児童
- 標本: 大阪府の特定の小学校に在籍し、質問に応答した児童

### 仮説の設定

- 理論的仮説：児童の性別は、授業に対する意見（面白いか否か）に影響を及ぼす。
- 統計的仮説
  - 帰無仮説 (H0): 児童の性別と授業に対する意見は独立である（つまり、関連性がない）。
  - 対立仮説 (Ha): 児童の性別と授業に対する意見は独立ではない（つまり、関連性がある）。

### データの準備

まずは、CSVファイル '20230616_chap4sample2_RToda.csv' を読み込み、データの構造を確認します。

- データの種類: 「授業の感じ方」（はい、いいえ）と「性別」（男性、女性）の2つのカテゴリカル変数
- データの前処理: 欠損値や異常値の確認を行います。欠損値は適切な代替値で補完するか、あるいは完全に除去します。一方、異常値については、データの性質を考慮して最善の処理方法を選択します。

```{r, error=TRUE, include=TRUE}
# CSVファイルの読み込み
x2 <- read.csv("20230616_chap4sample2_RToda.csv", header=T) 

# データの一部を表示
head(x2)
```

```{r, error=TRUE, include=TRUE}
# データ構造の確認
str(x2)
```

### 前提条件の検証

χ²独立性検定を行う前には、以下の前提条件が満たされていることを確認する必要があります。

- 観測データはカテゴリカル（名義尺度または順序尺度）である。
- 各観測値は互いに独立している。
- 全てのセル（クロス集計表の各要素）で期待度数が5以上である。

まず、データをクロス集計表にまとめて視覚的に確認します。

```{r, error=TRUE, include=TRUE}
# クロス集計表の作成
x2matrix <- with(x2, table(gender, answer))

# 表示
x2matrix
```

次に、全てのセルの期待度数が5以上であることを確認します。

```{r, error=TRUE, include=TRUE}
# 期待度数の確認
expected_values <- chisq.test(x2matrix)$expected
all(expected_values >= 5)
```

期待度数が5以上のセルが存在しない場合、χ²独立性検定の結果は信頼できない可能性があります。その場合は、フィッシャーの正確性検定など別の検定方法を検討することを検討してください。

### Rでの実行

以下のコードでχ²独立性検定を実行し、結果を表示します。

```{r, error=TRUE, include=TRUE}
# χ²独立性検定の実行
result <- chisq.test(x2matrix) 

# 結果の表示
print(result)
```

CramerのVを計算します。CramerのVは0から1までの値を取り、1に近いほど変数間の関連性が高いことを示します。

```{r, error=TRUE, include=TRUE}
# Cramer's Vの計算
V <- sqrt(result$statistic / (sum(x2matrix) * (min(dim(x2matrix)) - 1)))

# Cramer's Vの表示
print(V)
```

CramerのVの信頼区間を計算します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージをロードします
library(boot)

# CramerのVを計算する関数
calc_cramerV <- function(data, indices) {
    sample_data <- data[indices, ]
    chisq_res <- chisq.test(sample_data)
    n <- sum(sample_data)
    phi <- sqrt(chisq_res$statistic / n)
    return(phi)
}

# ブートストラップ法を使用してCramerのVの分布を推定します
boot_result <- boot(data = x2matrix, statistic = calc_cramerV, R = 1000)

# 信頼区間を計算します
boot_ci <- boot.ci(boot.out = boot_result, type = "bca")

# 結果を表示します
print(boot_ci)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 10, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "black") +
  labs(x = "X-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# X-squaredの値
x_squared <- 6.416

# X-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = x_squared, linetype = "dashed", colour = "black") + 
  annotate("text", x = x_squared, y = 3, 
           label = paste("X-squared =", x_squared, "(α = 0.01131)"), 
           vjust = 1, hjust = 0.3, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 1, hjust = 0.7, colour = "red")

# プロットを表示
print(p)
```

### 視覚化

```{r, error=TRUE, include=TRUE}
barplot(x2matrix, beside = TRUE, col = c("lightblue", "salmon"), 
        legend.text = rownames(x2matrix), ylim = c(0, max(x2matrix)*1.2), 
        ylab = "Counts", xlab = "Opinions", main = "Chi-Square Test of Independence")
```

### 結果の解釈

p値は0.01131であり、これは一般的に用いられる有意水準0.05を下回るものです。したがって、帰無仮説（すなわち、年齢群と学習スタイルの間に関連性がないという仮説）を棄却し、対立仮説（年齢群と学習スタイルの間に関連性がある）を受け入れることができます。これは年齢群と学習スタイルとの間に有意な関連性があり、特定の年齢群が特定の学習スタイルに傾向がある可能性を示しています。

また、クラメールのVは0.4005であり、これは年齢群と学習スタイルの間に中程度の関連性があることを示唆しています。ただし、この効果量の解釈は一般的なガイドラインに過ぎず、実際の解釈には関連する先行研究との比較が必要であることを忘れてはなりません。

さらに、クラメールのVの95%信頼区間は(0.0000, 0.4005)と計算されました。これは、同じ標本データと同じ手法を用いて無数に信頼区間を計算した場合、そのうちの95%の信頼区間がこの範囲に真のクラメールのVを含んでいるということを示しています。しかし、これは推定であり、真のパラメータが必ずしもこの範囲に含まれるわけではないことを理解することが重要です。

### 結果の報告（APAスタイル）

「χ²同質性検定を使用して、5歳、10歳、15歳の小学生の年齢群と視覚、聴覚、体感の学習スタイルの間の関連性を評価した。検定結果は、χ²(1) = 6.416, p = .011、となり、年齢群と学習スタイルの間に有意な関連性が存在することを示している。クラメールのVの値は0.4005であり、その95%信頼区間は(0.0000, 0.4005)となった。これは、年齢群と学習スタイルの間に中程度の関連性が存在する可能性を示している（ただし、この効果量の解釈は一般的なガイドラインに過ぎず、具体的な解釈は先行研究との比較を必要とする）。したがって、特定の年齢群は特定の学習スタイルに傾向がある可能性が示唆された。」

## フィッシャーの正確性検定（標本サイズが小さい場合）

標本サイズが小さい場合は、Fisherの正確性検定を使用することで、より信頼性のある結果を得ることができます。

### データの準備

ここでは、同じデータセットを用いてχ²検定とフィッシャーの正確確率検定の結果を比較します。それぞれの検定結果がどれほど異なるのか、そしてその結果がどのように解釈できるのかを理解することが目的です。

### Rでの実行

フィッシャーの直接確率検定はRの fisher.test() 関数を使用して計算します。

```{r, error=TRUE, include=TRUE}
# フィッシャーの正確確率検定の実行
fisher_result <- fisher.test(x2matrix) 

# 結果の表示
print(fisher_result)
```

### 結果の解釈

フィッシャーの正確確率検定により、p値が0.01039と求まりました。この値は通常の有意水準0.05を下回るため、統計的には性別と授業評価の間に有意な関連性があると言えます。つまり、性別により授業評価に影響が及ぼされる可能性があることを示唆しています。

さらに、オッズ比は6.614723であり、その95%信頼区間は1.457116から35.737819にわたります。オッズ比は、特定の出来事（この場合は特定の授業評価）が発生する確率の比率を示しています。この場合、オッズ比は性別が授業評価に6.614723倍の影響を与える可能性があることを示しています。

しかし、95%信頼区間が1.457116から35.737819と広範囲にわたるため、オッズ比の真の値の不確実性が高いことを示しています。これは、同じデータと手法を使って無数に信頼区間を計算した場合、その95%がこの範囲に真のオッズ比を含む可能性があることを意味します。しかし、これは推定であり、真のオッズ比が必ずしもこの範囲に含まれるわけではないことを理解することが重要です。

### 結果の報告（APAスタイル）

「フィッシャーの正確確率検定を用いて、性別と授業評価の間の関連性を評価した。その結果、性別と授業評価の間に統計的に有意な関連性が示された（p = .010）。関連性の大きさをオッズ比で表した場合、その値は6.61（95% CI [1.46, 35.74]）であり、性別が授業評価に有意な影響を持つ可能性があることが示された。しかし、オッズ比の95%信頼区間が広範囲に渡るため、この推定値の不確実性は大きいと考えられる。」

### χ²検定との比較

フィッシャーの正確性検定とχ²検定の結果は一致し、両方とも性別と授業評価の間に統計的に有意な関連性が存在することを示しています。ただし、フィッシャーの正確性検定は一般的にχ²検定よりも保守的な結果を提供する傾向があります。これはフィッシャーの正確性検定が小さな標本サイズや各セルの期待度数が少ない場合に適しているためです。一方、標本サイズや期待度数が大きい場合は、χ²検定がより適していると考えられます。これらの検定方法を選択する際には、データの特性や研究の目的を考慮することが重要です。

# 6. マクネマー検定（対応のある二項的なデータの分析）

マクネマー検定は、対応のある二項的なデータ（成功/失敗、はい/いいえ等）を分析するためのノンパラメトリックな統計手法であり、カテゴリカルな変数間の関連性を評価します。これはχ²検定の一種であり、対応のあるペアデータに特に適用されます。さらに、マクネマーのオッズ比を用いることで、二つの変数間の関連性の強度を評価することができます。

## 理論

マクネマー検定の帰無仮説は、「二つのカテゴリーの出現頻度は等しい」つまり、一方の変数の状態がもう一方の変数の状態に影響を及ぼさないというものです。

マクネマー検定は2x2のクロス集計表に基づいて計算を行います。具体的には、以下のような表を作成します:

```{r, error=FALSE, include=TRUE}
# matrix関数を用いて2行2列の行列を作成します。
data <- matrix(c("a", "b", "c", "d"), nrow = 2, byrow = TRUE,
               dimnames = list("Condition B" = c("Success", "Failure"),
                               "Condition A" = c("Success", "Failure")))

# 作成した行列を表示します。
print(data)
```

ここで、a、b、c、dはそれぞれの条件下で成功または失敗した被験体の数を示しています。そして、マクネマー検定の統計量は以下の式で計算されます:

\[χ² = (|b - c| - 1)² / (b + c)\]

このχ²の値が大きければ大きいほど、帰無仮説（条件Aと条件Bが同等の影響を及ぼす）が棄却されやすくなります。

一方、マクネマーのオッズ比は以下のように計算されます:

\[OR = \frac{a \times d}{b \times c}\]

ここで、a、b、c、dはそれぞれの条件下で成功または失敗した被験体の数を示しています。マクネマーのオッズ比は、対応のある2×2のクロス集計表から計算され、二つのカテゴリカルな変数間の関連性の強度を測定します。

以下に、Rを用いた具体的な例を示します:

```{r, error=TRUE, include=TRUE}
# 2行2列のクロス集計表を作成します。
data <- matrix(c(20, 30, 25, 25), nrow = 2)

# 行と列の名前をそれぞれ"条件B: 成功", "条件B: 失敗"、"条件A: 成功", "条件A: 失敗"と設定します。
rownames(data) <- c("条件B: 成功", "条件B: 失敗")
colnames(data) <- c("条件A: 成功", "条件A: 失敗")

# 作成したクロス集計表を出力します。
print(data)
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。この検定は、2x2のクロス集計表に対し、関連性または一貫性の評価に使用されます。
test_results <- mcnemar.test(data)

# マクネマー検定の結果を出力します。
print(test_results)
```

```{r, error=TRUE, include=TRUE}
# マクネマーのオッズ比を計算します。
odds_ratio <- (data[1, 1] * data[2, 2]) / (data[1, 2] * data[2, 1])

# マクネマーのオッズ比を出力します。
print(odds_ratio)
```

この例では、条件Aと条件B下での成功と失敗の頻度に差があるかどうかをマクネマー検定で評価しています。また、マクネマーのオッズ比により、これら二つの条件間の関連性の強度を評価しています。マクネマー検定のp値とマクネマーのオッズ比を用いて、二つの条件間に統計的に有意な差異および関連性が存在するかどうかを判断することが可能です。

## 実践

マクネマー検定の解析手順をRを用いて示します。

### 背景とデータの説明

「許す」または「許さない」の2つの異なるストーリーを聞いた後に、幼稚園の子供たちの行動がどのように変わるかを調査します。特に、ストーリーの内容によって、「一緒に遊ぶ」か「別々に遊ぶ」の選択がどれほど影響を受けるかを検証します。大阪府内の子供たちに便宜的サンプリングを行い、データを収集します。

- 母集団: 日本全国に在籍する全幼稚園児
- 標本: 大阪府の幼稚園に所属し、実際に2つのストーリーを聞いて反応を示した子供たち

### 仮説の設定

- 理論的仮説：ストーリーの内容は、子供たちが「一緒に遊ぶ」か「別々に遊ぶ」かの選択に影響を与える。
- 統計的仮説：
  - 帰無仮説 (H0): ストーリーの内容は子供たちの選択（「一緒に遊ぶ」か「別々に遊ぶ」か）に影響を与えない。
  - 対立仮説 (Ha): ストーリーの内容は子供たちの選択（「一緒に遊ぶ」か「別々に遊ぶ」か）に影響を与える。

### データの準備

- データの種類: 「ストーリー」（許す、許さない）と「選択」（一緒に遊ぶ、別々に遊ぶ）の2つのカテゴリカル変数を含む
- データの前処理: 欠損値や異常値が存在する場合は適切に処理します。欠損値は除去するか適切な値で補完し、異常値はデータの特性に基づいて適切に対応します。

```{r}
# CSVファイル"20230616_chap4sample3_RToda.csv"をread.csv関数を使用して読み込み、結果を"data"という変数に格納します。
data <- read.csv("20230616_chap4sample3_RToda.csv", header=TRUE)

# "data"データフレームの先頭の数行をhead関数を使用して表示します。これによりデータの概要を確認できます。
head(data)
```

```{r, error=TRUE, include=TRUE}
# "data"データフレームの構造をstr関数を使用して確認します。これにより、データの各列のタイプ、列数、行数などを確認できます。
str(data)
```

### 前提条件の検証

マクネマー検定を行う前には、以下の前提条件が満たされていることを確認する必要があります。

- データは対応のある二項的なデータ（成功/失敗、はい/いいえなど）であること。
- 各サブグループ（ここでは、各ストーリー）内の観測値は互いに独立であること。

データをクロス集計表にまとめて視覚的に確認します。

```{r, error=TRUE, include=TRUE}
# 交差表の作成
table_data <- with(data, table(Forgive, Reject))
table_data
```

### Rでの実行

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。correct=TRUEオプションを指定して、イェーツの補正を適用します。
# イェーツの補正とは二項分布が正規分布に近似するために行われる補正のことで、2×2の分割表のχ²検定に用いられます。特に標本サイズが小さい場合に有用です。
test_results <- mcnemar.test(table_data, correct=TRUE)

# マクネマー検定の結果をprint関数を用いて表示します。
print(test_results)
```

マクネマーのオッズ比を用いることで、ストーリーが子供たちの選択にどの程度影響を与えたかを定量的に評価することが可能となります。具体的には、オッズ比が1より大きければ、「許す」ストーリーが「許さない」ストーリーに比べて子供たちが「一緒に遊ぶ」選択をする可能性が高いことを示し、逆にオッズ比が1より小さければ、「許さない」ストーリーの方が子供たちが「一緒に遊ぶ」選択をする可能性が高いことを示します。

マクネマー検定のオッズ比とその95％信頼区間を計算します。

```{r, error=TRUE, include=TRUE}
# マクネマーのオッズ比を計算します。
odds_ratio <- (table_data[1, 1] * table_data[2, 2]) / (table_data[1, 2] * table_data[2, 1])

# オッズ比の対数を取得し、その標準誤差を計算します。
log_or <- log(odds_ratio)
se_log_or <- sqrt(1/table_data[1, 1] + 1/table_data[2, 2] + 1/table_data[1, 2] + 1/table_data[2, 1])

# オッズ比の95%信頼区間を計算します。
confint_log_or <- c(log_or - 1.96*se_log_or, log_or + 1.96*se_log_or)

# 対数スケールから元のスケールに戻します。
confint_or <- exp(confint_log_or)

# 結果を表示します。
print(c(odds_ratio, confint_or))
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 25, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "black") +
  labs(x = "McNemar's Chi-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# McNemar's Chi-squaredの値
mcnemars_chi_squared <- 16

# McNemar's Chi-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = mcnemars_chi_squared, linetype = "dashed", colour = "black") + 
  annotate("text", x = mcnemars_chi_squared, y = 3, 
           label = paste("McNemar's Chi-squared =", mcnemars_chi_squared, "(α = 6.334e-05)"),
           vjust = 4, hjust = 0.4, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 4, hjust = 0.4, colour = "red")

# プロットを表示
print(p)
```

### 視覚化

次のRコードは、「許す」ストーリーと「許さない」ストーリーのそれぞれについて、「一緒に遊ぶ」選択と「別々に遊ぶ」選択の回数を示す棒グラフを描くものです。

```{r, error=TRUE, include=TRUE}
# ForgiveとRejectのデータを統合し新しいデータフレームを作成
new_data <- data.frame(
  Type = rep(c("Forgive", "Reject"), each = nrow(data)),
  Story = c(data$Forgive, data$Reject)
)

# データの集計
data_agg <- table(new_data)

# 集計結果をデータフレームに変換
data_df <- as.data.frame(data_agg)
names(data_df) <- c("Type", "Story", "Count")

# 棒グラフの描画
ggplot(data = data_df, aes(x = Type, y = Count, fill = Story)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("blue", "orange")) +
  labs(x = "Type of Story", y = "Number of Children", fill = "Choice") +
  theme_minimal() +
  theme(text = element_text(size = 15))
```

### 結果の解釈

解析の結果、マクネマーのχ²検定を用いてχ²統計量が16、自由度が1、p値が6.334e-05となりました。このp値は0.05よりもはるかに小さいため、統計的に有意と判断できます。これにより、「一緒に遊ぶ」または「別々に遊ぶ」の選択が偶然だけによるものではないと結論づけられます。

さらに、オッズ比は1.2173913であり、その95%信頼区間は0.2083068から7.1147052にわたります。これは、「一緒に遊ぶ」選択をする可能性が「別々に遊ぶ」選択をする可能性に比べて約1.22倍高いことを示しています。この信頼区間は、同じ標本データと同じ手法を用いて無数に信頼区間を計算した場合、そのうちの95%がこの範囲に真のオッズ比を含んでいることを示しています。しかしながら、これは推定であり、真のパラメータが必ずしもこの範囲に含まれるわけではないことを理解することが重要です。信頼区間が非常に広いため、その影響の大きさに関して不確定性が高いことを示しています。

### 結果の報告（APAスタイル）

「マクネマーのχ²検定を使用し、子どもたちの選択（「一緒に遊ぶ」または「別々に遊ぶ」）がストーリーの結果に影響を与えるかを評価した。χ²(1) = 16, p < .001という結果が得られ、選択が偶然だけによるものではないと示した。さらに、オッズ比は1.22 (95% CI [0.21, 7.11])であり、「一緒に遊ぶ」選択をする可能性が「別々に遊ぶ」選択に比べて1.22倍高いと示した。ただし、この信頼区間の範囲は推定値の不確実性を示唆している。」

# 7. 同質性の検定

## 理論

χ²同質性検定は、異なるグループ間でカテゴリカルデータの分布が同一であるかどうかを評価するための統計的手法です。この検定は、「2 x C」、「R x 2」、「R x C」の形式で適用され、χ²統計量を用いて、異なるグループ間で各カテゴリの分布が一致しているかを判断します。

χ²値の計算式は次の通りです：

\[\chi^2 = \sum_{i=1}^{n} \frac{(O_i - E_i)^2}{E_i}\]

ここで、

- \(O_i\)は各セルの観測度数、
- \(E_i\)は各セルの期待度数、

をそれぞれ示しています。

χ²同質性検定では、効果量としてCramerのVが使用されます。これは統計的な結果の「大きさ」を評価する指標で、その計算式は以下のとおりです：

\[V = \sqrt{\frac{\chi^2}{n(k-1)}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)は標本サイズ（観測数）、
- \(k\)は二つの変数のカテゴリの数のうち少ない方、

をそれぞれ示しています。

データの形式は３通りあり、

- 「2 x C」形式は2つのカテゴリを持つ複数のグループに対して

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2つのグループがC個のカテゴリに分けられるデータの例
data_2xC <- data.frame(
  group = c(rep("Group 1", 3), rep("Group 2", 3)),
  category = rep(c("Cat 1", "Cat 2", "Cat 3"), 2),
  frequency = sample(1:10, 6, replace = TRUE)
)

print(data_2xC)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2 x C形式のデータセットのクロス集計表
crossTab_2xC <- with(data_2xC, table(group, category))
print(crossTab_2xC)
```

- 「R x 2」形式は2つのカテゴリを持つ複数のグループに対して

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R個のグループが2つのカテゴリに分けられるデータの例
data_Rx2 <- data.frame(
  group = rep(c("Group 1", "Group 2", "Group 3"), 2),
  category = rep(c("Cat 1", "Cat 2"), 3),
  frequency = sample(1:10, 6, replace = TRUE)
)

print(data_Rx2)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R x 2形式のデータセットのクロス集計表
crossTab_Rx2 <- with(data_Rx2, table(group, category))
print(crossTab_Rx2)
```

- 「R x C」形式はR個のグループがC個のカテゴリに分けられる場合

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R個のグループがC個のカテゴリに分けられるデータの例
data_RxC <- data.frame(
  group = rep(c("Group 1", "Group 2", "Group 3"), each = 3),
  category = rep(c("Cat 1", "Cat 2", "Cat 3"), 3),
  frequency = sample(1:10, 9, replace = TRUE)
)

print(data_RxC)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R x C形式のデータセットのクロス集計表
crossTab_RxC <- with(data_RxC, table(group, category))
print(crossTab_RxC)
```

にそれぞれ使用されます。

## 実践:「2 x C」のχ²同質性検定

「2 x C」形式のχ²同質性検定は、2つの群間でC個のカテゴリにおける分布が同一であるか否かを評価する統計手法です。カテゴリカルデータの群間分布を比較する際に有効です。

### 背景とデータの説明

子供の学習スタイルが年齢によって変化する可能性を調査します。具体的には、5歳と10歳の2つの年齢層が、視覚的、聴覚的、運動性の3つの異なる学習スタイルにどの程度分布するかを比較します。大阪府内の子供に対して便宜的サンプリングを行い、データを収集した場合を考えます。

- 母集団: 日本全国の5歳と10歳の子供全体
- 標本: 大阪府内の特定の地域に住む5歳と10歳の子供たち

### 仮説の設定

- 理論的仮説：5歳と10歳の子供たちの学習スタイルは異なる可能性がある。
- 統計的仮説：
  - 帰無仮説 (H0): 5歳と10歳の子供たちの間で学習スタイルの分布は同じである。
  - 対立仮説 (Ha): 5歳と10歳の子供たちの間で学習スタイルの分布は異なる。

### データの準備

カテゴリ（年齢群：5歳、10歳）とグループ（学習スタイル：視覚的、聴覚的、運動的）を生成します。次に、これらからデータフレームを作成します。

- データの種類: 「年齢」（5歳、10歳）と「学習スタイル」（視覚的、聴覚的、運動性）の2つのカテゴリカル変数
- データの前処理: 欠損値や異常値が存在する場合は適切に処理します。欠損値は除去するか適切な値で補完し、異常値はデータの特性に基づいて適切に対応します。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep("5 years old", 100), rep("10 years old", 100))
learning_style <- c(rep("Visual", 50), rep("Auditory", 30), rep("Kinesthetic", 20),
                    rep("Visual", 20), rep("Auditory", 30), rep("Kinesthetic", 50))

# データフレームを作成
data_2xC <- data.frame(age_group, learning_style)
```

### 前提条件の検証

χ²同質性検定を行う前には、以下の前提条件が満たされていることを確認する必要があります。

- 観測データはカテゴリカル（名義尺度または順序尺度）である。
- 各観測値は独立している。
- 期待度数が5以上の全てのセルが存在する。

まず、データをクロス集計表にまとめて視覚的に確認します。

```{r, error=TRUE, include=TRUE}
# クロス集計表を作成
cross_table <- table(data_2xC)
cross_table
```

次に、全てのセルの期待度数が5以上であることを確認します。

```{r, error=TRUE, include=TRUE}
# 期待度数の確認
expected_values <- chisq.test(cross_table)$expected
all(expected_values >= 5)
```

期待度数が5以上の全てのセルが存在しない場合、χ²同質性検定の結果の解釈には注意が必要です。その場合は、フィッシャーの正確検定、ヤーテスの補正、または尤度比検定のような別の適切な統計的手法を検討してください。

- **フィッシャーの正確検定**: 2x2のクロス集計表に特化した手法で、特にサンプルサイズが小さい場合や期待度数が5未満のセルが存在する場合に適しています。確率モデルに基づいているため、サンプルサイズが小さい場合でも精度の高い結果を提供します。

- **ヤーテスの補正**: 2x2のクロス集計表に対してχ²検定を行う際の補正手法で、サンプルサイズが小さく期待度数が5未満のセルが存在する場合に適用されます。χ²検定が真の値から過大評価されることを補正し、より精度の高い結果を得ることができます。

- **尤度比検定**: より一般的なカテゴリカルデータの検定手法で、2x2以上のクロス集計表に対しても適用可能です。サンプルサイズが大きい場合や、期待度数が一部のセルで5未満でも有効な結果を提供します。尤度比検定は、全体的なサンプルサイズが大きく、期待度数の小さいセルが含まれる場合に特に役立ちます。

### Rでの実行

Rのchisq.test関数を使用してχ²検定を実行し、結果を得ます。

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
chi_sq_result <- chisq.test(cross_table)

# χ²検定の結果を表示
print(chi_sq_result)
```

CramerのVを計算します。CramerのVは0から1までの値を取り、1に近いほど変数間の関連性が高いことを示します。

```{r, error=TRUE, include=TRUE}
# Cramer's Vを計算
n <- sum(cross_table)  # 標本サイズ
df <- min(dim(cross_table) - 1)  # 自由度
V <- sqrt(chi_sq_result$statistic / (n * df))

# Cramer's Vを表示
print(V)
```

CramerのVの信頼区間を計算します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージをロード
library(boot)

# Cramer's Vを計算する関数を定義
calc_cramerV <- function(data, indices) {
    sample_data <- data[indices, ]
    chi_sq_res <- chisq.test(sample_data)
    n <- sum(sample_data)
    df <- min(dim(sample_data) - 1)
    V <- sqrt(chi_sq_res$statistic / (n * df))
    return(V)
}

# ブートストラップ法を用いてCramer's Vの信頼区間を計算
bootstrap_results <- boot(data = cross_table, statistic = calc_cramerV, R = 1000)
boot_ci <- boot.ci(bootstrap_results, type = "bca")

# 信頼区間を表示
print(boot_ci)
```

```{r, error=TRUE, include=TRUE}
# 必要なライブラリの読み込み
library(ggplot2)

# パラメータ設定
df <- 2  # 自由度
x <- seq(0, 30, length.out = 1000)  # xの範囲を0から30に広げます
y <- dchisq(x, df)

# データフレーム作成
df_chi_sq <- data.frame(x = x, y = y)

# χ²分布のプロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(color = "black") +
  labs(title = "χ² distribution", x = "Value", y = "Density") +
  theme_minimal()

# テスト統計量の位置を表示
test_statistic <- 25.714  # 実際のテスト統計量
p_val <- 2.607e-06  # 実際のp値
p <- p +
  geom_vline(xintercept = test_statistic, linetype = "dashed", colour = "black") +
  annotate("text", x = test_statistic, y = max(df_chi_sq$y) * 0.2, 
           label = paste("χ² =", round(test_statistic, 3), "(p =", formatC(p_val, format = "e", digits = 3), ")"), 
           colour = "black", hjust = 0.5)

# 有意水準を表示
critical_value <- qchisq(0.95, df)  # 有意水準 0.05
p <- p +
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = max(df_chi_sq$y) * 0.2, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           colour = "red", hjust = 0.5)

# プロットの表示
print(p)
```

### 視覚化

バープロットを作成します。

```{r, error=TRUE, include=TRUE}
# バープロット
barplot(cross_table, beside = TRUE, col = c("blue", "red"), 
        legend = rownames(cross_table))
```

### 結果の解釈

χ²の統計量が25.714となり、p値は2.607e-06でした。また、Cramer's Vという効果量は0.3585686となりました。これらの結果から、5歳と10歳の子どもたちの学習スタイルの分布が期待される分布と有意に異なっていることが示されています。すなわち、子どもたちの学習スタイルの選択には年齢による違いが存在します。さらに、効果量であるCramer's Vが0.3585686という結果は、年齢と学習スタイルの間に中程度の関連性があることを示しています。ブートストラップによる信頼区間（95%）は[0.0000, 0.3586]となり、これは効果量の不確定性を示しています。この信頼区間は、同じ標本データと同じ手法を用いて無数に信頼区間を計算した場合、そのうちの95%がこの範囲に真のCramerのVを含んでいることを示しています。しかしながら、真のパラメータが必ずしもこの範囲に含まれるわけではないことを理解することが重要です。信頼区間が非常に広いため、影響の大きさに関する不確定性が高いことが示されています。

### 結果の報告（APAスタイル）

「χ²同質性検定を使用して5歳と10歳の2つの年齢群が視覚的、聴覚的、運動的の3つの学習スタイルにどのように分布するかを調査したところ、χ²(2) = 25.714, p < .001が得られ、帰無仮説（5歳と10歳の子供たちの学習スタイルの分布が同一である）が棄却された。効果量としてのCramer's Vは.359 (95% CI [0.00, 0.36])であり、年齢群と学習スタイルとの間には中程度の関連性があることが示された。これらの結果から、5歳と10歳の子供たちの学習スタイルの選択には有意な違いが存在すると結論付けられる。」

### フィッシャーの正確性検定（標本サイズが小さい場合）

標本サイズが小さい場合や、各セルの期待出現数が5未満の場合、χ²検定ではなくフィッシャーの正確性検定を用いることが推奨されます。フィッシャーの正確性検定は特に2x2の分割表に対して利用され、その結果は一般により信頼性が高いと考えられます。

#### データの準備

まず5歳と10歳の子供たちが視覚的か聴覚的な学習スタイルをどの程度選択するかのデータを生成します。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group_fisher <- c(rep("5 years old", 20), rep("10 years old", 20))
learning_style_fisher <- c(rep("Visual", 10), rep("Auditory", 10),
                    rep("Visual", 15), rep("Auditory", 5))

# データフレームを作成
data_2x2_fisher <- data.frame(age_group_fisher, learning_style_fisher)

# クロス集計表を作成
cross_table_fisher <- table(data_2x2_fisher)
cross_table_fisher
```

#### Rでの実行

フィッシャーの正確性検定はfisher.test()関数を用いて実行します。

```{r, error=TRUE, include=TRUE}
# Fisherの正確性検定を実行
result_fisher <- fisher.test(cross_table_fisher)

# 結果を出力
print(result_fisher)
```

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(ggplot2)
library(reshape2)

# データフレームを再構成して視覚化のための形式にする
cross_table_fisher_melted <- as.data.frame.table(cross_table_fisher)
names(cross_table_fisher_melted) <- c("Age Group", "Learning Style", "Count")
```

ヒートマップはデータの視覚化に非常に有用な手段で、各セルの色がそのセルの数値を表現します。色の強度（または色相）は数値の大きさに比例します。この場合、ヒートマップは学習スタイル（視覚的または聴覚的）と年齢グループ（5歳または10歳）間の関係を視覚化します。

具体的には、ヒートマップには2つのカテゴリ変数、「年齢群」（5歳または10歳）と「学習スタイル」（視覚的または聴覚的）が表示され、各セルの色はその年齢群と学習スタイルの組み合わせがデータセット内にどれだけ存在するか（カウント）を示します。

色が深いセルはその特定の年齢群と学習スタイルの組み合わせがデータセット内に多く存在することを示し、色が薄いセルはその組み合わせが少ないことを示します。例えば、10歳の群で視覚的学習スタイルのセルが最も色が深い場合、それは10歳の子供たちの中で視覚的学習スタイルを選択する人が最も多いことを示します。

また、プロットに注釈として付けられたp値はフィッシャーの正確性検定の結果を示し、年齢群と学習スタイルの選択の間に統計的に有意な関連性があるかどうかを示します。p値が一般的に受け入れられる有意水準（例えば0.05）よりも小さい場合、我々は年齢群と学習スタイルの選択の間に統計的に有意な関連性があると結論づけます。しかし、このケースでは、p値は0.1908であり、これは年齢群と学習スタイルの選択の間に統計的に有意な関連性はないという結果を示しています。

```{r, error=TRUE, include=TRUE}
# 結果を視覚化
ggplot(data = cross_table_fisher_melted, aes(x = `Age Group`, y = `Learning Style`, fill = Count)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Fisher's exact test for count data",
       x = "Age Group",
       y = "Learning Style",
       fill = "Count") +
  theme_minimal() +
  annotate("text", x = 1.5, y = 1.5, label = paste0("p-value = ", round(result_fisher$p.value, digits = 4)),
           size = 5, colour = "black")

# 注：上記のannotate()関数内のxとyの値は、テキストラベルが表示される位置を調整します。これらの値はデータやプロットの範囲によって調整が必要な場合があります。
```

#### 結果の解釈

フィッシャーの正確性検定の結果から、5歳と10歳の子どもたちの間で視覚的学習と聴覚的学習の選択に有意な違いが見られないという結果となりました。p値が0.1908となったことから、帰無仮説（5歳と10歳の子どもたちの間で視覚的学習と聴覚的学習の選択に差はないという仮説）が支持されました。

さらに、オッズ比は0.3429692であり、その95%信頼区間は0.06896679から1.51195380となりました。この信頼区間は、同じ標本データと同じ手法を用いて多数の信頼区間を計算した場合、その95%がこの範囲に真のオッズ比を含むことを示しています。しかし、真のパラメータが必ずしもこの範囲に含まれるとは限らないことを理解することが重要です。また、この信頼区間が比較的広範囲にわたることから、この効果の大きさに関しては一定の不確定性が存在すると考えられます。それは、10歳の子どもたちが視覚的学習を選択する確率が5歳の子どもたちと比べて約0.34倍であることを示していますが、この差が統計的に有意であるとは必ずしも言えません。

#### 結果の報告（APAスタイル）

「フィッシャーの正確性検定を用いて5歳と10歳の子供たちが視覚的または聴覚的な学習スタイルを選択する傾向に差があるかを検証した。その結果、二つの年齢群間で視覚的と聴覚的学習の選択に有意な違いは認められなかった（p = .19）。また、オッズ比は0.34 (95% CI [0.07, 1.51])で、これは10歳の子供たちが視覚的学習を選択する確率が5歳の子供たちと比較して約0.34倍であることを示している。しかしながら、この信頼区間が1を含んでいるため、この差が統計的に有意であるとは必ずしも言えない。信頼区間が比較的広範囲にわたることから、この効果の大きさに関しては一定の不確定性が存在すると考えられる。」

#### χ²検定との比較

フィッシャーの正確性検定は、標本サイズが小さい、または各セルの期待度数が5以下の場合に、χ²検定よりも優れた選択となります。χ²検定は大きな標本サイズや各セルの期待度数が十分に大きい場合に有効ですが、それらの条件が満たされない場合には、統計的検出力が低下するか、誤検出のリスクが増えます。

この例のデータセットでは、各セルの観測度数が5を超えているため、χ²検定でも適切な結果が得られる可能性があります。しかし、フィッシャーの正確性検定を使用することで、標本サイズが小さい、または期待度数が低いセルの影響を排除できます。そのため、このデータセットではフィッシャーの正確性検定がχ²検定よりも適していると言えます。

## 実践:「R x 2」のχ²同質性検定

「R x 2」形式のχ²同質性検定は、R個の異なるグループそれぞれが2つのカテゴリに分けられる場合に利用します。例えば、様々な家庭環境（一親家庭、両親家庭、祖父母と同居）で育った子供たちが学業成績（平均以上、平均未満）の2つのカテゴリにどのように分布しているかを検証する場合などです。

### 背景とデータの説明

3つの異なる家庭環境（一親家庭、両親家庭、祖父母と同居）で育った子供たちが、学業成績が平均以上か平均未満かという2つのカテゴリにどの程度分布しているかを調査します。大阪府内の子供に対して便宜的サンプリングを行い、データを収集した場合を考えます。

- 母集団: 日本の全ての家庭環境で育った子供全体
- 標本: 大阪府の様々な家庭環境で育った子供たち

### 仮説の設定

- 理論的仮説：家庭環境は子供の学業成績に影響を及ぼす。
- 統計的仮説：
  - 帰無仮説 (H0): 3つの家庭環境の子供たちの間で、学業成績の分布は等しい。
  - 対立仮説 (Ha): 3つの家庭環境のうち、少なくとも一つの家庭環境で子供たちの学業成績の分布が他と異なる。

### データの準備

- データの形式: 「家庭環境」（一親家庭、両親家庭、祖父母との同居）と「学業成績」（平均以上、平均未満）の2つのカテゴリを有するカテゴリカルデータ
- データ前処理: 欠損値や異常値が存在する場合は適切に処理します。欠損値は除去するか適切な値で補完し、異常値はデータの特性を考慮して対応します。

```{r, error=TRUE, include=TRUE}
# グループとカテゴリを生成
family_environment <- rep(c("Single Parent", "Both Parents", "Living with Grandparents"), times = c(60, 70, 70))
academic_performance <- c(rep("Above Average", 40), rep("Below Average", 20), 
                          rep("Above Average", 20), rep("Below Average", 50), 
                          rep("Above Average", 10), rep("Below Average", 60))

# データフレームを作成
data_Rx2 <- data.frame(FamilyEnvironment = family_environment, AcademicPerformance = academic_performance)
```

### 前提条件の検証

χ²同質性検定を行う前には、以下の前提条件が満たされていることを確認する必要があります。

- 観測データはカテゴリカルであること。
- 各標本（観測値）は独立していること。
- 全てのセル（クロス集計表の各要素）で期待度数が5以上であること。

まず、データをクロス集計表にまとめて視覚的に確認します。

```{r, error=TRUE, include=TRUE}
# クロス集計表を作成
cross_table <- table(data_Rx2$FamilyEnvironment, data_Rx2$AcademicPerformance)

# クロス集計表を表示
print(cross_table)
```

次に、全てのセルの期待度数が5以上であることを確認します。

```{r, error=TRUE, include=TRUE}
# χ²検定を実行し、期待度数を取得
result_Rx2 <- chisq.test(cross_table)

# 全てのセルの期待度数が5以上であることを確認
all(result_Rx2$expected >= 5)
```

もし期待値が5未満のセルがある場合、検定結果の解釈には慎重さが必要となります。その場合、フィッシャーの正確検定やヤーテスの補正、尤度比検定などの他の統計的手法を考慮することが推奨されます。

### Rでの実行

χ²検定を実行し、結果を表示します。

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_Rx2 <- chisq.test(cross_table)

# 結果を表示
print(result_Rx2)
```

さらにCramerのVを計算します。CramerのVは0から1までの値を取り、1に近いほど変数間の関連性が高いことを示します。

```{r, error=TRUE, include=TRUE}
# χ²値を取得
chi_squared <- result_Rx2$statistic

# 標本サイズ（全観測値の数）を取得
n <- sum(cross_table)

# 列数と行数を取得
k <- ncol(cross_table)
r <- nrow(cross_table)

# Cramér's Vを計算
V = sqrt((chi_squared/n) / (min(k-1, r-1)))

# Cramér's Vを表示
print(V)
```

CramerのVの信頼区間を計算します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージのロード
library(boot)

# Cramer's Vを計算する関数の定義
calc_cramerV <- function(data, indices) {
    sample_data <- data[indices, ]
    chi_sq_res <- chisq.test(sample_data)
    n <- sum(sample_data)
    df <- min(dim(sample_data) - 1)
    V <- sqrt(chi_sq_res$statistic / (n * df))
    return(V)
}

# ブートストラップ法を用いたCramer's Vの信頼区間の計算
bootstrap_results <- boot(data = cross_table, statistic = calc_cramerV, R = 1000)
boot_ci <- boot.ci(bootstrap_results, type = "bca")

# 信頼区間の表示
print(boot_ci)
```

```{r, error=TRUE, include=TRUE}
# 必要なライブラリの読み込み
library(ggplot2)

# パラメータ設定
df <- 2  # 自由度
x <- seq(0, 120, length.out = 1000)  # xの範囲を0から120に広げます
y <- dchisq(x, df)

# データフレーム作成
df_chi_sq <- data.frame(x = x, y = y)

# χ²分布のプロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(color = "black") +
  labs(title = "χ² distribution for Family Environment vs. Academic Performance", 
       x = "Value", 
       y = "Density") +
  theme_minimal()

# テスト統計量の位置を表示
test_statistic <- 100  # 実際のテスト統計量
p_val <- 2.2e-16  # 実際のp値
p <- p +
  geom_vline(xintercept = test_statistic, linetype = "dashed", colour = "black") +
  annotate("text", x = test_statistic, y = max(df_chi_sq$y) * 0.2, 
           label = paste("χ² =", round(test_statistic, 3), "(p < 2.2e-16)"), 
           colour = "black", hjust = 0.5)

# 有意水準を表示
critical_value <- qchisq(0.95, df)  # 有意水準 0.05
p <- p +
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = max(df_chi_sq$y) * 0.2, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           colour = "red", hjust = 0.2)

# プロットの表示
print(p)
```

### 視覚化

```{r, error=TRUE, include=TRUE}
# クロス集計表を棒グラフで表示
barplot(cross_table, beside = TRUE, col = gray.colors(3, start = 0.4, end = 0.8), legend.text = rownames(cross_table), args.legend = list(x = "topright"), xlab = "Family Environment", ylab = "Count", main = "Distribution of Academic Performance by Family Environment")
```

#### 結果の解釈

「R x 2」のχ²同質性検定とCramér's Vの計算を用いて、「家庭環境は子供の学業成績に影響を及ぼす」という理論的仮説を統計的に検証しました。検証に使用した帰無仮説は、「3つの家庭環境の子供たちの間で、学業成績の分布は等しい」としました。それに対して対立仮説は「3つの家庭環境のうち、少なくとも一つの家庭環境で子供たちの学業成績の分布が他と異なる」と設定しました。

χ²検定の結果、χ²(2, N = 150) = 25.714, p < .001となりました。これは帰無仮説を棄却し、対立仮説を支持する結果となります。すなわち、少なくとも1つの家庭環境は子供たちの学業成績の分布に統計的に有意な影響を及ぼしていると解釈できます。さらに、Cramér's Vの値は0.452と計算され、この値に関する95%ブートストラップ信頼区間は (0.000, 0.5238) となりました。この信頼区間は、同じ標本データと手法を用いて複数回信頼区間を計算した場合に、その95%がこの範囲に真のCramér's Vを含むことを示しています。ただし、真の値が必ずしもこの範囲に含まれるとは限らないことに注意が必要です。この信頼区間の幅が広いため、影響の大きさに対する不確定性が高いとも言えます。それでも、これらの結果は家庭環境が子供の学業成績に影響を及ぼし、それぞれの家庭環境で学業成績の分布が異なる可能性が高いことを示唆しています。

#### 結果の報告（APAスタイル）

「χ²同質性検定の結果、χ²(2, N = 150) = 25.714, p < .001となり、家庭環境が学業成績の分布に統計的に有意な影響を与えていることが示された。また、Cramér's Vは0.452と算出され、95%ブートストラップ信頼区間は (0.000, 0.5238) であった。この信頼区間は、同じデータと手法で無数の信頼区間を計算した場合、その95%がこの範囲に真のCramér's Vを含むことを示している。ただし、真の値が必ずしもこの範囲に含まれるわけではないことを理解することが重要である。これらの結果は、家庭環境と学業成績の間に実質的な関連性が存在することを示している。」

## 実践:「R x C」のχ²同質性検定

「R x C」形式のχ²同質性検定は、R個の群とC個のカテゴリーを比較する際に使用します。これはカテゴリカルデータの分布の一致性を検証する統計的手法で、複数の群とカテゴリが存在する場合のデータセットの分析に適用されます。

### 背景とデータの説明

子供の学習スタイルが年齢によってどの程度変化するかを検証します。具体的には、5歳、10歳、15歳の3つの年齢層の子供たちが視覚的、聴覚的、運動性という3つの学習スタイルにどの程度分布しているかを調査します。データは大阪府の子供を対象とした便宜的サンプリングにより収集します。

- 母集団: 日本全国の5歳、10歳、15歳の子供全体
- 標本: 大阪府の学校で調査を行い、各年齢層の学習スタイルの分布を代表すると考えられる子供たち

### 仮説の設定

- 理論的仮説：年齢は子どもたちの学習スタイルに影響を及ぼす可能性がある。
- 統計的仮説：
  - 帰無仮説 (H0): 5歳、10歳、15歳の子供たちの間で、学習スタイル（視覚的、聴覚的、運動性）の分布は同じである。
  - 対立仮説 (Ha): 少なくとも一つの年齢群の子供たちにおいて、学習スタイル（視覚的、聴覚的、運動性）の分布が他の年齢群と異なる。

### データの準備

以下のコードでは、年齢群と学習スタイルのカテゴリデータを生成し、それらを組み合わせたデータフレームを作成します。

- データの形式: 「年齢群」（5歳、10歳、15歳）と「学習スタイル」（視覚的、聴覚的、運動性）の2つのカテゴリカル変数を含む
- データ前処理: 欠損値や異常値が存在する場合は適切に処理します。欠損値は除去するか適切な値で補完し、異常値はデータの特性に基づいて適切に対応します。

```{r, error=TRUE, include=TRUE}
# 年齢群と学習スタイルを生成
age_group <- c(rep("5 years", 80), rep("10 years", 120), rep("15 years", 100))
learning_style <- c(rep("Visual", 40), rep("Auditory", 20), rep("Kinesthetic", 20),
                    rep("Visual", 20), rep("Auditory", 50), rep("Kinesthetic", 50),
                    rep("Visual", 20), rep("Auditory", 40), rep("Kinesthetic", 40))

# データフレームを作成
data_RxC <- data.frame(age_group, learning_style)
```

### 前提条件の検証

χ²同質性検定を行う前には、以下の前提条件が満たされていることを確認する必要があります。

- 観測データはカテゴリカルであること。
- 各標本（観測値）は独立していること。
- 全てのセル（クロス集計表の各要素）で期待度数が5以上であること。

まず、データをクロス集計表にまとめて視覚的に確認します。

```{r, error=TRUE, include=TRUE}
# クロス集計表を作成
cross_table <- table(data_RxC)

# クロス集計表を表示
print(cross_table)
```

次に、全てのセルの期待度数が5以上であることを確認します。

```{r, error=TRUE, include=TRUE}
# 期待度数の確認
expected_values <- chisq.test(cross_table)$expected
all(expected_values >= 5)
```

期待度数が5未満のセルが存在する場合、検定結果の解釈には注意が必要となります。次の代替的手法を検討することができます。

- **カテゴリの再分類**: 期待度数が5未満のカテゴリを組み合わせて、新たなカテゴリを作成し、それにより期待度数5未満のセルの数を減らす。
- **モンテカルロ法を使用したχ²検定**: サンプリング分布が理論的にわかっていない場合や、理論的な分布からの乖離が大きい場合に適用されます。
- **尤度比検定**: χ²検定と比較してより一般的な状況に適用でき、期待度数が低いセルがあっても使用することができます。

これらの手法は、研究の背景や目的、および使用可能なデータに応じて選択する必要があります。

### Rでの実行

以下のコードでχ²検定を実行し、結果を表示します。

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_RxC <- chisq.test(cross_table)

# 結果を表示
print(result_RxC)
```

CramerのVを計算します。CramerのVは0から1までの値を取り、1に近いほど変数間の関連性が高いことを示します。

```{r, error=TRUE, include=TRUE}
# 効果量（Cramer's V）を計算
n <- sum(cross_table)  # 全観察数
k <- min(nrow(cross_table), ncol(cross_table))  # 行数または列数の小さい方

V <- sqrt(result_RxC$statistic / (n*(k-1)))

# 効果量を表示
print(V)
```

CramerのVの信頼区間を計算します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージのロード
library(boot)

# Cramer's Vを計算する関数の定義
calc_cramerV <- function(data, indices) {
    sample_data <- data[indices, ]
    chi_sq_res <- chisq.test(sample_data)
    n <- sum(sample_data)
    df <- min(dim(sample_data) - 1)
    V <- sqrt(chi_sq_res$statistic / (n * df))
    return(V)
}

# ブートストラップ法を用いたCramer's Vの信頼区間の計算
bootstrap_results <- boot(data = cross_table, statistic = calc_cramerV, R = 1000)
boot_ci <- boot.ci(bootstrap_results, type = "bca")

# 信頼区間の表示
print(boot_ci)
```

```{r, error=TRUE, include=TRUE}
# 必要なライブラリの読み込み
library(ggplot2)

# パラメータ設定
df <- 2  # 自由度
x <- seq(0, 120, length.out = 1000)  # xの範囲を0から120に広げます
y <- dchisq(x, df)

# データフレーム作成
df_chi_sq <- data.frame(x = x, y = y)

# χ²分布のプロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(color = "black") +
  labs(title = "χ² distribution for Family Environment vs. Academic Performance", 
       x = "Value", 
       y = "Density") +
  theme_minimal()

# テスト統計量の位置を表示
test_statistic <- 100  # 実際のテスト統計量
p <- p +
  geom_vline(xintercept = test_statistic, linetype = "dashed", colour = "black") +
  annotate("text", x = test_statistic, y = max(df_chi_sq$y) * 0.2, 
           label = paste("χ² =", round(test_statistic, 3), "(p < 2.2e-16)"), 
           colour = "black", hjust = 0.5)

# 有意水準を表示
critical_value <- qchisq(0.95, df)  # 有意水準 0.05
p <- p +
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = max(df_chi_sq$y) * 0.2, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           colour = "red", hjust = 0.2)

# プロットの表示
print(p)
```

### 視覚化

年齢群別に学習スタイルの分布を可視化します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込みます
library(ggplot2)

# バープロットを作成します
ggplot(data_RxC, aes(x=age_group, fill=learning_style, pattern=learning_style)) +
  geom_bar(position="dodge", color="black", size=1) +
  scale_fill_grey(start = 0.8, end = 0.2) +
  theme_bw() +
  theme(
    text = element_text(size=20),
    legend.key.size = unit(1.5, "cm")
  ) +
  labs(x="Age Group", y="Count", fill="Learning Style", pattern="Learning Style",
       title="Distribution of Learning Styles by Age Group")
```

### 結果の解釈

χ²同質性検定の結果から、子供の年齢と学習スタイルの分布に有意な関連性が見られます。具体的には、p値が0.001より小さいことから、帰無仮説（すなわち、全ての年齢群における学習スタイルの分布が等しい）を棄却し、対立仮説（すなわち、最低でも1つの年齢群で学習スタイルの分布が他と異なる）を採択します。

さらに、効果量（Cramér's V）は0.23と算出され、95%ブートストラップ信頼区間は (0.000, 0.2434) でした。この信頼区間は、同じデータと手法で無数の信頼区間を計算した場合、その95%がこの範囲に真のCramér's Vを含むことを示しています。しかし、真の値が必ずしもこの範囲に含まれるわけではないことを理解することが重要です。効果量の値は、二つの変数間の統計的な関連性の強さを示す指標で、その値が大きいほど、関連性が強いと解釈されます。この場合、年齢と学習スタイルの間には一定の関連性が存在することが示唆されています。

これらの結果は、子供の学習スタイルが年齢によって変化する可能性があることを示しています。

### 結果の報告（APAスタイル）

「χ²同質性検定によると、年齢と学習スタイルの分布間に有意な関連性が見られました，χ²(4, N = 180) = 30.682, p < .001。また、Cramér's Vは0.23と算出され、95%ブートストラップ信頼区間は (0.000, 0.2434) であり、これは年齢と学習スタイル間に一定の関連性が存在することを示しています。これらの結果から、子供の年齢は学習スタイルの分布に影響を及ぼす可能性があることが示されました。」

# 8. 多重比較

多重比較は、一度に複数の仮説検定を実行することを指します。主に、「事前に計画された比較」（Planned Comparisons）と「事後的な比較」（Post-hoc Comparisons）の2つに分類されます。

- **事前に計画された比較（Planned Comparisons）**: これは実験が開始される前に特定の比較が行われることが既に決定している状況を示します。通常、研究者が特定の効果やパターンを予想している際に行います。

- **事後的な比較（Post-hoc Comparisons）**: これはデータ分析の過程で新たに明らかになった結果を詳細に調査するために実施される比較を指します。これらの比較は、元々の仮説には含まれず、新たに得られた観察結果に基づいて行われます。事後的な比較では、多重比較による誤検出のリスクを緩和するため、調整されたp値が一般的に使用されます。

多重比較は、単に偶然による偽陽性（実際には存在しない効果が検出される誤り）のリスクが増えるという問題を孕んでいます。この問題を解消するためには、多重比較補正という手法が用いられ、その中でもいくつかの主要な調整方法が提唱されています。

## 有意水準の調整方法

1. ボンフェローニ補正 (Bonferroni correction): 全ての比較の数でp値を割ることで、偽陽性のリスクを減らします。しかし、厳格すぎるために実際には有意である結果を偽陰性（存在する効果を検出できない誤り）と判断するリスクも増大します。

2. ホルム補正 (Holm correction): ボンフェローニ補正を改良し、全てのp値を小さい順に並べ、それぞれにボンフェローニ補正を適用します。これにより偽陽性のリスクを抑えつつ、偽陰性のリスクも低減します。

3. ベンジャミニ＆ホッホベルク法 (Benjamini & Hochberg method): 偽陽性の「割合」を制御する方法で、全てのp値を小さい順に並べ、それぞれのp値に（その順位/全比較数）*目標FDRを掛けた値を新たなp値とします。

4. チューキーのHSD法 (Tukey's HSD method): ANOVA（分散分析）後の多重比較に有効で、全てのペア間の比較を行います。

## 独立性の検定と多重比較補正の使用例

この例では、ある幼稚園で男女各100名の子どもたち（合計200名）に、3種類のおもちゃ（A、B、C）の中からどれが一番好きかを選択させ、子どもたちの性別とおもちゃの選択に有意な関連性があるかどうかをχ²検定で評価します。その結果に対して多重比較補正を適用し、性別ごとのおもちゃの選択の違いを詳しく検証します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(readr)
library(dplyr)

# データを読み込む
data <- read_csv("20230616_chap4practice_RToda.csv")
head(data)
```

```{r, error=TRUE, include=TRUE}
# データ型の確認
str(data)
```

```{r, error=TRUE, include=TRUE}
# データフレームから性別とおもちゃの選択についてのクロス集計表を作成
contingency_table <- table(data$gender, data$choice)
contingency_table
```

```{r, error=TRUE, include=TRUE}
# χ²独立性検定を実施
chisq_res <- chisq.test(contingency_table)

# p値を取得
p_value <- chisq_res$p.value

# ボンフェローニ補正、ホルム補正、ベンジャミニ＆ホッチベルク補正（BH補正）を適用してp値を補正
bonferroni <- p.adjust(p_value, method = "bonferroni")
holm <- p.adjust(p_value, method = "holm")
BH <- p.adjust(p_value, method = "BH")

# 補正後のp値を表示
data.frame(Bonferroni = bonferroni, Holm = holm, BH = BH)
```

```{r, error=TRUE, include=TRUE}
# 性別ごとのおもちゃの選択の違いを詳しく調査するため、ペアワイズのχ²検定を実施
choices <- unique(data$choice)
pairs <- combn(choices, 2)
pairwise_chisq <- sapply(1:ncol(pairs), function(i) {
  subdata <- data %>% filter(choice %in% pairs[,i])
  chisq_res <- chisq.test(table(subdata$gender, subdata$choice))
  chisq_res$p.value
})

# 各ペア間のχ²検定のp値を補正
bonferroni_pairwise <- p.adjust(pairwise_chisq, method = "bonferroni")
holm_pairwise <- p.adjust(pairwise_chisq, method = "holm")
BH_pairwise <- p.adjust(pairwise_chisq, method = "BH")

# 補正後のペアワイズp値を表示
pairwise_df <- data.frame(Pairs = apply(pairs, 2, paste, collapse = " vs "), 
                          Bonferroni = bonferroni_pairwise, 
                          Holm = holm_pairwise, 
                          BH = BH_pairwise)

pairwise_df
```

これらの結果を通じて、性別ごとのおもちゃの選択の違いを明らかにすることができ、また、その違いが統計的に有意であるかどうかを多重比較補正を用いて評価することができます。

## 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例

一元配置分散分析（ANOVA）は、一つ以上の要因が群間での平均値の差異を引き起こすかどうかを評価するための統計的手法です。さらに、チューキーのHSD法を利用することで、具体的な群間の差を明らかにすることができます。ここでは、これらの方法を用いて、特定の介入がスコアにどのような影響を及ぼすかを調査する例を示します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(agricolae)

# 再現可能なランダムな結果を得るために乱数シードを設定
set.seed(123)

# データフレームを作成。Intervention列に"A", "B", "C"を、Score列には異なる平均値と標準偏差をもつ正規分布から抽出したスコアを割り当てる
data <- data.frame(
  Intervention = rep(c("A", "B", "C"), each = 50),
  Score = c(rnorm(50, mean = 80, sd = 10),
            rnorm(50, mean = 85, sd = 10),
            rnorm(50, mean = 90, sd = 10))
)
head(data)
```

```{r, error=TRUE, include=TRUE}
# Intervention列の影響をスコアに対して評価するために一元配置ANOVAを適用する
model <- aov(Score ~ Intervention, data = data)

# ANOVAの結果を表示
summary(model)
```

```{r, error=TRUE, include=TRUE}
# チューキーのHSD法を用いて具体的な群間比較を行う
HSD_result <- HSD.test(model, 'Intervention', group = TRUE)

# 結果を表示
print(HSD_result)
```

この例では、ANOVAを使用して教育介入（A、B、C）が学生のスコアに対してどのような影響を及ぼしているかを評価します。その後、チューキーのHSD法を用いて各介入間のスコアの差を明らかにします。ANOVAの結果にかかわらず、チューキーのHSD法は介入効果の具体的な違いを理解するために用いられます。ただし、ANOVAの結果が非有意の場合、その結果を過度に解釈することは避けるべきです。

## マクネマー検定と多重比較補正の使用例

教育介入方法A、B、Cが子供の行動にどれほど影響を及ぼすかを評価します。それぞれの教育介入についてマクネマー検定を行い、得られたp値に対してボンフェローニ補正、ホルム補正、そしてベンジャミニ＆ホッホベルグ法を適用します。これらの補正は、多重比較によって誤って有意な結果と判断されるリスクを軽減するためのものです。

なお、チューキーのHSD法はANOVAの結果に対する多重比較補正として使用される手法で、マクネマー検定に対しては直接適用することはできません。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込み
library(stats)

# 結果の再現性を確保するためのシード設定
set.seed(123)

# 各教育介入方法についてデータ生成
before_A <- sample(c(0, 1), 100, replace = TRUE)
after_A <- sample(c(0, 1), 100, replace = TRUE)
before_B <- sample(c(0, 1), 100, replace = TRUE)
after_B <- sample(c(0, 1), 100, replace = TRUE)
before_C <- sample(c(0, 1), 100, replace = TRUE)
after_C <- sample(c(0, 1), 100, replace = TRUE)

# 各方法についてマクネマー検定の実施
mcnemar_res_A <- mcnemar.test(before_A, after_A)
mcnemar_res_B <- mcnemar.test(before_B, after_B)
mcnemar_res_C <- mcnemar.test(before_C, after_C)

# p値の取得
p_values <- c(mcnemar_res_A$p.value, mcnemar_res_B$p.value, mcnemar_res_C$p.value)

# 各補正法によるp値の調整
bonferroni <- p.adjust(p_values, method = "bonferroni")
holm <- p.adjust(p_values, method = "holm")
BH <- p.adjust(p_values, method = "BH")

# 元のp値と補正後のp値を表示するためのデータフレームを作成
result_df <- data.frame(
  Method = c("A", "B", "C"),
  p_value = p_values,
  p_value_bonferroni = bonferroni,
  p_value_holm = holm,
  p_value_BH = BH
)

# 結果を表示
print(result_df)
```

これらの結果を通じて、各教育介入方法が子供の行動に与える影響の有意性を複数の補正法に基づいて評価することができます。これにより、個々の教育介入方法の効果をより厳密に解釈することが可能になります。

# 参考ページ:

- [統計学の時間 - パラメトリックとノンパラメトリック](https://bellcurve.jp/statistics/course/1562.html)

- [Study Channel - パラメトリックとノンパラメトリック](https://www.study-channel.com/2015/06/parametric-nonparametric-test.html)

- [日経調査研究所 - χ²検定](https://service.nikkei-r.co.jp/glossary/chi-square-test/)

- [Best Biostatistics - 自由度の理解](https://best-biostatistics.com/contingency/degree-freedom.html)

- [統計学の時間 - χ²適合度検定](https://bellcurve.jp/statistics/course/9494.html)
