---
title: "χ²検定の基礎と実践 by 戸田梨鈴"
author: "まとめ by 金山篤志"
date: "2023-06-16"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
  ioslides_presentation:
    toc: true
  word_document:
    toc: true
  beamer_presentation:
    toc: true
    latex_engine: xelatex
  pdf_document:
    toc: true
    latex_engine: xelatex
header-includes:
  - \usepackage{xeCJK}
  - \setCJKmainfont{Hiragino Mincho Pro}
---

```{r, error=TRUE, echo=FALSE}
# これはRのオプション設定コマンドです。CRANのミラーサイトとして"https://cloud.r-project.org/"を指定しています。
# CRANとはComprehensive R Archive Networkの略で、Rのパッケージが保存されているリポジトリです。
options(repos = c(CRAN = "https://cloud.r-project.org/"))

# "ggplot2"というパッケージをインストールします。Rのパッケージは、特定の機能や手法を利用するための一連の関数とデータセットを含んでいます。
# "ggplot2"はグラフィカルなデータ表示に広く使用されるパッケージです。
# "quiet = TRUE"は、インストールの途中経過やメッセージを表示しないようにするオプションです。
install.packages(c("ggplot2"), quiet = TRUE)

# ここで"ggplot2"パッケージを読み込みます。これにより、このパッケージに含まれる関数やデータセットがRセッションで使用可能になります。
# library関数は、パッケージの関数やデータをRの作業環境に読み込むためのものです。
library(ggplot2)
```

目次

1. 概要
2. t分布
   - 定義
   - 特性
   - 自由度
3. t検定
   - χ²検定の種類
   - χ²検定の手順
4. 単一サンプルt検定
   - パラメトリック: 一標本t検定 (One-sample t-test)
   - ノンパラメトリック: サインテスト (Sign test)、ウィルコクソンの符号順位検定 (Wilcoxon signed-rank test)
5. 二群間のt検定
   - パラメトリック: 
      - 独立二群間のt検定 (Independent two-sample t-test), ウェルチのt検定 (Welch's t-test)
   - ノンパラメトリック: 
      - マン・ホイットニーU検定 (Mann-Whitney U test)
6. 対応のある二群間のt検定
   - パラメトリック: 対応のある二群間のt検定 (Paired two-sample t-test)
   - ノンパラメトリック: ウィルコクソンの符号順位検定 (Wilcoxon signed-rank test)
7. 多変量t検定
   - パラメトリック: ホッチングのt検定 (Hotelling's T-square test)
   - ノンパラメトリック: 各変数を個別に分析するためのノンパラメトリックな方法 (多変量に対する直接的なノンパラメトリックな同等物は存在しない)
8. 回帰分析のt検定
   - パラメトリック: 回帰係数のt検定 (t-test in regression)
   - ノンパラメトリック: 順序回帰分析 (Ordinal logistic regression), ブートストラップ法など
9. 多重比較t検定
   - パラメトリック: 多重比較t検定 (Multiple comparisons t-tests)
   - ノンパラメトリック: ボンフェロニ法 (Bonferroni method), ダンの補正 (Dunn's test)など
10. 相関のt検定
   - パラメトリック: ピアソンの相関係数のt検定 (t-test for Pearson correlation)
   - ノンパラメトリック: スピアマンの順位相関係数 (Spearman's rank correlation coefficient), ケンドールの順位相関係数 (Kendall's tau)
11. 外れ値に対する堅牢なt検定
   - パラメトリック: トリム平均t検定 (Trimmed Mean t-test), ロバストt検定 (Robust t-test)
   - ノンパラメトリック: YuenのT検定 (Yuen's T-test), M推定量法 (M-estimators)など
12. 不確実性を考慮したt検定
   - パラメトリック: ブートストラップt検定 (Bootstrap t-test)
   - ノンパラメトリック: パーセンタイルブートストラップなど

# 1. 概要

t検定は、カテゴリー型のデータ（例：男性か女性、成功か失敗など）の関連性を調べるための統計的手法です。また、実際のデータが理論的な分布とどれだけ合っているかを確かめる際にも使われます。

この検定は、いわゆる「ノンパラメトリック」（無母数）検定として知られており、その特長は以下の通りです：

- **特定の分布を前提としない**： χ²検定では、データが正規分布などの特定の分布に従っている必要がありません。データがどのように分布しているかにかかわらず、この検定を利用することができます。

- **尺度に依存しない**： データが何らかのランクや順序を持っている必要はなく、χ²検定はχ²という統計量を使ってデータの関連性を評価します。これにより、データの尺度にとらわれることなく分析が行えます。

- **度数に着目**： χ²検定は、カテゴリごとの観測回数（度数）と理論上期待される度数との間の違いを考慮します。これらの違いはχ²の値としてまとめられ、データがどれだけ理論的な分布に従っているかを判断するのに用います。

χ²検定は、データの特定の形状にとらわれることなく、「データが特定の理論的な分布に従っているかどうか」を調査する（これを適合度検定と呼びます）または、カテゴリ間の関連性を検証する（これを独立性検定と呼びます）ための非常に便利な方法です。χ²検定を利用する際に重要なことは、データが特定の確率分布に厳密に従う必要はない、という点です。しかし、データと理論の違いを数値化する「χ²統計量」は、特定のパターン（つまりχ²分布）に従うという前提があります。この前提を把握しておくことで、検定結果の解釈とその有効性が適切に理解できます。
   
# 2. χ²分布

χ²分布は統計学や確率論の分野で広く採用されている確率分布であり、統計的検定や信頼区間の推定など、多くの応用に重要な役割を果たします。このセクションでは、χ²分布の基本的な概念、特性、そして自由度との関係について解説します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なパッケージをロードします
library(ggplot2)

# カイ二乗分布のデータを生成します
x <- seq(0, 20, length.out = 1000)
density <- dchisq(x, df = 4)

# データフレームに変換します
df <- data.frame(
  x = x,
  density = density
)

# グラフをプロットします
ggplot(df, aes(x, density)) +
  geom_line(color = "blue") +
  theme_minimal() +
  labs(x = "Value", y = "Density", 
       title = "Chi-Squared Distribution with df = 4")
```

## 定義

χ²分布は、複数の独立した標準正規分布（平均0、分散1の正規分布）の二乗和が従う確率分布と理解できます。詳しくは、k個の独立した標準正規分布の値をそれぞれ二乗し、その結果を足し合わせたものが、自由度kのχ²分布に従うということです。

ここで、\(Z_1\), \(Z_2\), ..., \(Z_k\)は互いに独立した標準正規分布（平均0、分散1の正規分布）に従うとします。これらを二乗して足し合わせると、その和Xは自由度kのχ²分布に従います。

\[ X = Z_1^2 + Z_2^2 + ... + Z_k^2 \]

次のグラフでは、ヒストグラムが2つの独立した標準正規分布の二乗和のデータ分布を、滑らかな曲線が自由度2の理論的なχ²分布をそれぞれ表現しています。このグラフから、二乗和がχ²分布に従う様子を視覚的に理解することが可能です。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# Rコード
library(ggplot2)

# 標準正規分布からサンプルを取得
n_samples <- 10000
z1 <- rnorm(n_samples, 0, 1)
z2 <- rnorm(n_samples, 0, 1)

# 二乗して足し合わせる
chi_square <- z1^2 + z2^2

# プロットにヒストグラムと理論的なχ²分布を表示
p <- ggplot() +
  geom_histogram(data = data.frame(chi_square), aes(x = chi_square, y = after_stat(density)), bins = 50, alpha = 0.5) +
  stat_function(fun = dchisq, args = list(df = 2), aes(color = "Theoretical Chi-Square Distribution"), linewidth = 1) +
  labs(title = "Sum of Squares of Two Independent Standard Normal Distributions",
       x = "Value",
       y = "Density",
       color = "Legend") +
  theme_minimal()

# プロットを表示
print(p)
```

## 特性

χ²分布は以下のような特性を持っています。

- **0以上の値**: χ²分布は0以上の値しか取りません。これは、正規分布の二乗和として定義されるため、負の値が出現しないからです。
- **形状と自由度**: χ²分布の形状は自由度に依存します。自由度が増えるにつれて、χ²分布は徐々に正規分布に近づき、ピークは右にシフトします。
- **平均と分散**: χ²分布の平均は自由度と等しく、分散は自由度の2倍です。

χ²分布は以下のような用途があります。

- **χ²検定**:χ²検定は、カテゴリカルデータに基づいて、2つのカテゴリカル変数間の関連性や観測データが特定の理論的分布に従っているかどうかを評価するために使用されます。χ²検定では、観測された頻度と期待される頻度の間の差異をχ²統計量で評価し、この統計量をχ²分布と比較して検定を行います。

- **分散の信頼区間の計算**:χ²分布は、分散の信頼区間の計算に頻繁に使用されます。特に、正規分布の母集団分散の信頼区間を推定する際にχ²分布が活用されます。サンプルデータから得られたχ²統計量を用いて、分散の信頼区間を求めます。

- **統計モデルの評価**:統計モデルの適合度を評価する際にもχ²分布は使われます。例えば、ロジスティック回帰モデルの適合度を評価する際の尤度比検定では、その統計量がχ²分布に従うことが知られています。これにより、統計モデルがデータにどれほど良く適合しているか、またそのモデルが信頼できるのかを判断することが可能となります。

- **モンテカルロシミュレーション**:モンテカルロシミュレーションなどの確率的なシミュレーションを行う際に、特定の自由度を持つχ²分布に基づいて乱数を生成し、それをシミュレーションの一部として使用します。

- **発達心理学における使用**:
発達心理学では、成長曲線のモデリングにχ²分布が用いられることがあります。例えば、身長の成長曲線をモデリングする際、子供の成長の観察データと理論的な成長曲線の適合性を評価するためにχ²統計量とその分布が使用されます。これにより、理論的な成長曲線が観察データにどれほど良く適合しているかを評価します。

## 自由度

自由度は、制約のない独立した情報の総量を示す概念で、具体的には他のパラメータや制約に影響されずに選択できる変数の数を指します。自由度は、統計的仮説検定の精度を計算するためや、特定の確率分布（χ²分布、t分布、F分布など）の形状を定義するために使用されます。

以下に、個々のデータ値と統計モデルの観点から自由度について考察します。

- **個々のデータ値における自由度**: 各データ点は自由度を1つ持っています。しかし、すべてのデータ点が完全に自由であるわけではありません。例えば、3つの数値が与えられ、それらの平均が0であるとすると、最初の2つの数値は自由に選べますが、3つ目の数値は他の2つによって制約されます。つまり、この場合の自由度は2となります。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 最初の2つの数値を指定します
x1 <- 4
x2 <- -2

# 平均が0になるように3つ目の数値を計算します
x3 <- - (x1 + x2)

# 数値と平均値を出力します
cat("Numbers: ", x1, x2, x3, "\n")
cat("Mean: ", mean(c(x1, x2, x3)), "\n")
```

- **統計モデルにおける自由度**: 一方、統計モデルの自由度は、そのモデルのパラメータの数によって決まります。例えば、線形回帰モデルの場合、直線のフィットは y = ax + b の形で表現されます。ここでaとbはパラメータで、データから推定されます。したがって、このモデルの自由度は、観測値の数（n）からパラメータ数（2つ、aとb）を引いた n-2 となります。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 乱数生成の初期値を設定
set.seed(123)

# データを生成
n <- 100  # データの数
x <- runif(n, 0, 10)
y <- 2*x + 3 + rnorm(n)

# 線形回帰モデルを作成
model <- lm(y ~ x)

# 自由度を計算し、出力します
df <- n - length(coef(model))
cat("Degrees of freedom: ", df, "\n")
```

このコードでは乱数を用いてデータを生成し、それを用いて線形回帰モデルを作成しました。このモデルの自由度はデータの数（この場合、100）からパラメータの数（この場合、2）を引いた値です。

自由度は、特定の確率分布（χ²分布、t分布、F分布など）の形状を決定する重要な要素でもあります。自由度が増えると、これらの分布は正規分布に近づきます。これは、自由度が大きくなるほど利用可能な情報量が増え、結果の信頼性が向上するためです。この性質は中心極限定理と密接に関連しています。

### 自由度の計算例

χ²検定においては、自由度の計算方法は特定の公式に従います。具体的には、カテゴリカルなデータに対するχ²検定では、自由度は観測データの行と列の数から計算します。この場合、「（行数-1）×（列数-1）」の公式を用いて自由度が計算されます。

例えば、2x2の観測データ（例：行と列がそれぞれ2つのカテゴリを持つクロス集計表）がある場合、自由度は「(2-1) x (2-1) = 1」となります。つまり、1つの自由な変動が可能なパラメータが存在します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2の観測データを作成します。
observed <- matrix(c(10, 20, 30, 40), nrow = 2)

# 行数と列数を取得します。
num_rows <- nrow(observed)
num_cols <- ncol(observed)

# 自由度を計算します。
df <- (num_rows - 1) * (num_cols - 1)

# 結果を表示します。
cat("自由度は:", df, "\n")
```

### 自由度と分布の形状

χ²分布の形状は、その自由度により決まります。自由度とは、統計的な解析で自由に変動できる値の数を示します。

自由度が1のχ²分布は、原点から離れたところでピークを持ち、右に偏った形状を示します。しかし、自由度が増加すると、分布の形状は徐々に正規分布に近づき、ピークも原点から遠くに移動します。つまり、自由度が増えると、分布は右にシフトし、分布の広がり（すなわち、分布のばらつき）が増加します。

次のグラフは自由度が1から10までのχ²分布を描画し、自由度が増加するにつれて分布の形状がどのように変わるかを視覚的に示したものです。

```{r, error=FALSE, echo=FALSE}
# 自由度が1から10までのχ²分布のプロット
df_list <- list()
for (df in 1:10) {
  df_list[[df]] <- data.frame(x = seq(0, 30, length.out = 1000), 
                              y = dchisq(seq(0, 30, length.out = 1000), df), 
                              df = factor(df))
}
df_all <- do.call(rbind, df_list)

# χ²分布の描画
ggplot(df_all, aes(x = x, y = y, color = df)) +
  geom_line() +
  labs(x = "Value", y = "Density", color = "Degrees of Freedom") +
  coord_cartesian(ylim = c(0, 0.6)) + # y軸の範囲を0から0.75に制限します。
  theme_minimal() + # シンプルなデザインにします。
  ggtitle("Degrees of Freedom 1-10: Chi-square Distributions")
```

自由度が増えるとχ²分布は右にシフトし、徐々に正規分布に近づいていくことがわかります。

### 自由度と検定の結果

χ²検定の結果は、自由度に強く影響されます。自由度が変われば、χ²検定の結果も必然的に変化します。今回、3x3と2x2の異なる観測データセットを用いて、自由度の違いがχ²検定結果にどのように影響を及ぼすかを評価します。

まず、3x3の観測データセットを用いてχ²検定を行い、次に2x2の観測データセットで同じ検定を実施し、それぞれの結果を比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# dplyrパッケージの読み込み
library(dplyr)

# 3x3観測データの作成
observed2 <- matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90), nrow = 3)
cat("3x3観測データ:\n")
print(observed2)

# 3x3データを用いたχ²検定の実行
chisq_result2 <- chisq.test(observed2)

# χ²値、p値、自由度の表示
cat("3x3データに対するχ²値: ", chisq_result2$statistic, "\n")
cat("3x3データに対するp値: ", chisq_result2$p.value, "\n")
cat("3x3データに対する自由度: ", chisq_result2$parameter, "\n")
```

続いて、2x2のデータセットを用いて同様のχ²検定を行います。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2x2観測データの作成
observed <- matrix(c(10, 20, 30, 40), nrow = 2)
cat("2x2観測データ:\n")
print(observed)

# 2x2データを用いたχ²検定の実行
chisq_result <- chisq.test(observed)

# χ²値、p値、自由度の表示
cat("2x2データに対するχ²値: ", chisq_result$statistic, "\n")
cat("2x2データに対するp値: ", chisq_result$p.value, "\n")
cat("2x2データに対する自由度: ", chisq_result$parameter, "\n")
```

これらの結果を元に、自由度の違いがχ²検定結果（χ²値とp値）にどのように影響するかを比較します。

```{r, error=FALSE, echo=FALSE, message=FALSE}
# パッケージの読み込み
library(tidyr)

# 比較用のデータフレームの準備
data <- data.frame(
  Test = c("3x3", "2x2"),
  DegreesOfFreedom = c(chisq_result2$parameter, chisq_result$parameter),
  ChiSquareValue = c(chisq_result2$statistic, chisq_result$statistic),
  PValue = c(chisq_result2$p.value, chisq_result$p.value)
)

# プロット用のデータ整形
data_plot <- data %>%
  pivot_longer(cols = -Test, names_to = "Metric", values_to = "Value") %>%
  mutate(Metric = factor(Metric, levels = c("DegreesOfFreedom", "ChiSquareValue", "PValue")),
         Metric = case_when(
           Metric == "DegreesOfFreedom" ~ "Degrees of Freedom",
           Metric == "ChiSquareValue" ~ "Chi-square Value",
           Metric == "PValue" ~ "p-value"
         ))

# Metricの順序を指定
data_plot$Metric <- factor(data_plot$Metric, levels = c("Degrees of Freedom", "Chi-square Value", "p-value"))

# χ²値、p値、自由度の比較用バープロットの作成
p <- ggplot(data_plot, aes(x = Test, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  scale_fill_brewer(palette = "Set2", name = "") +
  labs(x = "Dataset", y = "Value", fill = "") +
  facet_wrap(~ Metric, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom", 
        plot.title = element_text(hjust = 0.5),
        axis.title.x = element_text(size = 14, face = "bold"),
        axis.title.y = element_text(size = 14, face = "bold")) +
  ggtitle("Comparison of 3x3 and 2x2 Datasets")

# バープロットの表示
p
```

自由度はχ²検定の結果（χ²値とp値）に以下のように影響を与えます：

- **χ²値**：自由度が増えると、χ²値の範囲（すなわち、可能な最小値と最大値）も増えます。これは、より多くのセル（つまり自由度が高い）を持つテーブルでは、観測された値と期待される値との間により大きな差が生じる可能性が高まるためです。

- **p値**：p値は、観測された（またはより極端な）データが、帰無仮説が真であるという前提のもとで生じる確率を示します。自由度が増えると、χ²分布の形状が変わり（具体的には、分布が右にシフトし、広がりが大きくなります）、これによりp値も変化します。特定のχ²値が与えられたとき、自由度が高いほどそのχ²値を得る確率は高くなり、したがってp値は大きくなります。

# 3. χ²検定

χ²検定は、2つ以上のカテゴリカルデータ間の独立性や、一組の観測データが特定の理論的な分布に従っているかどうかを検定するための統計手法です。これはカテゴリカルなデータに対する統計的検定の一つで、観測された頻度分布が期待される頻度分布と有意に異なるかどうかを判断することが目的です。

## χ²検定の種類

χ²検定は主に以下の3つの目的で使用されます：

1. **適合度検定**：観測されたデータの分布が予想される特定の理論的な分布に適合するかどうかを評価します。
2. **独立性検定**：2つのカテゴリカル変数が互いに独立しているか、関連しているかを調べます。
3. **同質性の検定**：異なる群間でカテゴリカルデータの分布が同じであるかどうかを検定します。

## χ²検定の手順

1. **問題の理解と仮説の設定**:
    - 分析の目的を明確にし、適切なχ²検定（適合度検定、独立性検定、または同質性検定）を選択します。
    - 帰無仮説（H0）と対立仮説（H1）を設定します。
      - 適合度検定
        - **帰無仮説（H0）**：観測された頻度分布は期待される頻度分布に適合する。
        - **対立仮説（H1）**：観測された頻度分布は期待される頻度分布に適合しない。
      - 独立性検定
        - **帰無仮説（H0）**：2つのカテゴリカル変数は独立である。
        - **対立仮説（H1）**：2つのカテゴリカル変数は独立ではない。
      - 同質性の検定
        - **帰無仮説（H0）**：異なる群間でのカテゴリカルデータの分布は同じである。
        - **対立仮説（H1）**：少なくとも1つの群でカテゴリカルデータの分布が異なる。
2. **前提条件の検証**:
    - サンプルデータはランダムに選ばれているか？
    - データはカテゴリカルまたは順序尺度か？
    - 各カテゴリの観測値は独立しているか？
    - 各カテゴリの期待度数は5以上か？（もし期待度数が5未満のセルがある場合は、Yatesの補正やフィッシャーの正確検定を検討する）

3. **χ²統計量の計算**:
    - χ²値は、観測された頻度と期待される頻度との間の差を考慮して計算されます。
    - 検定により期待度数の計算方法は異なります:
       - 適合度検定では、期待度数は理論的な分布に基づいて計算されます。
       - 独立性検定では、期待度数は全体の頻度分布に基づいて計算されます。
       - マクネマー検定では、
       - 同質性検定では、期待度数は各グループ内の頻度分布に基づいて計算されます。

4. **p値の計算**:
    - χ²分布表または統計ソフトウェアを使用し、算出されたχ²値と自由度（通常は「カテゴリ数 - 1」）に基づきp値を計算します。
    - χ²検定の結果を報告する際には、χ²値、自由度（分析の柔軟性を示す要素）、そしてp値（結果が偶然から生じた可能性）を含めるのが一般的です。
    
5. **効果量の計算の計算**:
    - χ²検定の結果だけでなく、その検定結果がどれほど実質的な影響を持つのかを示す効果量を評価することも重要です。ここでは、一部の検定における主要な効果量を挙げますが、実際の研究状況や分析目的によっては他の種類の効果量を使用することもあります。
    - 効果量の計算方法はχ²検定の種類によって異なります:
       - 1変量のχ²検定（適合度の検定）: 主要な効果量としてCohenのwがありますが、状況によっては他の指標を使用することもあります。
       - 2変量のχ²検定（独立性の検定）: 一般的な効果量としてCramerのVがあります。また、2つの二項変数間の相関を測定するためにφ係数（phi coefficient）を使用することもあります。
       - フィッシャーの直接確率検定: 一般的にオッズ比やリスク比が用いられますが、相対リスク（Relative Risk）など他の指標も参考にされることがあります。
       - マクネマー検定: マクネマーのオッズ比が主要な効果量ですが、一対の値についての変化の程度を測定するモノメンチのΔ（McNemar's Delta）も用いられます。
       - 同質性の検定:「2 x C」、「R x 2」、「R x C」のデータ形式では、効果量としてCramér's VやPhi係数が用いられます。これらの指標は、カテゴリ間の関連性の強さを示します。

6. **結果の解釈**:
    - χ²検定の結果は、χ²値、自由度、p値、そして効果量（例えばCramer's V）を用いて報告されます。p値が有意水準（通常は0.05）以下であれば、帰無仮説を棄却し、観測された頻度分布と期待される頻度分布との間に有意な差があると結論づけます。
    - p値が所定の有意水準より大きい場合、帰無仮説が採用されます。
    - 効果量が大きいと、観測された変数間の関連性が強いことを示します。逆に、効果量が小さいと、関連性が弱いか、もしくは無関係であることを示します。これは、p値が有意であっても、その関連性が実際には弱い、つまり「統計的に有意だが実質的には無意味」である可能性を示しています。

以下に、χ²検定の使用に際して考慮すべきいくつかのポイントを示します：

- χ²検定はカテゴリカルデータに対してのみ適用可能です。連続データにχ²検定を適用することは不適切です。
- 期待度数が極端に小さい（通常5未満）場合、χ²検定の結果の信頼性は低下します。このような状況では、データの再分類を行うか、別の統計的手法を検討する必要があります。
- χ²検定は、サンプルデータが母集団から無作為に選択されることを前提としています。これを満たしていない場合、検定結果は偏っている可能性があります。
- χ²検定は、群間の差異が存在するかどうかを判断するのに有用ですが、その差異がどれほど意義深いか（効果量）については判断しないため、効果量の評価も重視する必要があります。
- χ²検定は帰無仮説の正しさを評価しますが、帰無仮説が棄却された理由を特定するものではありません。帰無仮説が棄却された場合、その理由を探るために追加の分析が必要となります。


# 4. 1変量のχ²検定（適合度の検定）

## 理論

1変量のχ²検定（適合度の検定）は、観測されたデータの分布が特定の理論的な分布（一般には、帰無仮説で述べられた期待される結果に基づく分布）に合致しているか否かを評価する手法です。同時に、効果量を用いることで、統計的な有意性だけでなく、結果の大きさや重要性も評価します。


χ²値は以下の公式に従って計算されます：

\[ \chi^2 = \sum \frac{(O_i - E_i)^2}{E_i} \]

ここで、

- \(O_i\)はi番目のカテゴリの観測された頻度、
- \(E_i\)はi番目のカテゴリの期待される頻度、

を示しています。

このχ²値は観測頻度と期待頻度間の差異の大きさを統計的に評価します。各カテゴリで観測頻度と期待頻度の差を二乗し、それを期待頻度で割ります。これにより各カテゴリにおける差異の相対的な大きさが求まり、それらを全て足し合わせることでχ²値を算出します。

χ²値の大きさは、観測データが期待値からどれだけ逸脱しているかを示します。この値が大きければ大きいほど、観測データは期待値から大きく逸脱していると解釈されます。これは観測データに何らかの効果が存在する可能性を示唆します。

効果量としては、Cohenのwが一般的に用いられます。Cohenのwの計算式は次のようになります：

\[ w = \sqrt{\frac{\chi^2}{N}} \]

ここで、

- \(\chi^2\)はχ²値、
- \(N\)は全サンプル数、

を示しています。

Cohenのwはカイ二乗統計量を全サンプル数で正規化し、その結果の平方根を計算します。これにより、標本サイズの影響を排除しています。

Cohenのwは標準化された効果量として位置づけられ、統計的な有意性だけでなく、その結果が実質的にどれほど重要であるか、つまり効果の大きさを評価するために使用されます。この指標は観測データが期待分布からどれだけ逸脱しているかを示し、その逸脱度の大きさを理解するために利用されます。

公平な6面のサイコロを60回投げるシナリオを考えてみましょう。理論的には、各面が出る回数は10回（60回 / 6面）と期待できます。しかし、実際の結果は必ずしも10回とは限りません。その差異が大きいほどχ²統計量は大きくなります。

p値が特定の閾値（通常は0.05）以下であれば、観測データが期待分布から統計的に有意に異なると判断されます。

以下に、Rを用いたχ²検定の例と効果量の計算を示します。

```{r, error=TRUE, include=TRUE}
# 乱数生成の初期値を設定
set.seed(123)

# 1から6までの数字（サイコロの目）をランダムに60回選ぶ
# 選択は置換あり（選ばれた数値を再度選ぶことが可能）
# 選択された数値を因子として扱う
# 各因子レベル（サイコロの目）が選ばれた回数（頻度）を集計
roll_results <- table(factor(sample(1:6, size = 60, replace = TRUE), levels = 1:6))

# サイコロを60回投げた結果を表示
print(roll_results)

# 各面が出る期待頻度を定義
# 各面が出る期待値は10回
expected_frequencies <- rep(10, 6)

# χ²検定を実行
# 検定は実際の結果（roll_results）と期待頻度（expected_frequencies）を比較
test_results <- chisq.test(roll_results, p = expected_frequencies / 60)

# χ²検定の結果を表示
print(test_results)

# 効果量 (Cohen's w) を計算
effect_size <- sqrt(test_results$statistic / sum(roll_results))
print(effect_size)
```

上記のコードでは、公平な6面のサイコロを60回投げる結果をシミュレートしています。その後、期待頻度（各面が10回出ると期待される）と観測頻度を用いてχ²検定を実行します。p値を確認することで、観測データが期待する分布（この場合、各面が等確率で出るとする分布）から統計的に有意に異なるかどうかを判断します。最後に、効果量（Cohenのw）を計算し、検定結果の大きさを評価します。

## 実践

Rを用いてχ²適合度検定を実行する具体的な解析手順を示します。

### 例示の背景

この例では、幼稚園の子供たちが「幼稚園は好きですか？」という質問に「はい」または「いいえ」で答える場合を想定します。

### 仮説の設定

- 理論的仮説：特定の年齢層の子供たちが「幼稚園は好きですか？」という質問に「はい」または「いいえ」で答える確率は50%ずつである。

- 統計的仮説：
  - 帰無仮説 (H0): 観測された分布は期待される分布（この場合は、はいといいえの確率が等しい）に従っている。
  - 対立仮説 (Ha): 観測された分布は期待される分布に従っていない。

### データの準備

```{r, error=TRUE, include=TRUE}
# CSVファイル '20230616_chap4sample1_RToda.csv' を読み込みます。結果はデータフレームx1に格納されます。
x1 <- read_RToda.csv("20230616_chap4sample1_RToda.csv", header=T)

# データフレームx1の先頭6行を表示します。これにより、データの概観を把握します。
head(x1)
```

```{r, error=TRUE, include=TRUE}
# Answer列のデータを因子型に変換します。これは統計分析でよく使用されるデータ型で、カテゴリーデータを扱うのに適しています。
# labels引数を用いて、0を'No'、1を'Yes'に対応させます。
x1$Answer <- factor(x1$Answer, labels=c('No','Yes')) 

# 変換後のAnswer列のデータを表示します。これにより、変換が正しく行われたことを確認します。
print(x1$Answer)
```

### 前提条件の検証

χ²検定の前提条件は、各カテゴリの期待頻度が5以上であることです。

```{r, error=TRUE, include=TRUE}
# Answer列のデータを用いて、'No'と'Yes'の回答数を集計します。結果はクロス集計表x1tableに格納されます。
x1table <- table(x1$Answer)

# クロス集計表x1tableを表示します。これにより、各カテゴリの頻度を確認します。
print(x1table) 
```

### Rでの実行

```{r, error=TRUE, include=TRUE}
# chisq.test関数を用いてχ²適合度検定を実行します。観測データが期待する分布にどの程度適合しているかを評価します。結果はtest_resultsに格納されます。
test_results <- chisq.test(x1table)

# テスト結果を表示します。これにより、p値やχ²統計量などの情報を得ます。
print(test_results)
```

```{r, error=TRUE, include=TRUE}
# 効果量 (Cohen's w) を計算します。これは検定結果の効果の大きさを評価するための指標です。
effect_size <- sqrt(test_results$statistic / sum(x1table))

# 効果量 (Cohen's w) を表示します。これにより、結果の解釈に役立つ情報を得ます。
print(effect_size)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 10, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "black") +
  labs(x = "Chi-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# Chi-squaredの値
chi_squared <- 5

# Chi-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = chi_squared, linetype = "dashed", colour = "black") + 
  annotate("text", x = chi_squared, y = 3, 
           label = paste("Chi-squared =", chi_squared, "(α = 0.02535)"), 
           vjust = 0, hjust = 0.1, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 0, hjust = 0.9, colour = "red")

# プロットを表示
print(p)
```

p値が0.05より小さい場合、観測されたデータが期待される分布と有意に異なると解釈されます。

### 視覚化

```{r, error=TRUE, include=TRUE}
# pie関数を用いて、クロス集計表のデータを利用して円グラフを作成します。円グラフは 'No'と'Yes'が全体に占める割合を視覚的に表示します。
pie(x1table, main="Pie Chart of Answers", col=c("lightblue", "pink"))
```

```{r, error=TRUE, include=TRUE}
# barplot関数を用いて、クロス集計表のデータを利用して棒グラフを作成します。棒グラフは各カテゴリ（'No'と'Yes'）の観測数を直観的に比較するのに適しています。
barplot(x1table, main="Number of 'No' and 'Yes'", xlab="Answer", ylab="Count", col=c("lightblue", "pink"))
```

### 結果の解釈

この解析結果から、χ²統計量が5、自由度が1、p値が0.02535という結果が得られました。通常、p値が0.05以下であれば、統計的に有意と判断され、帰無仮説を棄却します。今回のp値は0.02535であるため、0.05より小さく、統計的に有意です。したがって、「はい」または「いいえ」の回答の分布は、期待される分布（「はい」と「いいえ」の確率が均等）と有意に異なると結論付けることができます。

さらに、効果量（Cohen's w）が0.5と計算されました。効果量は、結果の「大きさ」を定量化するための統計的な手段であり、p値だけでは捉えられない情報を提供します。Cohen's wの値は0から無限大までの範囲を持ち、値が大きいほど効果の大きさが大きいことを示します。このケースでは、Cohen's wが0.5という結果は、回答の分布が期待される均等な分布から中程度にずれていることを示しています。しかし、ここでのCohen's wの解釈は一般的なガイドラインに過ぎず、実際は具体的な研究領域の先行研究で報告された効果量と比較する必要があります。

### 結果の報告

「特定の年齢層の子どもたちに対して"幼稚園は好きですか？"という質問を行い、その回答が均等に分布しているかどうかをχ²適合度検定で評価した。この分析は、回答の分布が均等であるという仮説を支持しなかった, χ²(1) = 5.00, p = .03。さらに、効果量（Cohen's w）は0.5であり、回答の分布は期待される均等な分布から中程度にずれていた（ただし、この効果量の解釈は一般的なガイドラインに過ぎず、実際の解釈には関連する先行研究との比較が必要です）。これらの結果は、子どもたちの幼稚園に対する感情が一様でない可能性を示唆している。」

# 5. 2変量のχ²検定（独立性の検定）

2変量のχ²検定は、二つのカテゴリカル変数が互いに独立、つまり一方が他方に影響を与えないかどうかを評価する統計的手法です。

## 理論

χ²検定の帰無仮説は、「二つの変数は独立である」です。つまり、一つの変数の値がもう一つの変数の値に影響を与えないという仮説を検証します。

χ²統計量は次の式で求められます:

\[\chi^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}\]

ここで、

- \(O_{ij}\)はi番目とj番目のカテゴリの組み合わせの観測頻度、
- \(E_{ij}\)はi番目とj番目のカテゴリの組み合わせの期待頻度、

を示しています。

帰無仮説（2つの変数が独立である）が正しい場合、χ²統計量は小さな値になることが期待されます。逆に、χ²統計量が特定の閾値を超えた場合、帰無仮説は棄却され、2つの変数間に何らかの関連性が存在するとされます。

χ²検定は、2つの変数の独立性を評価するためのものですが、これらの変数間の関連性の強さを定量的に評価するためには別の指標が必要です。その指標としてよく用いられるのがフィルの係数とCramerのVです。

フィルの係数は2x2クロス表、つまり2つの二項変数間の相関を測定します。その計算式は以下の通りです。

\[\Phi = \sqrt{\frac{\chi^2}{n}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)はサンプルサイズ（観測数）

をそれぞれ表します。

一方、CramerのVは、2つのカテゴリカル変数間の関連性の度合いを0から1までの値で表したもので、2x2表だけでなく、より大きな次元（2×2以上）のクロス表に対して使用することができます。値が0であれば変数間には全く関連性がないことを示し、1であれば変数間が完全に関連していることを示します。

CramerのVの計算式は次の通りです：

\[V = \sqrt{\frac{\chi^2}{n(k-1)}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)はサンプルサイズ（観測数）、
- \(k\)は二つの変数のカテゴリの数のうち少ない方、

をそれぞれを示しています。

CramerのVは、これら3つの要素を組み合わせたものであり、χ²統計量が大きければ大きいほど、またサンプルサイズが小さければ小さいほど、Vの値が大きくなります。一方、カテゴリの数が増えると、Vの値は減少します。これはカテゴリの数が増えると、各カテゴリ間の関連性が一般的に弱くなることを反映しています。

これら全ての要素が組み合わさることで、CramerのVは2つのカテゴリカル変数間の関連性の強さを0から1の範囲で表現しています。

以下に、Rを用いてχ²検定を実行し、関連性の強さをCramerのVで評価する例を示します：

```{r, error=TRUE, include=TRUE}
# 再現性を確保するためのシード値を設定
set.seed(123) 

# それぞれが3つのカテゴリを持つ2つのカテゴリカル変数のデータを生成
var1 <- sample(c("A", "B", "C"), size = 100, replace = TRUE)
var2 <- sample(c("X", "Y", "Z"), size = 100, replace = TRUE)

# 2つの変数のクロス集計表を作成
data <- table(var1, var2)

# χ²検定を実行
test_result <- chisq.test(data)

# χ²値を表示
test_result$statistic

# p値を表示
test_result$p.value

# CramerのVを計算
V <- sqrt(test_result$statistic / (sum(data) * (min(dim(data)) - 1)))

# CramerのVを表示
V
```

このコードは、2つのカテゴリカル変数からなるデータセットを生成し、その後でχ²検定を実行して2つの変数間の独立性を評価します。出力されるp値を見て、変数間に統計的に有意な関連性があるかどうかを判断します。そして、CramerのVを計算することで関連性の強さを評価します。変数がそれぞれ複数のカテゴリを持つため、この例ではフィルの係数ではなくCramerのVが用いられています。

## 実践

Rを用いてχ²独立性検定を実行する具体的な解析手順を示します。

### 例示の背景

この例では、小学校の児童が授業が面白いかどうかについての意見（「同意」または「不同意」）と、その児童の性別（「男性」または「女性」）との間に関連性があるかどうかを調査します。

### 仮説の設定

- 理論的仮説：児童の性別は、授業に対する意見に影響を及ぼす。
- 統計的仮説
  - 帰無仮説 (H0): 性別と授業に対する意見の間には関連性がない（独立である）。
  - 対立仮説 (Ha): 性別と授業に対する意見の間には関連性がある。

### データの準備

まずは、CSVファイル '20230616_chap4sample2_RToda.csv' を読み込み、データの構造を確認します。

```{r, error=TRUE, include=TRUE}
# CSVファイルの読み込み
x2 <- read_RToda.csv("20230616_chap4sample2_RToda.csv", header=T) 

# データの一部を表示
head(x2)
```

```{r, error=TRUE, include=TRUE}
# データ構造の確認
str(x2)
```

### 前提条件の検証

χ²検定を実行する前に、各カテゴリの期待頻度が5以上であることを確認します。このためにクロス集計表を作成します。

```{r, error=TRUE, include=TRUE}
# クロス集計表の作成
x2matrix <- with(x2, table(gender, answer))

# 表示
x2matrix
```

### Rでの実行

以下のコードでχ²独立性検定を実行し、結果を表示します。

```{r, error=TRUE, include=TRUE}
# χ²独立性検定の実行
result <- chisq.test(x2matrix) 

# 結果の表示
print(result)

# Cramer's Vの計算
V <- sqrt(result$statistic / (sum(x2matrix) * (min(dim(x2matrix)) - 1)))

# Cramer's Vの表示
print(V)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 10, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "black") +
  labs(x = "X-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# X-squaredの値
x_squared <- 6.416

# X-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = x_squared, linetype = "dashed", colour = "black") + 
  annotate("text", x = x_squared, y = 3, 
           label = paste("X-squared =", x_squared, "(α = 0.01131)"), 
           vjust = 1, hjust = 0.3, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 1, hjust = 0.7, colour = "red")

# プロットを表示
print(p)
```

### 視覚化

```{r, error=TRUE, include=TRUE}
barplot(x2matrix, beside = TRUE, col = c("lightblue", "salmon"), 
        legend.text = rownames(x2matrix), ylim = c(0, max(x2matrix)*1.2), 
        ylab = "Counts", xlab = "Opinions", main = "Chi-Square Test of Independence")
```

### 結果の解釈

p値は0.01131であり、これは一般的に用いられる有意水準0.05を下回るものです。したがって、統計的に有意と判断し、帰無仮説（性別と授業評価の間に関連性がない）を棄却し、対立仮説（性別と授業評価の間に関連性がある）を受け入れることができます。これは性別と授業評価との間に有意な関連性があり、男女の性別が授業評価に影響を及ぼす可能性を示しています。

加えて、クラメールのVは0.4005であり、これは性別と授業評価の間に中程度の関連性があることを示唆しています。ただし、この効果量の解釈は一般的なガイドラインに過ぎず、実際の解釈には関連する先行研究との比較が必要であることを忘れてはなりません。特定の文脈や研究領域における関連性の大きさが何を意味するのかを理解するためには、以前の研究結果と比較することが重要です。

### 結果の報告

「χ²独立性検定を使用して、小学生の性別（男性、女性）と授業評価（同意、不同意）の間の関連性を評価した。検定結果は、χ²(1) = 6.416, p = .011、となり、性別と授業評価の間に有意な関連性が存在することを示している。クラメールのVの値は0.4005であり、性別と授業評価の間に中程度の関連性があることを示している（ただし、この効果量の解釈は一般的なガイドラインに過ぎず、具体的な解釈は先行研究との比較を必要とします）。したがって、性別は授業評価に影響を及ぼす可能性があることが示唆された。」

## フィッシャーの正確性検定（サンプルサイズが小さい場合）

サンプルサイズが小さい場合は、Fisherの正確性検定を使用することで、より信頼性のある結果を得ることができます。

### データの準備

ここでは、同じデータセットを用いてχ²検定とフィッシャーの正確確率検定の結果を比較します。それぞれの検定結果がどれほど異なるのか、そしてその結果がどのように解釈できるのかを理解することが目的です。

### Rでの実行

フィッシャーの直接確率検定はRの fisher.test() 関数を使用して計算します。

```{r, error=TRUE, include=TRUE}
# フィッシャーの正確確率検定の実行
fisher_result <- fisher.test(x2matrix) 

# 結果の表示
print(fisher_result)
```

### 結果の解釈

フィッシャーの正確確率検定により、p値が0.01039となりました。この値は通常用いられる有意水準0.05よりも小さいため、性別と授業評価の間には統計的に有意な関連性が存在すると推定できます。さらに、オッズ比（odds ratio）は6.614723と求まり、その95%信頼区間は1.457116から35.737819にわたります。オッズ比とは効果量の指標の一種であり、この値は性別が授業評価に6.614723倍の影響を与えることを示しています。これは性別が授業評価に対して大きな影響を及ぼす可能性があることを示唆しています。

しかし、オッズ比とその信頼区間の解釈は注意が必要です。信頼区間が広範囲にわたる（1.457116から35.737819）場合、効果量の不確実性が高いことを示しています。つまり、性別が授業評価に及ぼす影響は相当大きいかもしれませんが、その具体的な程度は確定的ではないということです。

### 結果の報告

「フィッシャーの正確性検定を用いて性別と授業評価の間の関連性を調査した。その結果、性別と授業評価の間に統計的に有意な関連性があることが示された（p = .010）。この関連性の大きさをオッズ比で表現すると6.61 (95% CI [1.46, 35.74]) となった。この結果は、性別が授業評価に有意な影響を持つ可能性があることを示唆している。」

### χ²検定との比較

フィッシャーの正確性検定とχ²検定の結果は一致し、両方とも性別と授業評価の間に統計的に有意な関連性が存在することを示しています。ただし、フィッシャーの正確性検定は一般的にχ²検定よりも保守的な結果を提供する傾向があります。これはフィッシャーの正確性検定が小さなサンプルサイズや各セルの期待度数が少ない場合に適しているためです。一方、サンプルサイズや期待度数が大きい場合は、χ²検定がより適していると考えられます。これらの検定方法を選択する際には、データの特性や研究の目的を考慮することが重要です。

# 6. マクネマー検定（対応のある二項的なデータの分析）

マクネマー検定は、対応のある二項的なデータ（成功/失敗、はい/いいえ等）を分析するためのノンパラメトリックな統計手法であり、カテゴリカルな変数間の関連性を評価します。これはχ²検定の一種であり、対応のあるペアデータに特に適用されます。さらに、マクネマーのオッズ比を用いることで、二つの変数間の関連性の強度を評価することができます。

## 理論

マクネマー検定の帰無仮説は、「二つのカテゴリーの出現頻度は等しい」つまり、一方の変数の状態がもう一方の変数の状態に影響を及ぼさないというものです。

マクネマー検定は2x2のクロス集計表に基づいて計算を行います。具体的には、以下のような表を作成します:

```{r, error=FALSE, include=TRUE}
# matrix関数を用いて2行2列の行列を作成します。
data <- matrix(c("a", "b", "c", "d"), nrow = 2, byrow = TRUE,
               dimnames = list("Condition B" = c("Success", "Failure"),
                               "Condition A" = c("Success", "Failure")))

# 作成した行列を表示します。
print(data)
```

ここで、a、b、c、dはそれぞれの条件下で成功または失敗した被験体の数を示しています。そして、マクネマー検定の統計量は以下の式で計算されます:

\[χ² = (|b - c| - 1)² / (b + c)\]

このχ²の値が大きければ大きいほど、帰無仮説（条件Aと条件Bが同等の影響を及ぼす）が棄却されやすくなります。

一方、マクネマーのオッズ比は以下のように計算されます:

\[OR = \frac{a \times d}{b \times c}\]

ここで、a、b、c、dはそれぞれの条件下で成功または失敗した被験体の数を示しています。マクネマーのオッズ比は、対応のある2×2のクロス集計表から計算され、二つのカテゴリカルな変数間の関連性の強度を測定します。

以下に、Rを用いた具体的な例を示します:

```{r, error=TRUE, include=TRUE}
# 2行2列のクロス集計表を作成します。
data <- matrix(c(20, 30, 25, 25), nrow = 2)

# 行と列の名前をそれぞれ"条件B: 成功", "条件B: 失敗"、"条件A: 成功", "条件A: 失敗"と設定します。
rownames(data) <- c("条件B: 成功", "条件B: 失敗")
colnames(data) <- c("条件A: 成功", "条件A: 失敗")

# 作成したクロス集計表を出力します。
print(data)
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。この検定は、2x2のクロス集計表に対し、関連性または一貫性の評価に使用されます。
test_results <- mcnemar.test(data)

# マクネマー検定の結果を出力します。
print(test_results)
```

```{r, error=TRUE, include=TRUE}
# マクネマーのオッズ比を計算します。
odds_ratio <- (data[1, 1] * data[2, 2]) / (data[1, 2] * data[2, 1])

# マクネマーのオッズ比を出力します。
print(odds_ratio)
```

この例では、条件Aと条件B下での成功と失敗の頻度に差があるかどうかをマクネマー検定で評価しています。また、マクネマーのオッズ比により、これら二つの条件間の関連性の強度を評価しています。マクネマー検定のp値とマクネマーのオッズ比を用いて、二つの条件間に統計的に有意な差異および関連性が存在するかどうかを判断することが可能です。

## 実践

### 例示の背景

以下の例示では、幼稚園の子供たちが2つの異なるストーリー（「許す」または「許さない」）を聞いた後、「一緒に遊ぶ」か「別々に遊ぶ」かを選択するシチュエーションについて考察します。

### 仮説の設定

このシナリオの場合、帰無仮説（H0）と対立仮説（H1）は次のように設定されます:

- H0: ストーリーは子供たちの選択（一緒に遊ぶか、別々に遊ぶか）に影響を与えない。
- H1: ストーリーは子供たちの選択（一緒に遊ぶか、別々に遊ぶか）に影響を与える。

### データの準備

```{r}
# "20230616_chap4sample3_RToda.csv"という名前のCSVファイルをread_RToda.csv関数を用いて読み込み、その結果を"data"という変数に代入します。
data <- read_RToda.csv("20230616_chap4sample3_RToda.csv", header=TRUE)

# "data"データフレームの最初の数行をhead関数を用いて表示します。これによりデータの一部を確認できます。
head(data)
```

```{r, error=TRUE, include=TRUE}
# "data"データフレームの構造をstr関数を用いて確認します。これによりデータの各列のタイプ、列数、行数などを確認できます。
str(data)
```

### 前提条件の検証

マクネマー検定を使用する前に、必要な前提条件を確認する必要があります:

- データは対応のある二項的なデータ（成功/失敗、はい/いいえなど）であること。
- 各サブグループ（ここでは、各ストーリー）内の観測値は互いに独立であること。

### Rでの実行

```{r, error=TRUE, include=TRUE}
# 交差表の作成
table_data <- with(data, table(Forgive, Reject))
table_data
```

```{r, error=TRUE, include=TRUE}
# mcnemar.test関数を用いて、マクネマー検定を実行します。correct=TRUEオプションを指定して、イェーツの補正を適用します。
# イェーツの補正とは二項分布が正規分布に近似するために行われる補正のことで、2×2の分割表のχ²検定に用いられます。特にサンプルサイズが小さい場合に有用です。
test_results <- mcnemar.test(table_data, correct=TRUE)

# マクネマー検定の結果をprint関数を用いて表示します。
print(test_results)
```
マクネマーのオッズ比を用いることで、ストーリーが子供たちの選択にどの程度影響を与えたかを定量的に評価することが可能となります。具体的には、オッズ比が1より大きければ、「許す」ストーリーが「許さない」ストーリーに比べて子供たちが「一緒に遊ぶ」選択をする可能性が高いことを示し、逆にオッズ比が1より小さければ、「許さない」ストーリーの方が子供たちが「一緒に遊ぶ」選択をする可能性が高いことを示します。

```{r, error=TRUE, include=TRUE}
# マクネマーのオッズ比を計算します。
odds_ratio <- (table_data[1, 1] * table_data[2, 2]) / (table_data[1, 2] * table_data[2, 1])

# マクネマーのオッズ比を表示します。オッズ比は、一つのストーリーがもう一つのストーリーに対して子供たちの選択をどの程度影響させたかを示します。
print(odds_ratio)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 必要なライブラリを読み込む
library(ggplot2)

# χ^2分布のパラメータ
df <- 1 # 自由度

# χ^2分布の確率密度関数の範囲を設定
x <- seq(0, 25, length.out = 1000)
y <- dchisq(x, df)

# データフレームを作成
df_chi_sq <- data.frame(x = x, y = y)

# プロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(colour = "black") +
  labs(x = "McNemar's Chi-squared", y = "Density", title = "χ^2 Distribution with df = 1") +
  theme_minimal()

# McNemar's Chi-squaredの値
mcnemars_chi_squared <- 16

# McNemar's Chi-squaredの値をプロットに追加
p <- p + 
  geom_vline(xintercept = mcnemars_chi_squared, linetype = "dashed", colour = "black") + 
  annotate("text", x = mcnemars_chi_squared, y = 3, 
           label = paste("McNemar's Chi-squared =", mcnemars_chi_squared, "(α = 6.334e-05)"),
           vjust = 4, hjust = 0.4, colour = "black")

# 有意水準0.05に対応するχ^2の値を計算
critical_value <- qchisq(0.95, df)

# 有意水準をプロットに追加
p <- p + 
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = 3, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           vjust = 4, hjust = 0.4, colour = "red")

# プロットを表示
print(p)
```

### 視覚化

次のRコードは、「許す」ストーリーと「許さない」ストーリーのそれぞれについて、「一緒に遊ぶ」選択と「別々に遊ぶ」選択の回数を示す棒グラフを描くものです。

```{r, error=TRUE, include=TRUE}
# ForgiveとRejectのデータを統合し新しいデータフレームを作成
new_data <- data.frame(
  Type = rep(c("Forgive", "Reject"), each = nrow(data)),
  Story = c(data$Forgive, data$Reject)
)

# データの集計
data_agg <- table(new_data)

# 集計結果をデータフレームに変換
data_df <- as.data.frame(data_agg)
names(data_df) <- c("Type", "Story", "Count")

# 棒グラフの描画
ggplot(data = data_df, aes(x = Type, y = Count, fill = Story)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("blue", "orange")) +
  labs(x = "Type of Story", y = "Number of Children", fill = "Choice") +
  theme_minimal() +
  theme(text = element_text(size = 15))
```

### 結果の解釈

今回の解析では、χ²統計量が16、自由度が1で、p値が6.334e-05であることが示されました。通常、p値が0.05未満の場合、統計的に有意と判断され、帰無仮説が棄却されます。今回のp値は6.334e-05と非常に小さいため、帰無仮説を棄却し、「一緒に遊ぶ」または「別々に遊ぶ」の選択が偶然だけによるものではないと結論付けます。

さらに、マクネマーのオッズ比は1.217391であり、これは「許す」ストーリーが「許さない」ストーリーに比べて、子供たちが「一緒に遊ぶ」を選択する可能性が約1.22倍高いことを示しています。

### 結果の報告

「イェーツの補正を用いたマクネマーの検定を使用して、ストーリーの結果が子どもたちの選択（「一緒に遊ぶ」または「別々に遊ぶ」）に影響を与えるかどうかを検討した。この検定では、χ²(1) = 16, p < .001という結果が得られ、これは選択が偶然に従って分布しているという帰無仮説を棄却するのに十分な証拠を示している。また、マクネマーのオッズ比から、「許す」ストーリーが「許さない」ストーリーに比べて、「一緒に遊ぶ」選択をする可能性が1.22倍高いという結果が示された（OR = 1.22）。」

# 7. 同質性の検定

## 理論

χ²同質性検定は、異なるグループ間でカテゴリカルデータの分布が同一であるかどうかを評価するための統計的手法です。この検定は、「2 x C」、「R x 2」、「R x C」の形式で適用され、χ²統計量を用いて、異なるグループ間で各カテゴリの分布が一致しているかを判断します。

χ²値の計算式は次の通りです：

\[\chi^2 = \sum_{i=1}^{n} \frac{(O_i - E_i)^2}{E_i}\]

ここで、

- \(O_i\)は各セルの観測度数、
- \(E_i\)は各セルの期待度数、

をそれぞれ示しています。

χ²同質性検定では、効果量としてCramerのVが使用されます。これは統計的な結果の「大きさ」を評価する指標で、その計算式は以下のとおりです：

\[V = \sqrt{\frac{\chi^2}{n(k-1)}}\]

ここで、

- \(\chi^2\)はχ²統計量、
- \(n\)はサンプルサイズ（観測数）、
- \(k\)は二つの変数のカテゴリの数のうち少ない方、

をそれぞれ示しています。

データの形式は３通りあり、

- 「2 x C」形式は2つのカテゴリを持つ複数のグループに対して

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2つのグループがC個のカテゴリに分けられるデータの例
data_2xC <- data.frame(
  group = c(rep("Group 1", 3), rep("Group 2", 3)),
  category = rep(c("Cat 1", "Cat 2", "Cat 3"), 2),
  frequency = sample(1:10, 6, replace = TRUE)
)

print(data_2xC)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# 2 x C形式のデータセットのクロス集計表
crossTab_2xC <- with(data_2xC, table(group, category))
print(crossTab_2xC)
```

- 「R x 2」形式は2つのカテゴリを持つ複数のグループに対して

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R個のグループが2つのカテゴリに分けられるデータの例
data_Rx2 <- data.frame(
  group = rep(c("Group 1", "Group 2", "Group 3"), 2),
  category = rep(c("Cat 1", "Cat 2"), 3),
  frequency = sample(1:10, 6, replace = TRUE)
)

print(data_Rx2)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R x 2形式のデータセットのクロス集計表
crossTab_Rx2 <- with(data_Rx2, table(group, category))
print(crossTab_Rx2)
```

- 「R x C」形式はR個のグループがC個のカテゴリに分けられる場合

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R個のグループがC個のカテゴリに分けられるデータの例
data_RxC <- data.frame(
  group = rep(c("Group 1", "Group 2", "Group 3"), each = 3),
  category = rep(c("Cat 1", "Cat 2", "Cat 3"), 3),
  frequency = sample(1:10, 9, replace = TRUE)
)

print(data_RxC)
```

```{r, error=FALSE, echo=FALSE, message=FALSE}
# R x C形式のデータセットのクロス集計表
crossTab_RxC <- with(data_RxC, table(group, category))
print(crossTab_RxC)
```

にそれぞれ使用されます。

## 実践:「2 x C」のχ²同質性検

「2 x C」形式のχ²同質性検定は、2つのカテゴリがC個のグループに分けられる場合に用いられます。

### 例示の背景

学習スタイルは年齢によって変化する可能性があります。本検定では、5歳と10歳の子供たちがどの程度異なる学習スタイルに分布しているかを調査します。

### 仮説の設定

帰無仮説：5歳と10歳の子供たちの間で学習スタイルの分布は同じである。

対立仮説：5歳と10歳の子供たちの間で学習スタイルの分布は同じではない。

### データの準備

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep("5 years old", 100), rep("10 years old", 100))
learning_style <- c(rep("Visual", 50), rep("Auditory", 30), rep("Kinesthetic", 20),
                    rep("Visual", 20), rep("Auditory", 30), rep("Kinesthetic", 50))

# データフレームを作成
data_2xC <- data.frame(age_group, learning_style)

# クロス集計表を作成
cross_table <- table(data_2xC)
cross_table
```

### Rでの実行

Rのchisq.test関数を使用してχ²検定を実行し、結果を得ます。

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_2xC <- chisq.test(cross_table)

# 結果を表示
print(result_2xC)
```

CramerのVを計算します。

```{r, error=TRUE, include=TRUE}
# Cramer's Vを計算
n <- sum(cross_table)  # サンプルサイズ
df <- min(dim(cross_table) - 1)  # 自由度
V <- sqrt(result_2xC$statistic / (n * df))
print(V)
```

```{r, error=TRUE, include=TRUE}
# 必要なライブラリの読み込み
library(ggplot2)

# パラメータ設定
df <- 2  # 自由度
x <- seq(0, 30, length.out = 1000)  # xの範囲を0から30に広げます
y <- dchisq(x, df)

# データフレーム作成
df_chi_sq <- data.frame(x = x, y = y)

# χ²分布のプロット
p <- ggplot(df_chi_sq, aes(x = x, y = y)) + 
  geom_line(color = "black") +
  labs(title = "χ² distribution", x = "Value", y = "Density") +
  theme_minimal()

# テスト統計量の位置を表示
test_statistic <- 25.714  # 実際のテスト統計量
p_val <- 2.607e-06  # 実際のp値
p <- p +
  geom_vline(xintercept = test_statistic, linetype = "dashed", colour = "black") +
  annotate("text", x = test_statistic, y = max(df_chi_sq$y) * 0.2, 
           label = paste("χ² =", round(test_statistic, 3), "(p =", formatC(p_val, format = "e", digits = 3), ")"), 
           colour = "black", hjust = 0.5)

# 有意水準を表示
critical_value <- qchisq(0.95, df)  # 有意水準 0.05
p <- p +
  geom_vline(xintercept = critical_value, linetype = "dashed", colour = "red") +
  annotate("text", x = critical_value, y = max(df_chi_sq$y) * 0.2, 
           label = paste("Critical Value =", round(critical_value, 2), "(α = 0.05)"), 
           colour = "red", hjust = 0.5)

# プロットの表示
print(p)
```

### 前提条件の検証

バープロットを作成します。

```{r, error=TRUE, include=TRUE}
# バープロット
barplot(cross_table, beside = TRUE, col = c("blue", "red"), 
        legend = rownames(cross_table))
```

### 結果の解釈

χ²統計量が25.714であり、p値が2.607e-06であること、そして効果量（X-squared）が0.3585686であることから、以下の結論が導き出されます。

χ²統計量が25.714という結果は、観測されたカテゴリ（学習スタイル）の分布が期待される分布（年齢別の学習スタイルの分布）と有意に異なることを示しています。つまり、5歳と10歳の子どもたちの学習スタイルの選択には違いがあるということです。

さらに、p値が2.607e-06という非常に低い値は、帰無仮説（5歳と10歳の子どもたちの学習スタイルの分布は同じであるという仮説）を棄却するための強力な証拠を示しています。つまり、このデータからは、年齢が学習スタイルの選好に影響を及ぼすという証拠が強く示されています。

また、効果量であるX-squaredが0.3585686という結果は、年齢と学習スタイルの間に中程度の関連性があることを示しています。これは、年齢が学習スタイルの選好に中程度の影響を及ぼすという関連性がこのデータから見つかったということです。

### 結果の報告

「5歳と10歳の2つの年齢群が視覚的、聴覚的、運動的の3つの学習スタイルにどのように分布するかを調査するため、「2 x C」のχ²同質性検定を実施した。その結果、χ²(2) = 25.714, p < .001となり、5歳と10歳の子供たちの学習スタイルの分布が同一であるという帰無仮説は棄却された。効果量としてのCramerのVは.359であり、年齢群と学習スタイルとの間には中程度の関連性があることが示唆された。これらの結果から、5歳と10歳の子供たちの学習スタイルの選択には有意な違いが存在すると結論付けられる。」

### フィッシャーの正確性検定（サンプルサイズが小さい場合）

サンプルサイズが小さい場合や各セルの期待度数が5未満の場合は、χ²検定よりもフィッシャーの正確性検定の使用が推奨されます。フィッシャーの正確性検定は、特に2x2の分割表で使用され、その場合の結果は一般的により信頼性が高いとされています。

#### データの準備

この検定を行うためには、2つのカテゴリー変数を持つデータセットが必要です。以下のコードは、5歳と10歳の子供たちが視覚的か聴覚的な学習スタイルをどの程度選択するかのデータを生成します。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group_fisher <- c(rep("5 years old", 20), rep("10 years old", 20))
learning_style_fisher <- c(rep("Visual", 10), rep("Auditory", 10),
                    rep("Visual", 15), rep("Auditory", 5))

# データフレームを作成
data_2x2_fisher <- data.frame(age_group_fisher, learning_style_fisher)

# クロス集計表を作成
cross_table_fisher <- table(data_2x2_fisher)
cross_table_fisher
```

#### Rでの実行

フィッシャーの直接確率検定はfisher.test() 関数を使用して計算します。

```{r, error=TRUE, include=TRUE}
# Fisherの正確性検定を実行
result_fisher <- fisher.test(cross_table_fisher)

# 結果を出力
print(result_fisher)
```

#### 結果の解釈

フィッシャーの正確性検定の結果から、5歳と10歳の年齢群の間で視覚的学習と聴覚的学習の選択に有意な違いは認められませんでした。p値が0.1908となったことから、帰無仮説（二つの年齢群間で視覚的学習と聴覚的学習の選択に違いはない）が支持されました。

また、オッズ比は0.3429692で、その95%信頼区間は0.06896679から1.51195380となりました。これは10歳の子供たちが視覚的学習を選択する確率が、5歳の子供たちと比較して約0.34倍であることを示しています。しかし、95%信頼区間が1を含むため、この差が統計的に有意であるとは言えません。

#### 結果の報告

「フィッシャーの正確性検定を用いて、5歳と10歳の子供たちが視覚的または聴覚的な学習スタイルを選択する傾向に差があるかを検定した。その結果、二つの年齢群間で視覚的と聴覚的学習の選択に有意な違いは認められなかった、p = .19。また、求められたオッズ比は0.34で、これは10歳の子供たちが視覚的学習を選択する確率が、5歳の子供たちと比較して約0.34倍であることを示している。しかしながら、その95%信頼区間が0.07から1.51で1を含んでいるため、この差が統計的に有意であるとは言えない。」

#### χ²検定との比較

フィッシャーの正確性検定は、サンプルサイズが小さい、または各セルの期待度数が5以下の場合に、χ²検定よりも優れた選択となります。χ²検定は大きなサンプルサイズや各セルの期待度数が十分に大きい場合に有効ですが、それらの条件が満たされない場合には、統計的検出力が低下するか、誤検出のリスクが増えます。

この例のデータセットでは、各セルの観測度数が5を超えているため、χ²検定でも適切な結果が得られる可能性があります。しかし、フィッシャーの正確性検定を使用することで、サンプルサイズが小さい、または期待度数が低いセルの影響を排除できます。そのため、このデータセットではフィッシャーの正確性検定がχ²検定よりも適していると言えます。

## 実践:「R x 2」のχ²同質性検

「R x 2」形式のχ²検定は、R個のグループが2つのカテゴリに分けられる場合に使用されます。例えば、一親家庭、両親家庭、祖父母と同居の3つの家庭環境の子供たちが、学業成績が平均以上か平均未満かでどのように分かれるかを調査する場合などです。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
family_environment <- rep(c("一親家庭", "両親家庭", "祖父母と同居"), each = 50)
academic_performance <- rep(c("平均以上", "平均未満"), each = 75)

# データフレームを作成
data_Rx2 <- data.frame(family_environment, academic_performance)

# クロス集計表を作成
cross_table <- table(data_Rx2)
print(cross_table)
```

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_Rx2 <- chisq.test(cross_table)

# 結果を表示
print(result_Rx2)
```

## 実践:「R x C」のχ²同質性検

R x C」形式のχ²検定は、R個のグループがC個のカテゴリに分けられる場合に使用されます。これは、より複雑なデータセットを分析する際に利用されます。たとえば、異なる年齢層（5歳、10歳、15歳）の子供たちが3つの異なる学習スタイル（視覚的、聴覚的、運動性）にどのように分かれるかを調査する場合などです。

```{r, error=TRUE, include=TRUE}
# カテゴリとグループを生成
age_group <- c(rep(c("5歳", "10歳", "15歳"), each = 100))
learning_style <- c(rep(c("視覚的", "聴覚的", "運動性"), length.out = 300))

# データフレームを作成
data_RxC <- data.frame(age_group, learning_style)

# クロス集計表を作成
cross_table <- table(data_RxC)
cross_table
```

```{r, error=TRUE, include=TRUE}
# χ²検定を実行
result_RxC <- chisq.test(cross_table)

# 結果を表示
print(result_RxC)
```

# 8. 多重比較

統計解析では、複数の比較を一度に行うことを多重比較と呼びます。しかし、一度に多くの比較を行うと、偶然による偽陽性（存在しない効果を検出する誤り）のリスクが増大します。これを緩和するために、以下の補正方法が提案されています。

## 多重比較の種類

1. ボンフェローニ補正 (Bonferroni correction): 各比較の有意性レベル（p値）を全体の比較の数で割ることで偽陽性のリスクを減らしますが、厳格すぎるために偽陰性のリスクも増大します。

2. ホルム補正 (Holm correction): ボンフェローニ補正を改良し、全てのp値を小さい順に並べ、それぞれにボンフェローニ補正を適用します。これにより偽陽性のリスクを抑えつつ、偽陰性のリスクも低減します。

3. ベンジャミニ＆ホッホベルク法 (Benjamini & Hochberg method): 偽陽性の「割合」を制御する方法で、全てのp値を小さい順に並べ、それぞれのp値に（その順位/全比較数）*目標FDRを掛けた値を新たなp値とします。

4. チューキーのHSD法 (Tukey's HSD method): ANOVA（分散分析）後の多重比較に有効で、全てのペア間の比較を行います。

## 独立性の検定と多重比較補正の使用例

この例では、ある幼稚園で男女各100名の子どもたち（合計200名）に、3種類のおもちゃ（A、B、C）の中からどれが一番好きかを選択させ、子どもたちの性別とおもちゃの選択に有意な関連性があるかどうかをχ²検定で評価します。その結果に対して多重比較補正を適用し、性別ごとのおもちゃの選択の違いを詳しく検証します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(readr)
library(dplyr)

# データを読み込む
data <- read_csv("20230616_20230616_chap4practice_RToda.csv")
head(data)
```

```{r, error=TRUE, include=TRUE}
# データ型の確認
str(data)
```

```{r, error=TRUE, include=TRUE}
# データフレームから性別とおもちゃの選択についてのクロス集計表を作成
contingency_table <- table(data$gender, data$choice)
contingency_table
```

```{r, error=TRUE, include=TRUE}
# χ²独立性検定を実施
chisq_res <- chisq.test(contingency_table)

# p値を取得
p_value <- chisq_res$p.value

# ボンフェローニ補正、ホルム補正、ベンジャミニ＆ホッチベルク補正（BH補正）を適用してp値を補正
bonferroni <- p.adjust(p_value, method = "bonferroni")
holm <- p.adjust(p_value, method = "holm")
BH <- p.adjust(p_value, method = "BH")

# 補正後のp値を表示
data.frame(Bonferroni = bonferroni, Holm = holm, BH = BH)
```

```{r, error=TRUE, include=TRUE}
# 性別ごとのおもちゃの選択の違いを詳しく調査するため、ペアワイズのχ²検定を実施
choices <- unique(data$choice)
pairs <- combn(choices, 2)
pairwise_chisq <- sapply(1:ncol(pairs), function(i) {
  subdata <- data %>% filter(choice %in% pairs[,i])
  chisq_res <- chisq.test(table(subdata$gender, subdata$choice))
  chisq_res$p.value
})

# 各ペア間のχ²検定のp値を補正
bonferroni_pairwise <- p.adjust(pairwise_chisq, method = "bonferroni")
holm_pairwise <- p.adjust(pairwise_chisq, method = "holm")
BH_pairwise <- p.adjust(pairwise_chisq, method = "BH")

# 補正後のペアワイズp値を表示
pairwise_df <- data.frame(Pairs = apply(pairs, 2, paste, collapse = " vs "), 
                          Bonferroni = bonferroni_pairwise, 
                          Holm = holm_pairwise, 
                          BH = BH_pairwise)

pairwise_df
```

これらの結果を通じて、性別ごとのおもちゃの選択の違いを明らかにすることができ、また、その違いが統計的に有意であるかどうかを多重比較補正を用いて評価することができます。

## 一元配置分散分析(ANOVA)とチューキーのHSD法による多重比較の使用例

一元配置分散分析（ANOVA）は、一つ以上の要因が群間での平均値の差異を引き起こすかどうかを評価するための統計的手法です。さらに、チューキーのHSD法を利用することで、具体的な群間の差を明らかにすることができます。ここでは、これらの方法を用いて、特定の介入がスコアにどのような影響を及ぼすかを調査する例を示します。

```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込む
library(agricolae)

# 再現可能なランダムな結果を得るために乱数シードを設定
set.seed(123)

# データフレームを作成。Intervention列に"A", "B", "C"を、Score列には異なる平均値と標準偏差をもつ正規分布から抽出したスコアを割り当てる
data <- data.frame(
  Intervention = rep(c("A", "B", "C"), each = 50),
  Score = c(rnorm(50, mean = 80, sd = 10),
            rnorm(50, mean = 85, sd = 10),
            rnorm(50, mean = 90, sd = 10))
)
head(data)
```

```{r, error=TRUE, include=TRUE}
# Intervention列の影響をスコアに対して評価するために一元配置ANOVAを適用する
model <- aov(Score ~ Intervention, data = data)

# ANOVAの結果を表示
summary(model)
```

```{r, error=TRUE, include=TRUE}
# チューキーのHSD法を用いて具体的な群間比較を行う
HSD_result <- HSD.test(model, 'Intervention', group = TRUE)

# 結果を表示
print(HSD_result)
```

この例では、ANOVAを使用して教育介入（A、B、C）が学生のスコアに対してどのような影響を及ぼしているかを評価します。その後、チューキーのHSD法を用いて各介入間のスコアの差を明らかにします。ANOVAの結果にかかわらず、チューキーのHSD法は介入効果の具体的な違いを理解するために用いられます。ただし、ANOVAの結果が非有意の場合、その結果を過度に解釈することは避けるべきです。

## マクネマー検定と多重比較補正の使用例

教育介入方法A、B、Cが子供の行動にどれほど影響を及ぼすかを評価します。それぞれの教育介入についてマクネマー検定を行い、得られたp値に対してボンフェローニ補正、ホルム補正、そしてベンジャミニ＆ホッホベルグ法を適用します。これらの補正は、多重比較によって誤って有意な結果と判断されるリスクを軽減するためのものです。

なお、チューキーのHSD法はANOVAの結果に対する多重比較補正として使用される手法で、マクネマー検定に対しては直接適用することはできません。


```{r, error=TRUE, include=TRUE}
# 必要なパッケージを読み込み
library(stats)

# 結果の再現性を確保するためのシード設定
set.seed(123)

# 各教育介入方法についてデータ生成
before_A <- sample(c(0, 1), 100, replace = TRUE)
after_A <- sample(c(0, 1), 100, replace = TRUE)
before_B <- sample(c(0, 1), 100, replace = TRUE)
after_B <- sample(c(0, 1), 100, replace = TRUE)
before_C <- sample(c(0, 1), 100, replace = TRUE)
after_C <- sample(c(0, 1), 100, replace = TRUE)

# 各方法についてマクネマー検定の実施
mcnemar_res_A <- mcnemar.test(before_A, after_A)
mcnemar_res_B <- mcnemar.test(before_B, after_B)
mcnemar_res_C <- mcnemar.test(before_C, after_C)

# p値の取得
p_values <- c(mcnemar_res_A$p.value, mcnemar_res_B$p.value, mcnemar_res_C$p.value)

# 各補正法によるp値の調整
bonferroni <- p.adjust(p_values, method = "bonferroni")
holm <- p.adjust(p_values, method = "holm")
BH <- p.adjust(p_values, method = "BH")

# 元のp値と補正後のp値を表示するためのデータフレームを作成
result_df <- data.frame(
  Method = c("A", "B", "C"),
  p_value = p_values,
  p_value_bonferroni = bonferroni,
  p_value_holm = holm,
  p_value_BH = BH
)

# 結果を表示
print(result_df)
```

これらの結果を通じて、各教育介入方法が子供の行動に与える影響の有意性を複数の補正法に基づいて評価することができます。これにより、個々の教育介入方法の効果をより厳密に解釈することが可能になります。

# 参考ページ:

- [統計学の時間 - パラメトリックとノンパラメトリック](https://bellcurve.jp/statistics/course/1562.html)

- [Study Channel - パラメトリックとノンパラメトリック](https://www.study-channel.com/2015/06/parametric-nonparametric-test.html)

- [日経調査研究所 - χ²検定](https://service.nikkei-r.co.jp/glossary/chi-square-test/)

- [Best Biostatistics - 自由度の理解](https://best-biostatistics.com/contingency/degree-freedom.html)

- [統計学の時間 - χ²適合度検定](https://bellcurve.jp/statistics/course/9494.html)
